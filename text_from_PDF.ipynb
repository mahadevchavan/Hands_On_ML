{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc1e4c-c69d-47f1-bf73-38a44df80689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d83157e6-c24a-4ad8-99f3-8224c446f506",
   "metadata": {},
   "source": [
    "## extracting all the string which contains text and string and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f269c274-4c6e-41ea-80b9-cf0be2a3d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pdfminer.high_level import extract_pages, extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870edd2a-0e67-4528-9f7e-59dd39a13669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "Contents lists available at ScienceDirect\n",
      "\n",
      "Graphics and Visual Computing\n",
      "\n",
      "journal homepage: www.elsevier.com/locate/gvc\n",
      "\n",
      "Technical section\n",
      "A comprehensive evaluation of deep models and optimizers for Indian\n",
      "sign language recognition✩,✩✩\n",
      "\n",
      "Prachi Sharma\n",
      "Indian Institute of Technology, Roorkee, India\n",
      "\n",
      "∗\n",
      ", Radhey Shyam Anand\n",
      "\n",
      "a r t i c l e\n",
      "\n",
      "i n f o\n",
      "\n",
      "a b s t r a c t\n",
      "\n",
      "Article history:\n",
      "Received 9 February 2021\n",
      "Received in revised form 12 June 2021\n",
      "Accepted 28 July 2021\n",
      "Available online 4 August 2021\n",
      "\n",
      "Keywords:\n",
      "Sign language recognition\n",
      "Deep learning\n",
      "Kinect\n",
      "Convolution neural networks\n",
      "\n",
      "Deep Learning has become popular among researchers for a long time, and still, new deep convolution\n",
      "neural networks come into the picture very frequently. However, it is challenging to select the best\n",
      "amongst such networks due to their dependence on the tuning of optimization hyperparameters,\n",
      "which is a trivial task. This situation motivates the current study, in which we perform a systematic\n",
      "evaluation and statistical analysis of pre-trained deep models. It is the first comprehensive analysis\n",
      "of pre-trained deep models, gradient-based optimizers and optimization hyperparameters for static\n",
      "Indian sign language recognition. A three-layered CNN model is also proposed and trained from scratch,\n",
      "which attained the best recognition accuracy of 99.0% and 97.6% on numerals and alphabets of a\n",
      "public ISL dataset. Among pre-trained models, ResNet152V2 performed better than other models with\n",
      "a recognition accuracy of 96.2% on numerals and 90.8% on alphabets of the ISL dataset. Our results\n",
      "reinforce the hypothesis for pre-trained deep models that, in general, a pre-trained deep network\n",
      "adequately tuned can yield results way more than the state-of-the-art machine learning techniques\n",
      "without having to train the whole model but only a few top layers for ISL recognition. The effect of\n",
      "hyperparameters like learning rate, batch size and momentum is also analyzed and presented in the\n",
      "paper.\n",
      "\n",
      "© 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND\n",
      "license (http://creativecommons.org/licenses/by-nc-nd/4.0/).\n",
      "\n",
      "1. Introduction\n",
      "\n",
      "Human–computer interface (HCI) [1] is one of the most crucial\n",
      "research areas due to its benefit to society and advancement\n",
      "in technology. HCI applies to every sector, whether healthcare,\n",
      "education, space, information technology, consumer discretionary\n",
      "or communication services. Gesture recognition is a part of HCI\n",
      "with many applications. Sign language recognition (SLR) is a\n",
      "gesture-recognition application that helps system control in com-\n",
      "puters and phones, gaming interface, image scaling, controlling\n",
      "machines like robots and TV. All these applications work on image\n",
      "or video processing and thus, require a lot of visual computation.\n",
      "Deaf communities use sign language as a communication\n",
      "mode within their community and outside the world. It is a\n",
      "visual language that uses facial, body and hand gestures, unlike\n",
      "the spoken language in everyday communication. Conversion of\n",
      "sign language into speech or text must bridge the gap between\n",
      "the deaf and hearing world. The usage of hand-crafted features\n",
      "and machine learning (ML) algorithms have been extensive since\n",
      "\n",
      "✩\n",
      "✩✩\n",
      "∗\n",
      "\n",
      "This article was recommended for publication by C. Sandor.\n",
      "\n",
      "Only capitalize first word and proper nouns in the title.\n",
      "Corresponding author.\n",
      "E-mail addresses: psharma3@ee.iitr.ac.in (P. Sharma), r.anand@ee.iitr.ac.in\n",
      "\n",
      "(R.S. Anand).\n",
      "\n",
      "1970s for gesture recognition, particularly SLR [2–6]. Deep learn-\n",
      "ing (DL) soon replaced the manual features and ML algorithms\n",
      "with more efficient, automatic, less time-consuming, and better-\n",
      "performing feature extraction and classification techniques like\n",
      "convolution neural networks (CNNs) [6–9]. Researchers also use\n",
      "multiple data types, such as RGB [6], depth [10] and skeleton [11],\n",
      "for gesture recognition. Depth is the distance of the object from\n",
      "the camera or sensor, and skeleton data consists of various\n",
      "joint locations of a human body. In 2014, Microsoft launched\n",
      "KinectV2 [6,12,13], based on the time-of-flight principle, which\n",
      "calculates the round trip time of a light signal from an LED or\n",
      "laser, thereby indicating the depth. This camera can capture all\n",
      "three data types, making it popular in the field of computer\n",
      "vision. Many works are reported in the literature on sign language\n",
      "recognition that used the data types mentioned above and CNN,\n",
      "and thus, outperformed the state-of-the-art ML techniques.\n",
      "\n",
      "Abiyev et al. [14] extracted the features using pre-trained\n",
      "deep model InceptionV3 [15] that outperformed the hand-crafted\n",
      "features with a finger-spelling recognition accuracy of 99.9% with\n",
      "support vector machines (SVMs) as a classifier. Wu et al. [16]\n",
      "classified the gestures of ChaLearn Looking At People dataset us-\n",
      "ing 3D-CNN with RGB, depth and skeletal data and outperformed\n",
      "the state-of-the-art ML algorithms with a Jaccard index score of\n",
      "0.81. Duan et al. [17] used a two-stream convolution network\n",
      "with both the spatial and temporal RGB and depth data and\n",
      "\n",
      "https://doi.org/10.1016/j.gvc.2021.200032\n",
      "2666-6294/© 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "achieved an accuracy of 67.3% on ChaLearn LAP isolated gesture\n",
      "dataset more than the state-of-the-art ML techniques. Liao et al.\n",
      "[18] used a bi-directional long short term memory (LSTM) 3D\n",
      "CNN residual network for recognition of signs in two Chinese\n",
      "sign language datasets with recognition accuracies of 89.8% and\n",
      "86.9%, more than the accuracy achieved with existing approaches\n",
      "like hidden markov models (HMMs), neural networks and dy-\n",
      "namic time warping. The works on combined usage of ML and\n",
      "DL algorithms [14] are also reported in literature such as, Koller\n",
      "et al. [19] combined GoogLeNet architecture [20] with HMMs [16]\n",
      "to recognize continuous sign language and improved word error\n",
      "rate on three public sign language datasets. More robust gesture\n",
      "recognition systems combined multiple data streams [13,17,21,\n",
      "22] like RGB, depth and skeleton. Liang et al. [23] used 3D-\n",
      "CNN with two sub-networks: (i) infra-red data and (ii) contour\n",
      "data as an input and achieved an accuracy of 89.2% on sign\n",
      "language video in museums dataset and 92.4% on ChaLearn LAP\n",
      "dataset. Ravi et al. [24] developed a four-stream CNN model using\n",
      "four inputs — both spatial and temporal RGB and depth data and\n",
      "achieved an accuracy of 86.7% on a 3D sign language dataset.\n",
      "Thus, a CNN deep learning model highly improves a recognition\n",
      "system’s performance, whether used alone or in combination\n",
      "with various ML techniques or multiple modalities.\n",
      "\n",
      "Training a deep model from scratch takes much time and a\n",
      "good graphics processing unit (GPU) which is not feasible if the\n",
      "dataset is vast or for the applications that require multiple runs\n",
      "of a model for optimization or analysis. Transfer learning [25–\n",
      "27] solves this problem by transferring the knowledge from one\n",
      "task to another completely in the form of weights or using the\n",
      "fine-tuning technique to train some layers of the trained model\n",
      "again on the new dataset. The literature consists of and uses CNN\n",
      "models, already trained on a public object recognition dataset −\n",
      "ImageNet [28], like AlexNet [29], GoogleNet [20] and many more.\n",
      "Transfer learning using the fine-tuning technique is a computa-\n",
      "tionally efficient and less time-consuming process that can be run\n",
      "even on a CPU. Liang et al. [23] formed two models using 3D-\n",
      "CNN − one model trained from scratch on ChaLearn LAP dataset\n",
      "achieved an accuracy of 92.4% on the same dataset, and the\n",
      "second model trained on another gesture dataset and finely tuned\n",
      "on ChaLearn LAP dataset achieved an accuracy of 96.3% more than\n",
      "the previous case. Abiyev et al. [14] extracted the features using\n",
      "InceptionV3 and classified gestures using SVM with an accuracy\n",
      "of 99.9%, which is more than the accuracy of 92.1% achieved\n",
      "when a CNN model is trained from scratch on the same dataset.\n",
      "The results show that transfer learning can greatly improve the\n",
      "performance of any deep model for SLR.\n",
      "\n",
      "The researchers explored SLR using different conventional and\n",
      "deep learning classification techniques; however, none of them\n",
      "simultaneously analyzed these models with various optimization\n",
      "algorithms and hyperparameters associated with them. Many\n",
      "works performed evaluations in the literature with either a fixed\n",
      "model [30] and hyperparameters [31] or no information about\n",
      "the used hyperparameters and optimizer [32]. Thus, based on\n",
      "literature and to the best of our knowledge, there is no com-\n",
      "prehensive analysis present in the literature evaluating the deep\n",
      "models, optimizers, and hyperparameters simultaneously.\n",
      "\n",
      "Motivated by this research gap, the proposed work discusses\n",
      "the evaluation results of\n",
      "four pre-trained models with five\n",
      "gradient-based optimizers and their associated optimization hy-\n",
      "perparameters like learning rate, batch size and momentum. A\n",
      "three-layered CNN model, trained from scratch, is also proposed\n",
      "that performed better than the other models used in the paper\n",
      "for ISL recognition. Thus, this comparative analysis gives insights\n",
      "into selecting the suitable deep model with the right optimizer\n",
      "and its hyperparameters to enhance the models’ performance for\n",
      "static ISL recognition.\n",
      "\n",
      "The paper is divided into sections: Section 1 introduces ad-\n",
      "vances in DL and transfer learning for SLR. Section 2 introduces\n",
      "the proposed methodology for the performance evaluation of\n",
      "CNN deep models with various optimizers and hyperparameters.\n",
      "The CNN architectures, optimization hyperparameters and algo-\n",
      "rithms used in the paper are explained in Sections 3, 4 and 5\n",
      "respectively. Section 6 discusses the evaluation metrics, dataset\n",
      "and its pre-processing for analysis of results in Section 7. Ex-\n",
      "perimental results are thoroughly discussed in Section 8 with\n",
      "conclusion in the last Section 9.\n",
      "\n",
      "2. Proposed methodology for comparative analysis\n",
      "\n",
      "This section discusses the proposed methodology for the eval-\n",
      "uation of deep models, optimizers and hyperparameters. Be-\n",
      "fore the performance evaluation, the depth data is first pro-\n",
      "cessed through depth thresholding to get the hands from the\n",
      "data. Secondly, the segmented hand’s binary image is converted\n",
      "to a colored image for deep models, and lastly, data is aug-\n",
      "mented to avoid over-fitting. Four pre-trained models viz. In-\n",
      "ceptionV3, ResNet152V2, InceptionResNetV2 and ReXNet101 are\n",
      "selected from the literature based on their performance in the Im-\n",
      "ageNet [28] challenge. A customized three-layered CNN model is\n",
      "also designed, trained from scratch, and then compared with the\n",
      "pre-trained deep models mentioned above. This paper uses five\n",
      "gradient-based optimizers: Stochastic gradient descent (SGD),\n",
      "adaptive gradient (AdaGrad), adaptive delta (AdaDelta), root mean\n",
      "square propagation (RMSProp) and adaptive moment estimation\n",
      "(Adam) with their hyperparameters like learning rate, batch size\n",
      "and momentum. This work aims to evaluate the latest deep mod-\n",
      "els, optimizers, and hyperparameters on Indian signs. Thus, two\n",
      "subsets, Numerals and Alphabets, of a publicly available dataset are\n",
      "selected for the comprehensive analysis. First, Numerals subset\n",
      "with 9 classes is used to tune the hyperparameters, which are\n",
      "then applied to the Alphabets subset (24 classes) to evaluate the\n",
      "performance of deep models on a subset using the hyperparam-\n",
      "eters tuned on a different subset of the same dataset. The pro-\n",
      "cess of evaluating the models, optimizers and hyperparameters\n",
      "follows the steps given below.\n",
      "\n",
      "Step 1: This step uses the relatively smaller sized architecture-\n",
      "InceptionV3 to tune the batch size on the Numerals subset of the\n",
      "dataset by fixing other hyperparameters and optimizers.\n",
      "\n",
      "Step 2: InceptionV3 is again used to tune the learning rate and\n",
      "momentum (SGD) for each optimizer by fixing the batch size with\n",
      "the value obtained in Step 1 and using the Numerals subset.\n",
      "\n",
      "Step 3: This step evaluates the optimizers with the hyperpa-\n",
      "rameter settings selected from Steps 1 and 2. The optimizer with\n",
      "the lowest loss and highest recognition accuracy on the Numerals\n",
      "subset is selected to evaluate the deep models further.\n",
      "\n",
      "Step 4: Finally, this last step evaluate the deep models with\n",
      "the selected hyperparameters and optimizer from Steps 1, 2 and\n",
      "3 on both the Numerals and Alphabets of the dataset.\n",
      "\n",
      "Thus, in the end, the CNN model that gives the highest recog-\n",
      "nition performance on both the subsets of the ISL dataset is\n",
      "considered to be the most suitable for the application of static\n",
      "ISL recognition.\n",
      "\n",
      "3. CNN models\n",
      "\n",
      "The work in this paper utilizes fine-tuning of pre-trained deep\n",
      "models, where a sequence of flatten, dense, and dropout layers\n",
      "(Fig. 1) replace the last layer of these models and freeze the re-\n",
      "maining layers to train on the ISL dataset. This section thoroughly\n",
      "discusses the architectures of pre-trained deep models and the\n",
      "proposed three-layered CNN model used for feature extraction\n",
      "and classification of Indian signs.\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "Table 1\n",
      "Architectural and performance details of pre-trained deep models.\n",
      "\n",
      "Models\n",
      "\n",
      "Parameters (M)\n",
      "\n",
      "Layers\n",
      "\n",
      "Size (MB)\n",
      "\n",
      "Top-1 Loss\n",
      "\n",
      "Top-2 Loss\n",
      "\n",
      "InceptionV3 [15]\n",
      "ResNet152V2 [33]\n",
      "InceptionResNetV2 [34]\n",
      "ResNeXt101 [35]\n",
      "\n",
      "23.8\n",
      "60.4\n",
      "55.8\n",
      "−−\n",
      "\n",
      "48\n",
      "152\n",
      "164\n",
      "101\n",
      "\n",
      "92\n",
      "232\n",
      "215\n",
      "638\n",
      "\n",
      "21.2\n",
      "19.38\n",
      "19.9\n",
      "19.1\n",
      "\n",
      "5.6\n",
      "4.49\n",
      "4.9\n",
      "4.4\n",
      "\n",
      "modules in softmax layers prevent the vanishing gradient prob-\n",
      "lem in the middle of the model. Thus, InceptionV1 aims to make\n",
      "a balance between efficiency and computational complexity to\n",
      "improve an inception model. InceptionV2 [15] also incorporates\n",
      "the following changes when compared to the previous versions:\n",
      "(1) factorizing large convolutions into smaller ones (2) factorizing\n",
      "convolutions into asymmetric ones (3) expanding the filter banks\n",
      "to make the model wider that reduces its representation bottle-\n",
      "neck (4) reducing the grid size by parallel pooling, convolving and\n",
      "then concatenation. InceptionV3 [15] is similar to InceptionV2\n",
      "with the addition of the following: (1) factorizing 7 × 7 convolu-\n",
      "tions (2) using RMSProp as an optimizer (3) batch normalization\n",
      "of the side layer of the network consisting of auxiliary classifiers\n",
      "(4) introducing label smoothing regularization to make the model\n",
      "less confident about a class, thereby, preventing the over-fitting\n",
      "problem. This paper selects InceptionV3 due to its popularity\n",
      "as it is the first runner up with the lowest error rate in image\n",
      "classification competition on ImageNet dataset in 2015.\n",
      "\n",
      "3.3. ResNet152V2\n",
      "\n",
      "He et al. [36] introduced deep residual neural networks\n",
      "(Resnets) in 2015 and proposed stacked residual blocks instead of\n",
      "a plain network to solve the vanishing gradient problem. Instead\n",
      "of following the main path in a plain network that involves linear\n",
      "operators and non−linear activations, the residual blocks have\n",
      "a short cut path that directly adds the input activation to the\n",
      "last layer’s output without going from the main path. The first\n",
      "version of resnet − ResNetV1 adds the last layer’s output in\n",
      "the original residual network before the non-linear activation\n",
      "− rectified linear unit (ReLU) and after the linear operation. In\n",
      "the second version − ResNetV2 [33], authors made a direct path\n",
      "in the resnet architecture for propagating the information from\n",
      "input to output in 2016. Unlike ResNetV1, ResNetV2 is a full\n",
      "pre-activation architecture using both the batch normalization\n",
      "(BN) and ReLU layers as pre-activation by adopting these layers\n",
      "before the weight layers. ResNetV2 has resulted in significant\n",
      "improvements in performance on various datasets as shown in\n",
      "paper [33], and thus, this work selected one of its variants,\n",
      "ResNet152V2 consisting of 152 layers for performance evaluation\n",
      "on the recognition of Indian signs.\n",
      "\n",
      "3.4. InceptionResNetV2\n",
      "\n",
      "InceptionResNetV2 [34] is similar to InceptionV4 [34] except\n",
      "the added advantage of residual connections. Deep networks with\n",
      "many layers like inceptions (>30) usually suffer from vanishing\n",
      "gradient problem. Thus, replacing filter concatenations in an in-\n",
      "ception model with the residual connections proves instrumental\n",
      "in increasing the speed of the model’s convergence and efficiency,\n",
      "thereby solving the vanishing gradient problem [36]. Szegedy\n",
      "et al. [34] analyzed both the cases of an inception network —\n",
      "residual (InceptionResNetV2) and non-residual (InceptionV4) and\n",
      "reported that InceptionResNetV2 is marginally better than Incep-\n",
      "tionV4 in terms of convergence speed, classification accuracy and\n",
      "loss. It is the reason for selecting InceptionReNetV2 for evalua-\n",
      "tion in this work. Table 1 gives the details about the network’s\n",
      "architecture and performance on the ImageNet dataset.\n",
      "\n",
      "Fig. 1. Layers in pre-trained (Top) and the proposed three-layered CNN deep\n",
      "models.\n",
      "\n",
      "3.1. Proposed CNN model\n",
      "\n",
      "A custom-made three-layered CNN model is proposed that\n",
      "consists of a max-pooling and a dropout layer for regularization\n",
      "following the first two CNN layers, and the dropout, flattened, and\n",
      "dense layers following the last CNN layer shown in Fig. 1. This\n",
      "proposed model trains on the ISL dataset from scratch, comparing\n",
      "its recognition performance with pre-trained deep models’ that\n",
      "utilize the fine-tuning technique for training.\n",
      "\n",
      "3.2. InceptionV3\n",
      "\n",
      "Before the advent of inception models, increasing the number\n",
      "of layers and the neurons connected to those layers to make the\n",
      "model prominent was the only solution for improving the neural\n",
      "networks. The big models suffer from the following problems:\n",
      "high computational complexity, over-fitting due to limited train-\n",
      "ing dataset and fast disappearance of gradient change. The first\n",
      "version of an inception model, InceptionV1 [20], tried to solve\n",
      "these problems by increasing the width rather than the depth of\n",
      "a model incorporating multiple sized convolutional filters to get\n",
      "both the local and global information from an image. Also, in-\n",
      "troducing two auxiliary classifiers at the output of two inception\n",
      "\n",
      "3\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "3.5. ResNeXt101\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "5.1. Stochastic gradient descent (SGD)\n",
      "\n",
      "ResNeXt, one of the variants of resnet, was introduced in pa-\n",
      "per [35] in which the building block that aggregates a set of trans-\n",
      "formations repeats with the same topology. Here, ′X ′ represents\n",
      "′Next ′ dimension called ’Cardinality (C)’, which is the number of\n",
      "repetitions of a set of aggregated transformations, i.e. expand-\n",
      "ing the ’Network-in-Neuron’ along this new dimension. Eq. (1)\n",
      "represents these aggregated transformations as −\n",
      "\n",
      "SGD [38,39] is an optimizer that accelerates the process of\n",
      "convergence to the desired objective in a fast way. Instead of\n",
      "using all the training examples for computing the gradient by\n",
      "plain gradient descent method [40], SGD uses a mini-batch of\n",
      "samples from the training set for calculating the gradient. This\n",
      "process reduces the computational complexity irrespective of the\n",
      "size of the training data. The calculation of gradient at each\n",
      "iteration in SGD is shown in Eq. (2) as −\n",
      "\n",
      "F (x) =\n",
      "\n",
      "C\n",
      "∑\n",
      "\n",
      "i=1\n",
      "\n",
      "Ti(x)\n",
      "\n",
      "(1)\n",
      "\n",
      "g =\n",
      "\n",
      "·\n",
      "\n",
      "1\n",
      "\n",
      "n\n",
      "\n",
      "n\n",
      "∑\n",
      "\n",
      "i=1\n",
      "\n",
      "∇θ L(x(i), y(i), θt )\n",
      "\n",
      "(2)\n",
      "\n",
      "where Ti(x) is an arbitrary function that projects x into a low\n",
      "dimension and then transforms it.\n",
      "\n",
      "ResNeXt performs better than the other models like Incep-\n",
      "tionV3, V4 and InceptionResNetV2 for ImageNet-2k validation\n",
      "set as experimented in paper [35]. That is why this paper uses\n",
      "ResNeXt101 for SLR.\n",
      "\n",
      "4. Hyperparameters\n",
      "\n",
      "Hyperparameters of a network control the entire training pro-\n",
      "cess and are of two types: model and optimization. Model hyper-\n",
      "parameters define the structure of a network, and optimization\n",
      "hyperparameters decide the training process’s path to reach the\n",
      "desired output. This paper analyzes various optimization hyper-\n",
      "parameters with different pre-trained deep models. The opti-\n",
      "mization hyperparameters — batch size and learning rate are\n",
      "discussed below.\n",
      "\n",
      "Batch size: Batch size is the number of input training samples\n",
      "given, at a time, to the network. It decides the utilization of\n",
      "resources and the speed of a network. There are three types of\n",
      "training: batch, Stochastic and mini-batch. In batch training, the\n",
      "whole training set goes into training at once, i.e. batch size equals\n",
      "the total number of training samples. However, it is less time-\n",
      "consuming, but it takes too much memory and can get stuck\n",
      "in a local minimum. At a time, Stochastic training sends one\n",
      "training sample into training, i.e. batch size equals 1 and is very\n",
      "time-consuming but guarantees to reach the global minimum.\n",
      "Mini-batch training, where the batch size is greater than 1, con-\n",
      "verges fast with less memory requirement if the chosen batch size\n",
      "is not too large. The proposed work uses mini-batch training to\n",
      "solve the problems of batch and Stochastic training methods.\n",
      "\n",
      "The range of batch size selected for tuning is from 23(8) to\n",
      "\n",
      "27(128) because this is the most used range in the literature.\n",
      "\n",
      "Learning Rate: Learning rate is a hyperparameter that decides\n",
      "how fast and accurately the model converges to the desired\n",
      "point. The learning rate can be a constant value for the training\n",
      "process, or it can be automatically decayed using various decay\n",
      "schemes. This work follows a constant learning rate throughout\n",
      "the training process for each model, with the most used range\n",
      "from 1e − 1 to 1e − 5 based on the literature surveyed by\n",
      "Shivaprasad et al. [37].\n",
      "\n",
      "This paper also tunes two more hyperparameters, namely,\n",
      "momentum and Nesterov acceleration gradient (NAG), which are\n",
      "discussed in Section 5.1 as they belong to the SGD optimizer\n",
      "helping its gradient reach the objective quickly and accurately.\n",
      "\n",
      "5. Optimization algorithms\n",
      "\n",
      "Then, the weights of the model gets updated using the follow-\n",
      "\n",
      "ing update rule (Eq. (3)):\n",
      "θt+1 = θt − η · g\n",
      "(3)\n",
      "where θ is a parameter that can be changed to get the minimum\n",
      "loss. η is the learning rate that decides the extent of change of\n",
      "parameters w.r.t the gradients. However, SGD has the following\n",
      "problems − (1) becomes very slow when the gradient is con-\n",
      "sistently small, (2) has gradient-dependent update rule at each\n",
      "iteration, and (3) follows the wrong gradient frequently due to\n",
      "noisy gradients. The tuning of the optimization hyper-parameters\n",
      "− momentum and NAG solve the problems mentioned above.\n",
      "\n",
      "Momentum (M) and Nesterov acceleration gradient (NAG):\n",
      "Momentum method [41], developed by Polyak [42], accelerated\n",
      "the gradient descent by taking into account the previous gradi-\n",
      "ents at each iteration, thereby, updating the update rule as given\n",
      "in Eqs. (4) and (5) below.\n",
      "vt+1 = α · vt − η · g\n",
      "\n",
      "(4)\n",
      "\n",
      "θt+1 = θt + vt+1\n",
      "(5)\n",
      "where v is the velocity term that determines how fast and in what\n",
      "direction the parameter should be changed. The α is a decay-\n",
      "ing hyperparameter that determines how fast the accumulated\n",
      "gradients will decay.\n",
      "\n",
      "The momentum smoothens the unnecessary oscillations of\n",
      "gradients while reaching the desired output. However, if the\n",
      "momentum value is high and unknowingly skips the desired\n",
      "objective point, it will give bad results. NAG [43–45] further\n",
      "solves the problem of high momentum. The difference between\n",
      "the momentum and the NAG method lies only in the gradient\n",
      "part’s computation while the update rule remains the same. As\n",
      "given in Eq. (5), the gradient calculation in momentum method\n",
      "considers only current parameters θ but in NAG, velocity vt is\n",
      "applied to θ to compute the interim parameters ˜θ as shown\n",
      "in Eq. (6) below −\n",
      "˜θ = θt + α · vt\n",
      "\n",
      "(6)\n",
      "After the gradient calculation, the ˜θ will replace θ in the\n",
      "update rule given in Eq. (5). Thus, NAG acts as a correction\n",
      "factor for the momentum method. The momentum values used\n",
      "in the SGD optimizer are 0.0 (without momentum), 0.5 (slight\n",
      "momentum) and 0.9 (high momentum) with and without NAG\n",
      "because its value ranges from 0 to 1. InceptionV3 model tunes the\n",
      "momentum and NAG for SGD optimizer on ISL dataset’s numerals.\n",
      "\n",
      "5.2. Adaptive Gradient (AdaGrad)\n",
      "\n",
      "The gradient-based optimizers used in the paper are discussed\n",
      "\n",
      "in detail in the following subsections −\n",
      "\n",
      "The SGD optimizer works using a procedural scheme that\n",
      "applies the learning rate, unaware of the dataset’s characteristics.\n",
      "AdaGrad algorithm [46] solves this problem using the previous\n",
      "\n",
      "4\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "iterations to gather the knowledge of data’s geometry and in-\n",
      "corporate it in an informative way for gradient-based learning.\n",
      "A small learning rate is given in this algorithm if the features\n",
      "occur frequently and a large learning rate if the frequency of\n",
      "features occurring is shallow. SGD carry out an update for all\n",
      "the parameters θ because for every parameter θi, there is a fixed\n",
      "learning rate η. In AdaGrad, there are different learning rates for\n",
      "each parameter θi at every time step or iteration [47] as observed\n",
      "from Eq. (7) as −\n",
      "gt,i = ∇θt J(θt,i)\n",
      "where gt,i = gradient of the objective function w.r.t the parame-\n",
      "ter θi at time step t. The SGD update rule for every θi at each time\n",
      "step is given in Eq. (8) similar to Eq. (5) as −\n",
      "θt+1,i = θt,i + η · gt,i\n",
      "\n",
      "(7)\n",
      "\n",
      "(8)\n",
      "\n",
      "However, in Eq. (8), the learning rate has to be updated at\n",
      "every iteration for every parameter θi based on the previous\n",
      "gradients computed for θi for AdaGrad optimizer. Thus, Eq. (8)\n",
      "can be written as in Eq. (9) −\n",
      "\n",
      "θt+1,i = θt,i +\n",
      "\n",
      "η\n",
      "√Gt,ii + ϵ\n",
      "\n",
      "· gt,i\n",
      "\n",
      "where Gt,ii is the diagonal matrix where each diagonal element\n",
      "i, i is the sum of squares of gradients w.r.t θi up to time step t. ϵ\n",
      "is the smoothing term to prevent division by zero and is usually\n",
      "of the order of 1e − 8.\n",
      "\n",
      "The learning rate becomes endlessly small towards the end of\n",
      "the training process due to the aggregation of squared gradients\n",
      "in the denominator of Eq. (9) making it difficult for the model to\n",
      "learn new knowledge. Another optimizer called AdaDelta solves\n",
      "this problem and is explained in the following sub-section.\n",
      "\n",
      "5.3. AdaDelta\n",
      "\n",
      "Monotonically decreasing learning rate and a need to man-\n",
      "ually select the global learning rate are the two disadvantages\n",
      "of AdaGrad optimizer taken care of by AdaDelta. To solve the\n",
      "first problem, AdaDelta [48] implements an aggregation of ex-\n",
      "ponentially decaying average of squared gradients. The series of\n",
      "Equations [47] from (10) to (14) given below shows the imple-\n",
      "mentation of the above-mentioned aggregation. The SGD update\n",
      "rule in the form of δθt is given in Eqs. (10) and (11) as −\n",
      "δθt = −η · gt,i\n",
      "\n",
      "(10)\n",
      "\n",
      "θt+1 = θt + δθt\n",
      "\n",
      "(11)\n",
      "The value of δθt (Eq. (12)) in case of AdaDelta is written as −\n",
      "\n",
      "exponentially decaying average E[δθ 2]t of parameter updates δθ\n",
      "such as −\n",
      "√\n",
      "\n",
      "δθt = −\n",
      "\n",
      "E[δθ 2]t + ϵ\n",
      "RMS[g]t\n",
      "\n",
      "· gt\n",
      "\n",
      "Eq. (15) can also be written as −\n",
      "\n",
      "δθt = −\n",
      "\n",
      "RMS[δθ]t−1\n",
      "RMS[g]t\n",
      "\n",
      "· gt\n",
      "\n",
      "(15)\n",
      "\n",
      "(16)\n",
      "\n",
      "The Eq. (16) is now free from learning rate η solving the\n",
      "\n",
      "AdaGrad’s second problem.\n",
      "\n",
      "5.4. Root mean square propagation (RMSProp)\n",
      "\n",
      "RMSProp [49] is almost similar to the solution given by\n",
      "AdaDelta to the first problem of AdaGrad, as shown in Eq. (14).\n",
      "Both the algorithms, AdaDelta and RMSProp, were developed\n",
      "by two different researchers simultaneously but independently.\n",
      "Geoff Hinton discussed RMSProp for the first time in 2012 and\n",
      "stated that 0.9 value for γ (Eq. (13)) and 0.001 value for learning\n",
      "rate η (Eq. (14)) are the best suited ones.\n",
      "\n",
      "Adam [50] is a combination of two optimization algorithms\n",
      "− RMSProp and SGD with momentum. It also takes advantage of\n",
      "AdaGrad and RMSProp for dealing well with sparse gradients and\n",
      "online settings. Adam stores the second raw moment estimate,\n",
      "say vt , similar to RMSProp and AdaDelta, and the first-moment\n",
      "estimate, say mt , similar to momentum, and thus is named as\n",
      "adaptive moment estimation. The first and second moment es-\n",
      "timates [47] are exponentially decaying average of past and past\n",
      "squared gradients, respectively.\n",
      "mt = β1 · mt−1 + (1 − β1) · gt\n",
      "\n",
      "(17)\n",
      "\n",
      "vt = β2 · vt−1 + (1 − β1) · g 2\n",
      "\n",
      "t\n",
      "\n",
      "(18)\n",
      "\n",
      "According to Adam’s algorithm, the moment estimates are\n",
      "biased towards zero, especially in the initial phase of training\n",
      "when mt and vt initializes to 0 in Eqs. (17) and (18), and the\n",
      "learning process becomes slower when the decay rates β1 and\n",
      "β2 are close to zero. To solve this issue, bias-corrected estimates\n",
      "ˆmt and ˆvt are used to update the weights as given in Eqs. (19)\n",
      "and (20) below.\n",
      "ˆmt = mt /(1 − β t\n",
      "1)\n",
      "\n",
      "(19)\n",
      "\n",
      "ˆvt = vt /(1 − β t\n",
      "2)\n",
      "\n",
      "(20)\n",
      "\n",
      "(9)\n",
      "\n",
      "5.5. Adaptive Moment Estimation (Adam)\n",
      "\n",
      "δθt = −\n",
      "\n",
      "√\n",
      "\n",
      "η\n",
      "E[g 2]t + ϵ\n",
      "\n",
      "· gt\n",
      "\n",
      "(12)\n",
      "\n",
      "These bias-corrected terms are now used to calculate the\n",
      "Adam update rule (Eq. (21)) similar to RMSProp and AdaDelta.\n",
      "\n",
      "where E[g 2]t is the running average of the past squared gradi-\n",
      "ents and the current gradient at each time step t. It is defined\n",
      "in Eq. (13) as\n",
      "E[g 2]t = γ E[g 2]t−1 + (1 − γ )g 2\n",
      "\n",
      "(13)\n",
      "Here, γ is a decay constant similar to momentum. In Eq. (12),\n",
      "E[g 2]t + ϵ is the root mean squared error criterion of the gra-\n",
      "dient. Thus, Eq. (12) can be rewritten as Eq. (14) as shown below.\n",
      "\n",
      "√\n",
      "\n",
      "t\n",
      "\n",
      "δθt = −\n",
      "\n",
      "η\n",
      "RMS[g]t\n",
      "\n",
      "· gt\n",
      "\n",
      "(14)\n",
      "\n",
      "To solve the second problem of manually setting the global\n",
      "learning rate, the learning rate η in Eq. (14) is replaced by an\n",
      "\n",
      "5\n",
      "\n",
      "θt+1 = θt −\n",
      "\n",
      "η\n",
      "√ˆvt + ϵ\n",
      "\n",
      "· ˆmt\n",
      "\n",
      "(21)\n",
      "\n",
      "Kingma and Ba [50] suggests the default values for β1, β2 and\n",
      "\n",
      "ϵ to be 0.9, 0.999 and 10−8 respectively.\n",
      "\n",
      "6. Dataset descriptions and pre-processing\n",
      "\n",
      "This paper works on a public static ISL dataset developed by\n",
      "Ansari, and Harit [51], consisting of 140 Indian signs for alphabets,\n",
      "numerals, technical words and words related to objects, situa-\n",
      "tions, actions and people. The dataset involves 18 users repeating\n",
      "a particular Indian sign two times, but out of 18, data of only\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "focuses on a single cue — depth, for segmentation of hands, thus\n",
      "considering only depth data from the dataset. A depth value of\n",
      "2047 is assigned to a pixel in the dataset if it is out of the\n",
      "Kinect’s sensing limit. The segmentation of hands from the depth\n",
      "images uses the same methodology as described in paper [10]\n",
      "on American SLR involving depth thresholding for hand region\n",
      "segmentation followed by forearm removal. The steps for seg-\n",
      "menting the hand palm and fingers from a depth image are\n",
      "shown in Fig. 4. The segmented hands’ binary images are then\n",
      "converted into color images and given input to the pre-trained\n",
      "deep models. This manuscript aims to evaluate optimizers, pre-\n",
      "trained deep models, and optimization hyperparameters on static\n",
      "Indian signs; thus, the evaluation uses only two subsets of the\n",
      "ISL dataset − Numerals (1 − 9) and Alphabets (A − Y excluding\n",
      "J) instead of the whole dataset. Each class of Numerals (9) and\n",
      "Alphabets (24) consists of approximately 30 sample depth images,\n",
      "making a total of 269 images for Numerals and 716 images for\n",
      "Alphabets. Both the subsets consist of only single-handed Indian\n",
      "signs, and Fig. 2 shows some sample images of classes of both the\n",
      "subsets. The Alphabets are pretty complicated than the Numerals\n",
      "as the former consists of many similar shaped signs (shown in\n",
      "Fig. 2) and have more classes than the latter. These differences\n",
      "between both subsets help in a more robust evaluation of the\n",
      "classification models.\n",
      "\n",
      "A deep model requires many training samples to train the top\n",
      "layers of an already trained model or to train it from scratch.\n",
      "Thus, the ISL dataset’s size is increased to 63,188 and 240,716\n",
      "images for Numerals and Alphabets, respectively. The details of the\n",
      "operations like rotation, blurring, horizontal flipping and adding\n",
      "random noise to the ISL dataset’s original images for data aug-\n",
      "mentation are shown in Fig. 3.\n",
      "\n",
      "7. Evaluation metrics\n",
      "\n",
      "The following subsections describe the performance measures\n",
      "\n",
      "used for comprehensive analysis:\n",
      "\n",
      "7.1. Accuracy, Precision, Recall and F 1−Score\n",
      "\n",
      "For a supervised classification problem (SLR in this paper)\n",
      "on a balanced dataset, metrics such as accuracy, false negatives\n",
      "(FN) and false positives (FP) become very important for a robust\n",
      "performance comparison between two or more models. These\n",
      "metrics are mathematically defined in Eqs. (23) and (25) as −\n",
      "\n",
      "Accuracy =\n",
      "\n",
      "TP + TN\n",
      "TP + TN + FP + FN\n",
      "\n",
      ",\n",
      "\n",
      "Precision =\n",
      "\n",
      "TP\n",
      "TP + FP\n",
      "\n",
      "Recall =\n",
      "\n",
      "TP\n",
      "TP + FN\n",
      "\n",
      ",\n",
      "\n",
      "F 1 − Score = 2 ·\n",
      "\n",
      "( Recall · Precision\n",
      "Recall + Precision\n",
      "\n",
      "(22)\n",
      "\n",
      "(23)\n",
      "\n",
      "(24)\n",
      "\n",
      "(25)\n",
      "\n",
      ")\n",
      "\n",
      "where TP = True positive and TN = True negative\n",
      "\n",
      "7.2. Categorical cross entropy loss\n",
      "\n",
      "Cross entropy loss is a loss for binary classification problems\n",
      "\n",
      "and is defined in Eq. (26) as\n",
      "\n",
      "Cross entropy (CE) loss = −\n",
      "\n",
      "C\n",
      "∑\n",
      "\n",
      "i\n",
      "\n",
      "ti · log f (si)\n",
      "\n",
      "(26)\n",
      "\n",
      "where s is the CNN score for each class i in C , f (si) represents\n",
      "activations: sigmoid or softmax and t is the ground truth. The\n",
      "\n",
      "6\n",
      "\n",
      "Fig. 2. Numerals and Alphabets in ISL Dataset (1 − 9, A − Y except J and Z ).\n",
      "\n",
      "Fig. 3. Dataset Processing is shown in (a), (b) and (c). Dataset augmentation is\n",
      "shown in (d) Blur (Probability = 0.1), (e) Rotation (Prob. = 0.5, Max. right and\n",
      "left degree = 25), (f) Random Noise (Prob. = 0.5) and (g) Vertical Flip (Prob. =\n",
      "0.3).\n",
      "\n",
      "Fig. 4. Hand palm and fingers segmentation process. From Top left to right: Depth\n",
      "image, segmented hand region using depth thresholding, Gaussian blurring to\n",
      "find the point with maximum density of pixels, forming the axis of hand region,\n",
      "rotated hand in a standard direction, circle fitting to find the wrist points, From\n",
      "Bottom left to right: Dividing the image into four quadrants, increasing the radius\n",
      "of the circle till it intersects the hand region in 3rd and 4th quadrants, wrist\n",
      "points, joining the wrist points, and removing the forearm.\n",
      "\n",
      "15 users are available online. Ansari and Harit captured both\n",
      "the RGB and depth data for the ISL dataset using Microsoft’s\n",
      "KinectV2 camera in a uniform background allowing only a single\n",
      "user at a time in the frame. Ansari and Harit also did not limit the\n",
      "users of wearing any wearable during the signing and assumed\n",
      "that the hand is the closest object to the camera. This work\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "Fig. 5. Performance comparison of batch sizes on numerals using InceptionV3 model. (a) Validation loss evolution, and (b) training time.\n",
      "\n",
      "classification of more than two classes uses categorical CE loss\n",
      "that is a combination of softmax activation and CE loss. Softmax\n",
      "activation function is given in Eq. (27) as\n",
      "\n",
      "6.1 compute capability and memory limit of 268 MB and 10 GB\n",
      "on CPU and GPU, respectively. The subsections from 8.1 to 8.5 dis-\n",
      "cuss the result of the experiments, and Section 8.6 compares the\n",
      "results of the present work with the state-of-the-art approaches.\n",
      "\n",
      "f (si) =\n",
      "\n",
      "esi\n",
      "∑C\n",
      "j esj\n",
      "\n",
      "(27)\n",
      "\n",
      "8.1. Impact of batch size\n",
      "\n",
      "where sj is the net of scores of each class i in C . This equation\n",
      "shows that softmax activation of a class si depends on all CNN\n",
      "scores in s. Categorical CE loss can be obtained by combining\n",
      "Eqs. (26) and (27) in Eq. (28) as −\n",
      "\n",
      "Categorical cross entropy (CCE) loss = − log\n",
      "\n",
      ")\n",
      "\n",
      "(\n",
      "\n",
      "esp\n",
      "∑C\n",
      "j esj\n",
      "\n",
      "(28)\n",
      "\n",
      "where sp is the CNN score for positive class because labels are\n",
      "one-hot, so the target vector t = tp represents only one non-zero\n",
      "element of the target vector.\n",
      "\n",
      "7.3. Coefficient of variation (CV)\n",
      "\n",
      "CV is a statistical method for calculating and comparing the\n",
      "data samples’ spread or variance in different datasets around\n",
      "the mean even when the means are very distinct from each\n",
      "other. This paper uses CV to compare the performance stability\n",
      "of different combinations of deep models, optimizers and hy-\n",
      "perparameters by calculating the spread of their training and\n",
      "validation loss evolution throughout the epochs. Mathematically,\n",
      "it is written as shown below in Eq. (29) [52].\n",
      "\n",
      "√\n",
      "\n",
      "1\n",
      "N\n",
      "\n",
      "∑N\n",
      "\n",
      "i=1(xi − µ)2\n",
      "µ\n",
      "\n",
      "CV =\n",
      "\n",
      "(29)\n",
      "\n",
      "where numerator is the standard deviation with N = number of\n",
      "data samples, xi = data sample at ith location in a dataset and\n",
      "µ = mean\n",
      "\n",
      "8. Experimental details and results\n",
      "\n",
      "The experiments divide each augmented group − numerals\n",
      "and alphabets into train and validation set in the ratio of 75% :\n",
      "25%. The user’s sample image of an Indian sign is either placed\n",
      "in a validation or train set, but not in both. The input image’s\n",
      "size is 224 × 224, and the number of epochs is 100 for the\n",
      "training process. The experiments for comprehensive analysis\n",
      "follow the steps as explained in Section 2 with, first, tuning the\n",
      "batch size followed by optimizing the models and tuning the hy-\n",
      "perparameters on numerals and, last, evaluating the recognition\n",
      "performance of optimized deep models on both numerals and\n",
      "alphabets of the ISL dataset. This work does not include those\n",
      "results in which a model stops learning any new knowledge with\n",
      "very high error values. The hardware used for the implementation\n",
      "of the comprehensive analysis is Nvidia GeForce GTX 1080Ti with\n",
      "\n",
      "This subsection analyzes the impact of batch size on the recog-\n",
      "nition performance of InceptionV3 on the Numerals subset of the\n",
      "ISL dataset by fixing the other hyperparameters, such as learning\n",
      "rate 1e − 5 is used with Adam optimizer. According to exper-\n",
      "imental results, batch size 8 achieved the highest recognition\n",
      "accuracy of 83.8% on Numerals subset. This result indicates that\n",
      "the selection of smaller batch size is a valuable heuristic towards\n",
      "good optimization. However, convergence speed and the frequent\n",
      "variation of validation loss values throughout the training process\n",
      "increases with increasing batch size leading to an increase in\n",
      "the final loss value, as shown in Fig. 5. Batch size 8 performed\n",
      "better than others due to noisy gradients in small batch size,\n",
      "which prevents the model from being trapped in sharp mini-\n",
      "mizers and encourage it to move forward towards more flatter\n",
      "minimizers [53]. That is how the small batch size helps the model\n",
      "to reach global minima smoothly. The subsequent experiments of\n",
      "optimizing deep models and tuning other hyperparameters use\n",
      "batch size 8 for the training process.\n",
      "\n",
      "8.2. Tuning of SGD optimizer’s hyperparameters\n",
      "\n",
      "This work analyzes SGD optimizer’s performance utilizing a\n",
      "range of learning rates - 1e − 1 : 1e − 1 : 1e − 5 with and\n",
      "without momentum values - 0.5, 0.6 and NAG using InceptionV3\n",
      "on the ISL dataset’s Numerals subset. Although, through experi-\n",
      "ments, SGD with momentum and NAG show promising results\n",
      "for learning rates 1e − 4 and 1e − 5, the highest recognition\n",
      "accuracy of 82.5% is achieved with learning rate 1e − 3 and when\n",
      "SGD uses momentum 0.5 without NAG. SGD with M=0.9 and NAG\n",
      "using learning rate 1e− 4 also attained almost similar recognition\n",
      "accuracy of 81.8%. Fig. 6 shows that the learning rate lower than\n",
      "1e − 3 degrades the model’s performance when SGD uses only\n",
      "the momentum and the learning rate higher than 1e − 3 stops\n",
      "the model’s learning with both momentum and NAG. For lower\n",
      "learning rates, momentum and NAG help by speeding the training\n",
      "process by helping it to pass through the right path, thereby\n",
      "leading fastly to the convergence point. For higher learning rates,\n",
      "momentum and NAG do not help much as a high learning rate\n",
      "itself speeds up the process of convergence but usually on the\n",
      "wrong path. These insights are also reflected in the experimental\n",
      "results. Table 2 shows the metrics like loss, recall, precision, f1-\n",
      "score, CV and percentage of errors in the validation set for all the\n",
      "learning rates using SGD with and without momentum and NAG.\n",
      "These results SGD uses the selected hyperparameter’s setting to\n",
      "compare its performance with other optimizers in the subsequent\n",
      "subsections.\n",
      "\n",
      "7\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "Fig. 6. Tuning of learning rate, momentum and NAG for SGD optimizer. (a)–(d) Validation loss evolution for learning rates 1e − 2 − 1e − 5.\n",
      "\n",
      "Table 2\n",
      "Evaluation metrics for tuning of SGD Optimizer’s hyperparameters.\n",
      "\n",
      "LR, M (N)\n",
      "\n",
      "Train\n",
      "loss\n",
      "\n",
      "CV for\n",
      "train (CVT)\n",
      "\n",
      "1e − 2, 0.0 (×)\n",
      "1e − 3, 0.5 (×)\n",
      "1e − 4, 0.9 (✓)\n",
      "1e − 5, 0.9 (✓)\n",
      "\n",
      "0.12\n",
      "0.05\n",
      "0.06\n",
      "0.20\n",
      "\n",
      "0.73\n",
      "0.94\n",
      "0.33\n",
      "0.60\n",
      "\n",
      "Val\n",
      "loss\n",
      "\n",
      "0.81\n",
      "0.57\n",
      "0.59\n",
      "1.05\n",
      "\n",
      "CV for\n",
      "Val (CVV)\n",
      "\n",
      "Train\n",
      "acc (%)\n",
      "\n",
      "Val\n",
      "acc (%)\n",
      "\n",
      "Precision\n",
      "\n",
      "Recall\n",
      "\n",
      "f1-score\n",
      "\n",
      "Val\n",
      "errors (%)\n",
      "\n",
      "0.24\n",
      "0.33\n",
      "0.32\n",
      "0.21\n",
      "\n",
      "95.9\n",
      "98.1\n",
      "98.1\n",
      "93.3\n",
      "\n",
      "77.2\n",
      "82.5\n",
      "81.8\n",
      "65.6\n",
      "\n",
      "0.79\n",
      "0.83\n",
      "0.82\n",
      "0.68\n",
      "\n",
      "0.77\n",
      "0.82\n",
      "0.82\n",
      "0.66\n",
      "\n",
      "0.77\n",
      "0.83\n",
      "0.82\n",
      "0.66\n",
      "\n",
      "22.7\n",
      "17.7\n",
      "18.2\n",
      "34.3\n",
      "\n",
      "Note: LR is learning rate, M is momentum, N is NAG.\n",
      "\n",
      "8.3. Tuning of learning rate for adaptive optimizers\n",
      "\n",
      "The comparative evaluation and tuning of adaptive optimizers\n",
      "uses InceptionV3 model, batch size 8, learning rates - 1e − 1 :\n",
      "1e − 1 : 1e − 5 as used in Section 8.2 and the Numerals subset of\n",
      "the dataset.\n",
      "\n",
      "Fig. 7(a,b) shows the performance results of AdaDelta on ISL\n",
      "dataset’s Numerals with various learning rates. The learning rate\n",
      "1e − 1 suffers from increasing validation loss evolution with\n",
      "frequent ups and downs, i.e., high CVV, because high learning\n",
      "rates try to converge faster and get stuck in the local minima\n",
      "before reaching the desired global minima. The lower learning\n",
      "rates 1e − 4 and 1e − 5 converges very slow as observed from\n",
      "Fig. 7(a). The experimental results show that the learning rate\n",
      "1e − 2 performs better than the other learning rate values.\n",
      "\n",
      "In AdaGrad, if the initial gradients are large, the learning rate\n",
      "becomes low (Eq. (9)), which makes it difficult for the model\n",
      "to learn new knowledge as given in Section 5.2. According to\n",
      "experiments, the model stops learning with learning rates 1e − 1\n",
      "and 1e − 2 and the learning rate 1e − 3 achieves relatively\n",
      "better recognition performance compared to other learning rates.\n",
      "However, the convergence speed becomes too slow for all the re-\n",
      "maining learning rates, indicating no learning of new knowledge\n",
      "and thus, it seems almost saturated as observed from Fig. 7(b).\n",
      "\n",
      "Experimental results for Adam show that the model stops\n",
      "learning with learning rates 1e − 1, 1e − 2 and 1e − 3. Out of\n",
      "learning rates 1e − 4 and 1e − 5, 1e − 4 takes more time to train\n",
      "and has more frequent validation loss variations ,i.e. high CVV\n",
      "\n",
      "than 1e − 5 as shown in Fig. 7(c). Thus, learning rate 1e − 5 gives\n",
      "better results than the other learning rates for Adam optimizer.\n",
      "For RMSProp, the model stops learning with learning rates\n",
      "1e − 1, 1e − 2 and 1e − 3, and 1e − 5 results in better performance\n",
      "than 1e − 4 similar to Adam on Numerals subset. The RMSProp’s\n",
      "validation loss evolution for different learning rates is shown in\n",
      "Fig. 7(d).\n",
      "\n",
      "Thus, based on experimental results, AdaDelta uses learning\n",
      "rate 1e − 2, AdaGrad 1e − 3, Adam 1e − 5 and RMSProp 1e − 5 for\n",
      "further evaluation of optimizers in the next subsection. Mostly,\n",
      "lower learning rates perform better than the higher learning\n",
      "rates. In almost all the cases in the paper, model has either\n",
      "stopped working on higher learning over 1e−3 or have given low\n",
      "recognition performance and the reverse is true for the remaining\n",
      "learning rates. However, the reason why some learning rates,\n",
      "among the remaining ones, work well on the current application\n",
      "and why some do not is based on trial and error.\n",
      "\n",
      "8.4. Performance evaluation of tuned optimizers\n",
      "\n",
      "This subsection compares the tuned optimizers, and although\n",
      "the experimental results show that Adam takes more time to train\n",
      "than other optimizers, it also achieves the highest recognition\n",
      "accuracy of 83.79% on ISL’s Numerals subset. The performance\n",
      "of SGD is very close to Adam’s and also has the fastest training\n",
      "process. AdaDelta, AdaGrad and RMSProp follow Adam and SGD\n",
      "in recognition performance, with RMSProp attaining the least\n",
      "performance with the second-highest training time after Adam.\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "Fig. 7. Tuning of learning rate for adaptive optimizers. (a)–(d) Validation loss evolution.\n",
      "\n",
      "Table 3\n",
      "Evaluation metrics for tuned optimizers’ comparison.\n",
      "\n",
      "Optimizer\n",
      "\n",
      "Train\n",
      "loss\n",
      "\n",
      "CV for\n",
      "train (CVT)\n",
      "\n",
      "SGD\n",
      "AdaGrad\n",
      "AdaDelta\n",
      "RMSProp\n",
      "Adam\n",
      "\n",
      "0.05\n",
      "0.11\n",
      "0.07\n",
      "0.20\n",
      "0.04\n",
      "\n",
      "0.94\n",
      "3.47\n",
      "0.87\n",
      "0.44\n",
      "1.07\n",
      "\n",
      "Val\n",
      "loss\n",
      "\n",
      "0.57\n",
      "0.76\n",
      "0.81\n",
      "1.76\n",
      "0.60\n",
      "\n",
      "CV for\n",
      "val (CVV)\n",
      "\n",
      "Train\n",
      "acc (%)\n",
      "\n",
      "Val\n",
      "acc (%)\n",
      "\n",
      "Precision\n",
      "\n",
      "Recall\n",
      "\n",
      "f1-score\n",
      "\n",
      "Val\n",
      "errors (%)\n",
      "\n",
      "Train\n",
      "time (s)\n",
      "\n",
      "0.33\n",
      "1.75\n",
      "0.24\n",
      "0.08\n",
      "0.31\n",
      "\n",
      "98.1\n",
      "96.5\n",
      "97.9\n",
      "95.8\n",
      "98.5\n",
      "\n",
      "82.5\n",
      "74.9\n",
      "81.8\n",
      "74.0\n",
      "83.8\n",
      "\n",
      "0.83\n",
      "0.76\n",
      "0.82\n",
      "0.76\n",
      "0.84\n",
      "\n",
      "0.82\n",
      "0.75\n",
      "0.82\n",
      "0.74\n",
      "0.83\n",
      "\n",
      "0.83\n",
      "0.75\n",
      "0.82\n",
      "0.74\n",
      "0.83\n",
      "\n",
      "17.7\n",
      "24.8\n",
      "18.3\n",
      "25.8\n",
      "16.4\n",
      "\n",
      "246\n",
      "288\n",
      "380\n",
      "456\n",
      "470\n",
      "\n",
      "Table 4\n",
      "Evaluation metrics for CNN models.\n",
      "\n",
      "Deep models\n",
      "\n",
      "Train\n",
      "loss\n",
      "\n",
      "CV train\n",
      "(CVT)\n",
      "\n",
      "Val\n",
      "loss\n",
      "\n",
      "CV val\n",
      "(CVV)\n",
      "\n",
      "Train\n",
      "acc (%)\n",
      "\n",
      "Val\n",
      "acc (%)\n",
      "\n",
      "Precision\n",
      "\n",
      "Recall\n",
      "\n",
      "f1-\n",
      "score\n",
      "\n",
      "Val\n",
      "errors (%)\n",
      "\n",
      "Train\n",
      "time (s)\n",
      "\n",
      "Numerals\n",
      "InceptionV3\n",
      "ResNet152V2\n",
      "InceptionResNetV2\n",
      "ResNeXt101\n",
      "CNN\n",
      "\n",
      "Alphabets\n",
      "InceptionV3\n",
      "ResNet152V2\n",
      "InceptionResNetV2\n",
      "ResNeXt101\n",
      "CNN\n",
      "\n",
      "0.04\n",
      "0.01\n",
      "0.02\n",
      "0.02\n",
      "0.01\n",
      "\n",
      "0.14\n",
      "0.02\n",
      "0.05\n",
      "0.07\n",
      "0.07\n",
      "\n",
      "1.60\n",
      "1.53\n",
      "2.67\n",
      "0.31\n",
      "0.50\n",
      "\n",
      "1.13\n",
      "1.01\n",
      "1.94\n",
      "0.19\n",
      "0.33\n",
      "\n",
      "0.60\n",
      "0.21\n",
      "0.19\n",
      "0.37\n",
      "0.01\n",
      "\n",
      "1.21\n",
      "0.58\n",
      "0.57\n",
      "0.79\n",
      "0.12\n",
      "\n",
      "0.50\n",
      "0.35\n",
      "0.33\n",
      "0.35\n",
      "1.93\n",
      "\n",
      "0.32\n",
      "0.22\n",
      "0.17\n",
      "0.22\n",
      "1.17\n",
      "\n",
      "98.5\n",
      "99.9\n",
      "99.5\n",
      "99.4\n",
      "99.8\n",
      "\n",
      "95.5\n",
      "99.5\n",
      "98.3\n",
      "97.9\n",
      "97.9\n",
      "\n",
      "83.8\n",
      "96.2\n",
      "94.4\n",
      "91.5\n",
      "99.8\n",
      "\n",
      "71.1\n",
      "90.8\n",
      "85.6\n",
      "83.00\n",
      "97.0\n",
      "\n",
      "0.84\n",
      "0.96\n",
      "0.95\n",
      "0.92\n",
      "1.00\n",
      "\n",
      "0.72\n",
      "0.91\n",
      "0.86\n",
      "0.83\n",
      "0.97\n",
      "\n",
      "0.83\n",
      "0.96\n",
      "0.94\n",
      "0.92\n",
      "1.00\n",
      "\n",
      "0.71\n",
      "0.91\n",
      "0.86\n",
      "0.83\n",
      "0.97\n",
      "\n",
      "0.83\n",
      "0.96\n",
      "0.95\n",
      "0.92\n",
      "1.00\n",
      "\n",
      "0.71\n",
      "0.91\n",
      "0.86\n",
      "0.83\n",
      "0.97\n",
      "\n",
      "16.4\n",
      "4.1\n",
      "5.6\n",
      "8.7\n",
      "0.2\n",
      "\n",
      "28.8\n",
      "9.2\n",
      "14.3\n",
      "17.2\n",
      "3.0\n",
      "\n",
      "470\n",
      "665\n",
      "501\n",
      "1215\n",
      "226\n",
      "\n",
      "801\n",
      "1536\n",
      "1253\n",
      "2956\n",
      "568\n",
      "\n",
      "Table 3 shows the metrics that evaluate the tuned optimizers.\n",
      "The reason of these results is well presented in Section 5. The fol-\n",
      "lowing subsection uses Adam optimizer for further deep models’\n",
      "comparison.\n",
      "\n",
      "8.5. Performance evaluation of CNN models\n",
      "\n",
      "The comparative evaluation shows that among pre-trained\n",
      "deep models, ResNet152V2 performs better than other mod-\n",
      "els with a recognition accuracy of 96.18% and 90.84% on the\n",
      "ISL dataset’s Numerals and Alphabets subsets, respectively. The\n",
      "performance of InceptionResNetV2 is closer to ResNet152V2 on\n",
      "both the Numerals and Alphabets but has the frequently changing\n",
      "\n",
      "validation loss values over 100 epochs leading to increased CVV,\n",
      "as shown in Table 4. Although InceptionV3 takes less time to\n",
      "train, it shows the least performance on both the ISL dataset\n",
      "subsets. ResNeXt101 performs better than InceptionV3 but not\n",
      "better than the other pre-trained deep models. These results\n",
      "show that pure resnet work well in the SLR application due to\n",
      "concept of skip connections that tackles the vanishing gradient\n",
      "problem and make the model more robust to many layers. The\n",
      "designing and training of a model from scratch has to go through\n",
      "several trials to decide the number of CNN layers, regularization\n",
      "techniques, and structural parameters, e.g., hidden units and pool\n",
      "size. Thus, if there are limitations on computational resources\n",
      "and decision-making time, the models already trained on the\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "Fig. 8. Training and validation loss evolution for pre-trained and the proposed CNN models. Left: For numerals and Right: For alphabets of ISL dataset.\n",
      "\n",
      "Table 5\n",
      "Comparison with state-of-the-art approaches.\n",
      "\n",
      "Models/References\n",
      "\n",
      "[51]\n",
      "[54]\n",
      "InceptionV3\n",
      "ResNet152V2\n",
      "InceptionResNetV2\n",
      "ResNeXt101\n",
      "Proposed CNN\n",
      "\n",
      "Accuracy (%)\n",
      "(numerals)\n",
      "\n",
      "72.07\n",
      "68.8\n",
      "83.79\n",
      "96.18\n",
      "94.42\n",
      "91.46\n",
      "99.76\n",
      "\n",
      "Accuracy (%)\n",
      "(alphabets)\n",
      "\n",
      "57.03 (55.11a)\n",
      "78.67a\n",
      "71.09 (71.12a)\n",
      "90.84 (91.22a)\n",
      "85.65 (85.8a)\n",
      "83.04 (83.16a)\n",
      "97 (96.74)a\n",
      "\n",
      "a18 Alphabets (A − S excluding J).\n",
      "\n",
      "ImageNet dataset yield good results for static Indian SLR without\n",
      "training the whole model. However, the ImageNet is a generic\n",
      "object recognition dataset different from a sign language dataset,\n",
      "and thus, the CNN’s lower layers help the model learn the features\n",
      "of the new data rather than the higher layers. The proposed\n",
      "three-layered CNN model outperformed the pre-trained models\n",
      "with a recognition accuracy of 99.76% on Numerals and 97.00% on\n",
      "Alphabets subset of the ISL dataset. This result shows that training\n",
      "even a small CNN model from scratch on the new dataset can\n",
      "prove better than the transfer learning technique when the pre-\n",
      "trained models have been trained on a different dataset than the\n",
      "dataset at hand. Training the small CNN model from scratch is\n",
      "also faster than fine-tuning the pre-trained models. Thus, it seems\n",
      "that pre-trained models are not able to adapt the sign language\n",
      "datasets properly, which can be seen from the frequent variations\n",
      "in the test loss evolution of the pre-trained models compared\n",
      "to the proposed CNN model in Fig. 8. Fig. 8 shows the training\n",
      "and validation loss evolution, and Table 4 gives the metrics, such\n",
      "as training time, validation errors, f1-score, CVV, loss, recall and\n",
      "precision, to evaluate the deep models. The confusion matrices of\n",
      "the deep models are given in Fig. 9 for Numerals and in Fig. 10 for\n",
      "Alphabets subset.\n",
      "\n",
      "8.6. Performance comparison of proposed work with state-of-the-art\n",
      "\n",
      "Raghuveera et al. [54] and the developers [51] of the ISL\n",
      "dataset extracted the hand-crafted features from the input images\n",
      "and classified them using machine learning algorithms. The pro-\n",
      "posed three-layered CNN model outperforms the work of Ansari\n",
      "and Harit [51] by 38.4% and 70.1% on Numerals and Alphabets\n",
      "subset, respectively. Raghuveera et al. [54] worked on both the\n",
      "subsets of the ISL dataset and showed the recognition accuracy\n",
      "on all numerals but only on 18 alphabets. Thus, the average\n",
      "recognition accuracy of both 18 and 24 alphabets is shown in\n",
      "Table 5 for a fair comparison with literature. The proposed CNN\n",
      "model outperforms the work of Raghuveera et al. [54] by 45%\n",
      "on Numerals and 23% on 18 alphabets of the ISL dataset. Among\n",
      "the already trained deep models, ResNet152V2 outperforms the\n",
      "\n",
      "Fig. 9. Confusion matrix for deep models on ISL Dataset’s numerals.\n",
      "\n",
      "work of Ansari and Harit [51] and Raghuveera et al. [54] by 33.4%\n",
      "and 39.8% on Numerals and by 45.6% and 5.7% on Alphabets of\n",
      "the ISL dataset, respectively as shown in Table 5. These results\n",
      "show that the features extracted using the proposed CNN model\n",
      "and the other pre-trained deep models are highly efficient and\n",
      "informative than the hand-crafted features. Selection of the right\n",
      "optimizer and tuning of hyperparameters also helps in highly\n",
      "improving the deep models’ recognition performance.\n",
      "\n",
      "9. Conclusion\n",
      "\n",
      "This manuscript presents the first comprehensive evaluation\n",
      "of a proposed three-layered CNN architecture, four popular pre-\n",
      "trained deep models, gradient-based optimizers and optimization\n",
      "hyperparameters for static ISL recognition, to the best of our\n",
      "knowledge. The comparative analysis is motivated by the prolif-\n",
      "eration and, thus, lack of systematic comparative evaluation of\n",
      "pre-trained deep architectures, trained on ImageNet dataset, with\n",
      "their hyperparameters. This paper’s deep models are inceptions,\n",
      "resnets, and variants, and a small three-layered CNN model is\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "Fig. 10. Confusion matrix for deep models on ISL Dataset’s alphabets.\n",
      "\n",
      "trained from scratch. The performance evaluation reports metrics\n",
      "such as accuracy, loss, precision, recall, f 1−score and coefficient\n",
      "of variation for each model run. The proposed CNN model trained\n",
      "from scratch and ResNet152V2 achieves the highest recognition\n",
      "performance on the ISL dataset’s Numerals and Alphabets through\n",
      "experimental results. All the deep models highly outperform the\n",
      "state-of-the-art machine learning techniques and hand−crafted\n",
      "features. This comparative analysis can be used as a reference\n",
      "for researchers to select the suitable deep model, optimizer and\n",
      "hyperparameters for the static ISL recognition.\n",
      "\n",
      "CRediT authorship contribution statement\n",
      "\n",
      "Prachi Sharma: Conceptualization, Methodology, Software,\n",
      "Data curation, Writing - original draft, Visualization, Investiga-\n",
      "tion, Validation. Radhey Shyam Anand: Supervision, Writing -\n",
      "review & editing.\n",
      "\n",
      "[4] Dahmani D, Larabi S. User-independent system for sign language finger\n",
      "spelling recognition. J Vis Commun Image Represent 2014;25(5):1240–50.\n",
      "http://dx.doi.org/10.1016/j.jvcir.2013.12.019.\n",
      "\n",
      "[5] Fagiani M, Principi E, Squartini S, Piazza F. Signer independent isolated\n",
      "Italian sign recognition based on hidden Markov models. Pattern Anal Appl\n",
      "2015;18(2):385–402. http://dx.doi.org/10.1007/s10044-014-0400-z.\n",
      "\n",
      "[6] Roy PP, Kumar P, Kim B-G. An efficient sign language recognition (SLR)\n",
      "system using camshift tracker and hidden Markov model (HMM). SN\n",
      "Comput Sci 2021;2(2):1–15.\n",
      "\n",
      "[7] Fukushima K. Neocognitron: A self-organizing neural network model for\n",
      "a mechanism of pattern recognition unaffected by shift in position. Biol\n",
      "Cybernet 1980;36(4):193–202. http://dx.doi.org/10.1007/BF00344251.\n",
      "[8] Rastgoo R, Kiani K, Escalera S. Real-time isolated hand sign language\n",
      "J Ambient Intell Humaniz\n",
      "\n",
      "recognition using deep networks and SVD.\n",
      "Comput 2021;1–21.\n",
      "\n",
      "[9] Ben Slimane F, Bouguessa M. Context Matters: Self-Attention for Sign\n",
      "\n",
      "Language Recognition. 2021, arXiv e-prints arXiv–2101.\n",
      "\n",
      "[10] Sharma P, Anand RS. Depth data and fusion of feature descriptors for\n",
      "IET Image Process 2020;14(5):909–20. http:\n",
      "\n",
      "static gesture recognition.\n",
      "//dx.doi.org/10.1049/iet-ipr.2019.0230.\n",
      "Jiang S, Sun B, Wang L, Bai Y, Li K, Fu Y. Skeleton aware multi-modal sign\n",
      "language recognition. 2021, arXiv preprint arXiv:2103.08833.\n",
      "\n",
      "Declaration of competing interest\n",
      "\n",
      "[11]\n",
      "\n",
      "The authors declare that they have no known competing finan-\n",
      "cial interests or personal relationships that could have appeared\n",
      "to influence the work reported in this paper.\n",
      "\n",
      "Acknowledgments\n",
      "\n",
      "The authors are thankful to the Ministry of Education (MoE),\n",
      "earlier Ministry of Human Resource Development (MHRD), under\n",
      "the Government of India for financial support in pursuing the\n",
      "proposed work.\n",
      "\n",
      "References\n",
      "\n",
      "[1] Card SK, Moran TP, Newwell A. The psychology of human-computer\n",
      "\n",
      "interaction. Hillsdale, NJ: Lawrence Erlbaum Associates; 1983.\n",
      "\n",
      "[2] Li Y, Chen X, Zhang X, Wang K, Wang ZJ. A sign-component-based\n",
      "framework for Chinese sign language recognition using accelerometer and\n",
      "sEMG data. IEEE Trans Biomed Eng 2012;59(10):2695–704. http://dx.doi.\n",
      "org/10.1109/TBME.2012.2190734.\n",
      "\n",
      "[3] Yang H-D, Lee S-W. Robust sign language recognition by combining manual\n",
      "and non-manual features based on conditional random field and support\n",
      "vector machine. Pattern Recognit Lett 2013;34(16):2051–6. http://dx.doi.\n",
      "org/10.1016/j.patrec.2013.06.022.\n",
      "\n",
      "[12] Kumar P, Saini R, Roy PP, Dogra DP. A position and rotation invariant\n",
      "framework for sign language recognition (SLR) using Kinect. Multimedia\n",
      "Tools Appl 2018;77(7):8823–46.\n",
      "Jebali M, Dakhli A,\n",
      "recognition using multimodal sensor fusion. Evol Syst 2021;1–14.\n",
      "\n",
      "Jemni M. Vision-based continuous sign language\n",
      "\n",
      "[13]\n",
      "\n",
      "[14] Abiyev RH, Arslan M,\n",
      "\n",
      "Idoko JB. Sign language translation using deep\n",
      "convolutional neural networks. KSII Trans Internet Inf Syst 2020;14(2).\n",
      "http://dx.doi.org/10.3837/tiis.2020.02.009.\n",
      "\n",
      "[15] Szegedy C, Vanhoucke V,\n",
      "\n",
      "Ioffe S, Shlens J, Wojna Z. Rethinking the\n",
      "inception architecture for computer vision. In: Proceedings of the IEEE\n",
      "conference on computer vision and pattern recognition. 2016, p. 2818–26.\n",
      "http://dx.doi.org/10.1109/CVPR.2016.308.\n",
      "\n",
      "[16] Wu D, Pigou L, Kindermans P-J, Le ND-H, Shao L, Dambre J, et al.\n",
      "Deep dynamic neural networks for multimodal gesture segmentation and\n",
      "recognition. IEEE Trans Pattern Anal Mach Intell 2016;38(8):1583–97. http:\n",
      "//dx.doi.org/10.1109/TPAMI.2016.2537340.\n",
      "\n",
      "[17] Duan J, Wan J, Zhou S, Guo X, Li SZ. A unified framework for multi-modal\n",
      "isolated gesture recognition. ACM Trans Multimed Comput Commun Appl\n",
      "(TOMM) 2018;14(1s):1–16. http://dx.doi.org/10.1145/3131343.\n",
      "\n",
      "[18] Liao Y, Xiong P, Min W, Min W, Lu J. Dynamic sign language recognition\n",
      "based on video sequence with BLSTM-3D residual networks. IEEE Access\n",
      "2019;7:38044–54. http://dx.doi.org/10.1109/ACCESS.2019.2904749.\n",
      "\n",
      "[19] Koller O, Zargaran O, Ney H, Bowden R. Deep sign: Hybrid CNN-HMM\n",
      "for continuous sign language recognition. In: Proceedings of the British\n",
      "machine vision conference 2016. 2016.\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "P. Sharma and R.S. Anand\n",
      "\n",
      "Graphics and Visual Computing 5 (2021) 200032\n",
      "\n",
      "[20] Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, et al. Going deeper\n",
      "with convolutions. In: Proceedings of the IEEE conference on computer\n",
      "vision and pattern recognition. 2015, p. 1–9. http://dx.doi.org/10.1109/\n",
      "CVPR.2015.7298594.\n",
      "\n",
      "[21] Kumar P, Gauba H, Roy PP, Dogra DP. Coupled HMM-based multi-\n",
      "sensor data fusion for sign language recognition. Pattern Recognit Lett\n",
      "2017;86:1–8.\n",
      "\n",
      "[22] Rastgoo R, Kiani K, Escalera S. Multi-modal deep hand sign language\n",
      "recognition in still images using restricted Boltzmann machine. Entropy\n",
      "2018;20(11):809.\n",
      "\n",
      "[23] Liang Z-j, Liao S-b, Hu B-z. 3D convolutional neural networks for dynamic\n",
      "sign language recognition. Comput J 2018;61(11):1724–36. http://dx.doi.\n",
      "org/10.1093/comjnl/bxy049.\n",
      "\n",
      "[24] Ravi S, Suman M, Kishore P, Kumar K, Kumar A, et al. Multi modal spatio\n",
      "temporal co-trained CNNs with single modal testing on RGB–D based\n",
      "sign language gesture recognition. J. Computer Languages 2019;52:88–102.\n",
      "http://dx.doi.org/10.1016/j.cola.2019.04.002.\n",
      "\n",
      "[25] Pratt LY. Discriminability-based transfer between neural networks.\n",
      "In: Advances\n",
      "information processing systems. 1993. p.\n",
      "204–211 http://papers.nips.cc/paper/641-discriminability-based-transfer-\n",
      "between-neural-networks.pdf.\n",
      "\n",
      "in neural\n",
      "\n",
      "[26] Töngi R. Application of transfer learning to sign language recognition using\n",
      "an inflated 3D deep convolutional neural network. 2021, arXiv preprint\n",
      "arXiv:2103.05111.\n",
      "\n",
      "[27] Halvardsson G, Peterson J, Soto-Valero C, Baudry B.\n",
      "\n",
      "Interpretation of\n",
      "Swedish sign language using convolutional neural networks and transfer\n",
      "learning. SN Comput Sci 2021;2(3):1–15.\n",
      "\n",
      "[28] Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L. Imagenet: A large-scale\n",
      "hierarchical image database. In: 2009 IEEE conference on computer vision\n",
      "and pattern recognition. Ieee; 2009, p. 248–55. http://dx.doi.org/10.1109/\n",
      "CVPR.2009.5206848.\n",
      "[29] Krizhevsky A, Sutskever\n",
      "\n",
      "Imagenet classification with\n",
      "deep convolutional neural networks. In: Advances in neural information\n",
      "processing systems. 2012, p. 1097–105. http://dx.doi.org/10.1145/3065386.\n",
      "[30] Ozcan T, Basturk A. Transfer learning-based convolutional neural networks\n",
      "with heuristic optimization for hand gesture recognition. Neural Comput\n",
      "Appl 2019;31(12):8955–70. http://dx.doi.org/10.1007/s00521-019-04427-\n",
      "y.\n",
      "\n",
      "I, Hinton GE.\n",
      "\n",
      "[31] Wadhawan A, Kumar P. Deep learning-based sign language recognition\n",
      "system for static signs. Neural Comput Appl 2020;1–12. http://dx.doi.org/\n",
      "10.1007/s00521-019-04691-y.\n",
      "\n",
      "[35] Xie S, Girshick R, Dollár P, Tu Z, He K. Aggregated residual transformations\n",
      "for deep neural networks.\n",
      "In: Proceedings of the IEEE conference on\n",
      "computer vision and pattern recognition. 2017, p. 1492–500. http://dx.doi.\n",
      "org/10.1109/CVPR.2017.634.\n",
      "\n",
      "[36] He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition.\n",
      "In: Proceedings of the IEEE conference on computer vision and pattern\n",
      "recognition. 2016, p. 770–8. http://dx.doi.org/10.1109/CVPR.2016.90.\n",
      "[37] Sivaprasad PT, Mai F, Vogels T, Jaggi M, Fleuret F. Optimizer benchmarking\n",
      "needs to account for hyperparameter tuning. In: International conference\n",
      "on machine learning. PMLR; 2020, p. 9036–45.\n",
      "\n",
      "[38] Robbins H, Monro S. A stochastic approximation method. Ann Math Stat\n",
      "\n",
      "1951;400–7. http://dx.doi.org/10.1214/aoms/1177729586.\n",
      "\n",
      "[39] Kiefer J, Wolfowitz J, et al. Stochastic estimation of the maximum of a\n",
      "regression function. Ann Math Stat 1952;23(3):462–6. http://dx.doi.org/10.\n",
      "1214/aoms/1177729392.\n",
      "\n",
      "[40] Cauchy A. Méthode générale pour la résolution des systemes d’équations\n",
      "\n",
      "simultanées. C R Sci Paris 1847;25(1847):536–8.\n",
      "\n",
      "[41] Qian N. On the momentum term in gradient descent learning algo-\n",
      "rithms. Neural Netw 1999;12(1):145–51. http://dx.doi.org/10.1016/S0893-\n",
      "6080(98)00116-6.\n",
      "\n",
      "[42] Polyak BT. Some methods of speeding up the convergence of iteration\n",
      "methods. USSR Comput Math Math Phys 1964;4(5):1–17. http://dx.doi.org/\n",
      "10.1016/0041-5553(64)90137-5.\n",
      "\n",
      "[43] Nesterov Y. A method for unconstrained convex minimization problem\n",
      "with the rate of convergence O (1/k2). In: Doklady an Ussr, vol. 269. 1983.\n",
      "p. 543–547.\n",
      "\n",
      "[44] Sutskever I, Martens J, Dahl G, Hinton G. On the importance of initialization\n",
      "and momentum in deep learning. In: International conference on machine\n",
      "learning. 2013. p. 1139–1147.\n",
      "\n",
      "[45] Goodfellow I, Bengio Y, Courville A. Deep learning. MIT Press; 2016.\n",
      "[46] Duchi\n",
      "\n",
      "J, Hazan E, Singer Y. Adaptive subgradient methods for online\n",
      "learning and stochastic optimization. J Mach Learn Res 2011;12(Jul):2121–\n",
      "59.\n",
      "\n",
      "[47] Ruder S. An overview of gradient descent optimization algorithms. 2016,\n",
      "\n",
      "arXiv preprint arXiv:1609.04747.\n",
      "\n",
      "[48] Zeiler MD. Adadelta: An adaptive learning rate method. 2012, arXiv\n",
      "\n",
      "preprint arXiv:1212.5701.\n",
      "\n",
      "[49] Hinton G, Srivastava N, Swersky K. Neural networks for machine learning\n",
      "lecture 6a overview of mini-batch gradient descent. Cited on 2012;14(8).\n",
      "[50] Kingma DP, Ba J. Adam: A method for stochastic optimization. 2014, arXiv\n",
      "\n",
      "preprint arXiv:1412.6980.\n",
      "\n",
      "[32] Pinto RF, Borges CD, Almeida A, Paula IC. Static hand gesture recognition\n",
      "based on convolutional neural networks. J Electr Comput Eng 2019;2019.\n",
      "http://dx.doi.org/10.1155/2019/4167890.\n",
      "\n",
      "[51] Ansari ZA, Harit G. Nearest neighbour classification of Indian sign language\n",
      "gestures using kinect camera. Sadhana 2016;41(2):161–82. http://dx.doi.\n",
      "org/10.1007/s12046-015-0405-3.\n",
      "\n",
      "[33] He K, Zhang X, Ren S, Sun J. Identity mappings in deep residual networks.\n",
      "In: European conference on computer vision. Springer; 2016, p. 630–45.\n",
      "http://dx.doi.org/10.1007/978-3-319-46493-0_38.\n",
      "\n",
      "[34] Szegedy C, Ioffe S, Vanhoucke V, Alemi AA. Inception-v4, inception-resnet\n",
      "and the impact of residual connections on learning. In: Thirty-first AAAI\n",
      "conference on artificial intelligence. 2017.\n",
      "\n",
      "[52] Everitt B. The Cambridge dictionary of statistics. Cambridge, UK ; New\n",
      "\n",
      "York: Cambridge University Press; 1998, ISBN 9780521593465.\n",
      "\n",
      "[53] Keskar NS, Mudigere D, Nocedal J, Smelyanskiy M, Tang PTP. On large-\n",
      "batch training for deep learning: Generalization gap and sharp minima.\n",
      "2016, arXiv preprint arXiv:1609.04836.\n",
      "\n",
      "[54] Raghuveera T, Deepthi R, Mangalashri R, Akshaya R. A depth-based Indian\n",
      "Sign Language recognition using Microsoft Kinect. Sadhana 2020;45(1):34.\n",
      "http://dx.doi.org/10.1007/s12046-019-1250-6.\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "text = extract_text(\"/home/mahadevks1048/Desktop/Mahadev/1-s2.0-S2666629421000152-main.pdf\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d2ac7a-88d3-4d59-a178-3f5198716031",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.compile(r'\\w+')\n",
    "matches = match.findall(text)\n",
    "# matches_unique = list(set(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5064f1ef-e836-4ba8-afa5-bc14e5001d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'Contents', 'lists', 'available', 'at', 'ScienceDirect', 'Graphics', 'and', 'Visual', 'Computing', 'journal', 'homepage', 'www', 'elsevier', 'com', 'locate', 'gvc', 'Technical', 'section', 'A', 'comprehensive', 'evaluation', 'of', 'deep', 'models', 'and', 'optimizers', 'for', 'Indian', 'sign', 'language', 'recognition', 'Prachi', 'Sharma', 'Indian', 'Institute', 'of', 'Technology', 'Roorkee', 'India', 'Radhey', 'Shyam', 'Anand', 'a', 'r', 't', 'i', 'c', 'l', 'e', 'i', 'n', 'f', 'o', 'a', 'b', 's', 't', 'r', 'a', 'c', 't', 'Article', 'history', 'Received', '9', 'February', '2021', 'Received', 'in', 'revised', 'form', '12', 'June', '2021', 'Accepted', '28', 'July', '2021', 'Available', 'online', '4', 'August', '2021', 'Keywords', 'Sign', 'language', 'recognition', 'Deep', 'learning', 'Kinect', 'Convolution', 'neural', 'networks', 'Deep', 'Learning', 'has', 'become', 'popular', 'among', 'researchers', 'for', 'a', 'long', 'time', 'and', 'still', 'new', 'deep', 'convolution', 'neural', 'networks', 'come', 'into', 'the', 'picture', 'very', 'frequently', 'However', 'it', 'is', 'challenging', 'to', 'select', 'the', 'best', 'amongst', 'such', 'networks', 'due', 'to', 'their', 'dependence', 'on', 'the', 'tuning', 'of', 'optimization', 'hyperparameters', 'which', 'is', 'a', 'trivial', 'task', 'This', 'situation', 'motivates', 'the', 'current', 'study', 'in', 'which', 'we', 'perform', 'a', 'systematic', 'evaluation', 'and', 'statistical', 'analysis', 'of', 'pre', 'trained', 'deep', 'models', 'It', 'is', 'the', 'first', 'comprehensive', 'analysis', 'of', 'pre', 'trained', 'deep', 'models', 'gradient', 'based', 'optimizers', 'and', 'optimization', 'hyperparameters', 'for', 'static', 'Indian', 'sign', 'language', 'recognition', 'A', 'three', 'layered', 'CNN', 'model', 'is', 'also', 'proposed', 'and', 'trained', 'from', 'scratch', 'which', 'attained', 'the', 'best', 'recognition', 'accuracy', 'of', '99', '0', 'and', '97', '6', 'on', 'numerals', 'and', 'alphabets', 'of', 'a', 'public', 'ISL', 'dataset', 'Among', 'pre', 'trained', 'models', 'ResNet152V2', 'performed', 'better', 'than', 'other', 'models', 'with', 'a', 'recognition', 'accuracy', 'of', '96', '2', 'on', 'numerals', 'and', '90', '8', 'on', 'alphabets', 'of', 'the', 'ISL', 'dataset', 'Our', 'results', 'reinforce', 'the', 'hypothesis', 'for', 'pre', 'trained', 'deep', 'models', 'that', 'in', 'general', 'a', 'pre', 'trained', 'deep', 'network', 'adequately', 'tuned', 'can', 'yield', 'results', 'way', 'more', 'than', 'the', 'state', 'of', 'the', 'art', 'machine', 'learning', 'techniques', 'without', 'having', 'to', 'train', 'the', 'whole', 'model', 'but', 'only', 'a', 'few', 'top', 'layers', 'for', 'ISL', 'recognition', 'The', 'effect', 'of', 'hyperparameters', 'like', 'learning', 'rate', 'batch', 'size', 'and', 'momentum', 'is', 'also', 'analyzed', 'and', 'presented', 'in', 'the', 'paper', '2021', 'The', 'Authors', 'Published', 'by', 'Elsevier', 'Ltd', 'This', 'is', 'an', 'open', 'access', 'article', 'under', 'the', 'CC', 'BY', 'NC', 'ND', 'license', 'http', 'creativecommons', 'org', 'licenses', 'by', 'nc', 'nd', '4', '0', '1', 'Introduction', 'Human', 'computer', 'interface', 'HCI', '1', 'is', 'one', 'of', 'the', 'most', 'crucial', 'research', 'areas', 'due', 'to', 'its', 'benefit', 'to', 'society', 'and', 'advancement', 'in', 'technology', 'HCI', 'applies', 'to', 'every', 'sector', 'whether', 'healthcare', 'education', 'space', 'information', 'technology', 'consumer', 'discretionary', 'or', 'communication', 'services', 'Gesture', 'recognition', 'is', 'a', 'part', 'of', 'HCI', 'with', 'many', 'applications', 'Sign', 'language', 'recognition', 'SLR', 'is', 'a', 'gesture', 'recognition', 'application', 'that', 'helps', 'system', 'control', 'in', 'com', 'puters', 'and', 'phones', 'gaming', 'interface', 'image', 'scaling', 'controlling', 'machines', 'like', 'robots', 'and', 'TV', 'All', 'these', 'applications', 'work', 'on', 'image', 'or', 'video', 'processing', 'and', 'thus', 'require', 'a', 'lot', 'of', 'visual', 'computation', 'Deaf', 'communities', 'use', 'sign', 'language', 'as', 'a', 'communication', 'mode', 'within', 'their', 'community', 'and', 'outside', 'the', 'world', 'It', 'is', 'a', 'visual', 'language', 'that', 'uses', 'facial', 'body', 'and', 'hand', 'gestures', 'unlike', 'the', 'spoken', 'language', 'in', 'everyday', 'communication', 'Conversion', 'of', 'sign', 'language', 'into', 'speech', 'or', 'text', 'must', 'bridge', 'the', 'gap', 'between', 'the', 'deaf', 'and', 'hearing', 'world', 'The', 'usage', 'of', 'hand', 'crafted', 'features', 'and', 'machine', 'learning', 'ML', 'algorithms', 'have', 'been', 'extensive', 'since', 'This', 'article', 'was', 'recommended', 'for', 'publication', 'by', 'C', 'Sandor', 'Only', 'capitalize', 'first', 'word', 'and', 'proper', 'nouns', 'in', 'the', 'title', 'Corresponding', 'author', 'E', 'mail', 'addresses', 'psharma3', 'ee', 'iitr', 'ac', 'in', 'P', 'Sharma', 'r', 'anand', 'ee', 'iitr', 'ac', 'in', 'R', 'S', 'Anand', '1970s', 'for', 'gesture', 'recognition', 'particularly', 'SLR', '2', '6', 'Deep', 'learn', 'ing', 'DL', 'soon', 'replaced', 'the', 'manual', 'features', 'and', 'ML', 'algorithms', 'with', 'more', 'efficient', 'automatic', 'less', 'time', 'consuming', 'and', 'better', 'performing', 'feature', 'extraction', 'and', 'classification', 'techniques', 'like', 'convolution', 'neural', 'networks', 'CNNs', '6', '9', 'Researchers', 'also', 'use', 'multiple', 'data', 'types', 'such', 'as', 'RGB', '6', 'depth', '10', 'and', 'skeleton', '11', 'for', 'gesture', 'recognition', 'Depth', 'is', 'the', 'distance', 'of', 'the', 'object', 'from', 'the', 'camera', 'or', 'sensor', 'and', 'skeleton', 'data', 'consists', 'of', 'various', 'joint', 'locations', 'of', 'a', 'human', 'body', 'In', '2014', 'Microsoft', 'launched', 'KinectV2', '6', '12', '13', 'based', 'on', 'the', 'time', 'of', 'flight', 'principle', 'which', 'calculates', 'the', 'round', 'trip', 'time', 'of', 'a', 'light', 'signal', 'from', 'an', 'LED', 'or', 'laser', 'thereby', 'indicating', 'the', 'depth', 'This', 'camera', 'can', 'capture', 'all', 'three', 'data', 'types', 'making', 'it', 'popular', 'in', 'the', 'field', 'of', 'computer', 'vision', 'Many', 'works', 'are', 'reported', 'in', 'the', 'literature', 'on', 'sign', 'language', 'recognition', 'that', 'used', 'the', 'data', 'types', 'mentioned', 'above', 'and', 'CNN', 'and', 'thus', 'outperformed', 'the', 'state', 'of', 'the', 'art', 'ML', 'techniques', 'Abiyev', 'et', 'al', '14', 'extracted', 'the', 'features', 'using', 'pre', 'trained', 'deep', 'model', 'InceptionV3', '15', 'that', 'outperformed', 'the', 'hand', 'crafted', 'features', 'with', 'a', 'finger', 'spelling', 'recognition', 'accuracy', 'of', '99', '9', 'with', 'support', 'vector', 'machines', 'SVMs', 'as', 'a', 'classifier', 'Wu', 'et', 'al', '16', 'classified', 'the', 'gestures', 'of', 'ChaLearn', 'Looking', 'At', 'People', 'dataset', 'us', 'ing', '3D', 'CNN', 'with', 'RGB', 'depth', 'and', 'skeletal', 'data', 'and', 'outperformed', 'the', 'state', 'of', 'the', 'art', 'ML', 'algorithms', 'with', 'a', 'Jaccard', 'index', 'score', 'of', '0', '81', 'Duan', 'et', 'al', '17', 'used', 'a', 'two', 'stream', 'convolution', 'network', 'with', 'both', 'the', 'spatial', 'and', 'temporal', 'RGB', 'and', 'depth', 'data', 'and', 'https', 'doi', 'org', '10', '1016', 'j', 'gvc', '2021', '200032', '2666', '6294', '2021', 'The', 'Authors', 'Published', 'by', 'Elsevier', 'Ltd', 'This', 'is', 'an', 'open', 'access', 'article', 'under', 'the', 'CC', 'BY', 'NC', 'ND', 'license', 'http', 'creativecommons', 'org', 'licenses', 'by', 'nc', 'nd', '4', '0', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'achieved', 'an', 'accuracy', 'of', '67', '3', 'on', 'ChaLearn', 'LAP', 'isolated', 'gesture', 'dataset', 'more', 'than', 'the', 'state', 'of', 'the', 'art', 'ML', 'techniques', 'Liao', 'et', 'al', '18', 'used', 'a', 'bi', 'directional', 'long', 'short', 'term', 'memory', 'LSTM', '3D', 'CNN', 'residual', 'network', 'for', 'recognition', 'of', 'signs', 'in', 'two', 'Chinese', 'sign', 'language', 'datasets', 'with', 'recognition', 'accuracies', 'of', '89', '8', 'and', '86', '9', 'more', 'than', 'the', 'accuracy', 'achieved', 'with', 'existing', 'approaches', 'like', 'hidden', 'markov', 'models', 'HMMs', 'neural', 'networks', 'and', 'dy', 'namic', 'time', 'warping', 'The', 'works', 'on', 'combined', 'usage', 'of', 'ML', 'and', 'DL', 'algorithms', '14', 'are', 'also', 'reported', 'in', 'literature', 'such', 'as', 'Koller', 'et', 'al', '19', 'combined', 'GoogLeNet', 'architecture', '20', 'with', 'HMMs', '16', 'to', 'recognize', 'continuous', 'sign', 'language', 'and', 'improved', 'word', 'error', 'rate', 'on', 'three', 'public', 'sign', 'language', 'datasets', 'More', 'robust', 'gesture', 'recognition', 'systems', 'combined', 'multiple', 'data', 'streams', '13', '17', '21', '22', 'like', 'RGB', 'depth', 'and', 'skeleton', 'Liang', 'et', 'al', '23', 'used', '3D', 'CNN', 'with', 'two', 'sub', 'networks', 'i', 'infra', 'red', 'data', 'and', 'ii', 'contour', 'data', 'as', 'an', 'input', 'and', 'achieved', 'an', 'accuracy', 'of', '89', '2', 'on', 'sign', 'language', 'video', 'in', 'museums', 'dataset', 'and', '92', '4', 'on', 'ChaLearn', 'LAP', 'dataset', 'Ravi', 'et', 'al', '24', 'developed', 'a', 'four', 'stream', 'CNN', 'model', 'using', 'four', 'inputs', 'both', 'spatial', 'and', 'temporal', 'RGB', 'and', 'depth', 'data', 'and', 'achieved', 'an', 'accuracy', 'of', '86', '7', 'on', 'a', '3D', 'sign', 'language', 'dataset', 'Thus', 'a', 'CNN', 'deep', 'learning', 'model', 'highly', 'improves', 'a', 'recognition', 'system', 's', 'performance', 'whether', 'used', 'alone', 'or', 'in', 'combination', 'with', 'various', 'ML', 'techniques', 'or', 'multiple', 'modalities', 'Training', 'a', 'deep', 'model', 'from', 'scratch', 'takes', 'much', 'time', 'and', 'a', 'good', 'graphics', 'processing', 'unit', 'GPU', 'which', 'is', 'not', 'feasible', 'if', 'the', 'dataset', 'is', 'vast', 'or', 'for', 'the', 'applications', 'that', 'require', 'multiple', 'runs', 'of', 'a', 'model', 'for', 'optimization', 'or', 'analysis', 'Transfer', 'learning', '25', '27', 'solves', 'this', 'problem', 'by', 'transferring', 'the', 'knowledge', 'from', 'one', 'task', 'to', 'another', 'completely', 'in', 'the', 'form', 'of', 'weights', 'or', 'using', 'the', 'fine', 'tuning', 'technique', 'to', 'train', 'some', 'layers', 'of', 'the', 'trained', 'model', 'again', 'on', 'the', 'new', 'dataset', 'The', 'literature', 'consists', 'of', 'and', 'uses', 'CNN', 'models', 'already', 'trained', 'on', 'a', 'public', 'object', 'recognition', 'dataset', 'ImageNet', '28', 'like', 'AlexNet', '29', 'GoogleNet', '20', 'and', 'many', 'more', 'Transfer', 'learning', 'using', 'the', 'fine', 'tuning', 'technique', 'is', 'a', 'computa', 'tionally', 'efficient', 'and', 'less', 'time', 'consuming', 'process', 'that', 'can', 'be', 'run', 'even', 'on', 'a', 'CPU', 'Liang', 'et', 'al', '23', 'formed', 'two', 'models', 'using', '3D', 'CNN', 'one', 'model', 'trained', 'from', 'scratch', 'on', 'ChaLearn', 'LAP', 'dataset', 'achieved', 'an', 'accuracy', 'of', '92', '4', 'on', 'the', 'same', 'dataset', 'and', 'the', 'second', 'model', 'trained', 'on', 'another', 'gesture', 'dataset', 'and', 'finely', 'tuned', 'on', 'ChaLearn', 'LAP', 'dataset', 'achieved', 'an', 'accuracy', 'of', '96', '3', 'more', 'than', 'the', 'previous', 'case', 'Abiyev', 'et', 'al', '14', 'extracted', 'the', 'features', 'using', 'InceptionV3', 'and', 'classified', 'gestures', 'using', 'SVM', 'with', 'an', 'accuracy', 'of', '99', '9', 'which', 'is', 'more', 'than', 'the', 'accuracy', 'of', '92', '1', 'achieved', 'when', 'a', 'CNN', 'model', 'is', 'trained', 'from', 'scratch', 'on', 'the', 'same', 'dataset', 'The', 'results', 'show', 'that', 'transfer', 'learning', 'can', 'greatly', 'improve', 'the', 'performance', 'of', 'any', 'deep', 'model', 'for', 'SLR', 'The', 'researchers', 'explored', 'SLR', 'using', 'different', 'conventional', 'and', 'deep', 'learning', 'classification', 'techniques', 'however', 'none', 'of', 'them', 'simultaneously', 'analyzed', 'these', 'models', 'with', 'various', 'optimization', 'algorithms', 'and', 'hyperparameters', 'associated', 'with', 'them', 'Many', 'works', 'performed', 'evaluations', 'in', 'the', 'literature', 'with', 'either', 'a', 'fixed', 'model', '30', 'and', 'hyperparameters', '31', 'or', 'no', 'information', 'about', 'the', 'used', 'hyperparameters', 'and', 'optimizer', '32', 'Thus', 'based', 'on', 'literature', 'and', 'to', 'the', 'best', 'of', 'our', 'knowledge', 'there', 'is', 'no', 'com', 'prehensive', 'analysis', 'present', 'in', 'the', 'literature', 'evaluating', 'the', 'deep', 'models', 'optimizers', 'and', 'hyperparameters', 'simultaneously', 'Motivated', 'by', 'this', 'research', 'gap', 'the', 'proposed', 'work', 'discusses', 'the', 'evaluation', 'results', 'of', 'four', 'pre', 'trained', 'models', 'with', 'five', 'gradient', 'based', 'optimizers', 'and', 'their', 'associated', 'optimization', 'hy', 'perparameters', 'like', 'learning', 'rate', 'batch', 'size', 'and', 'momentum', 'A', 'three', 'layered', 'CNN', 'model', 'trained', 'from', 'scratch', 'is', 'also', 'proposed', 'that', 'performed', 'better', 'than', 'the', 'other', 'models', 'used', 'in', 'the', 'paper', 'for', 'ISL', 'recognition', 'Thus', 'this', 'comparative', 'analysis', 'gives', 'insights', 'into', 'selecting', 'the', 'suitable', 'deep', 'model', 'with', 'the', 'right', 'optimizer', 'and', 'its', 'hyperparameters', 'to', 'enhance', 'the', 'models', 'performance', 'for', 'static', 'ISL', 'recognition', 'The', 'paper', 'is', 'divided', 'into', 'sections', 'Section', '1', 'introduces', 'ad', 'vances', 'in', 'DL', 'and', 'transfer', 'learning', 'for', 'SLR', 'Section', '2', 'introduces', 'the', 'proposed', 'methodology', 'for', 'the', 'performance', 'evaluation', 'of', 'CNN', 'deep', 'models', 'with', 'various', 'optimizers', 'and', 'hyperparameters', 'The', 'CNN', 'architectures', 'optimization', 'hyperparameters', 'and', 'algo', 'rithms', 'used', 'in', 'the', 'paper', 'are', 'explained', 'in', 'Sections', '3', '4', 'and', '5', 'respectively', 'Section', '6', 'discusses', 'the', 'evaluation', 'metrics', 'dataset', 'and', 'its', 'pre', 'processing', 'for', 'analysis', 'of', 'results', 'in', 'Section', '7', 'Ex', 'perimental', 'results', 'are', 'thoroughly', 'discussed', 'in', 'Section', '8', 'with', 'conclusion', 'in', 'the', 'last', 'Section', '9', '2', 'Proposed', 'methodology', 'for', 'comparative', 'analysis', 'This', 'section', 'discusses', 'the', 'proposed', 'methodology', 'for', 'the', 'eval', 'uation', 'of', 'deep', 'models', 'optimizers', 'and', 'hyperparameters', 'Be', 'fore', 'the', 'performance', 'evaluation', 'the', 'depth', 'data', 'is', 'first', 'pro', 'cessed', 'through', 'depth', 'thresholding', 'to', 'get', 'the', 'hands', 'from', 'the', 'data', 'Secondly', 'the', 'segmented', 'hand', 's', 'binary', 'image', 'is', 'converted', 'to', 'a', 'colored', 'image', 'for', 'deep', 'models', 'and', 'lastly', 'data', 'is', 'aug', 'mented', 'to', 'avoid', 'over', 'fitting', 'Four', 'pre', 'trained', 'models', 'viz', 'In', 'ceptionV3', 'ResNet152V2', 'InceptionResNetV2', 'and', 'ReXNet101', 'are', 'selected', 'from', 'the', 'literature', 'based', 'on', 'their', 'performance', 'in', 'the', 'Im', 'ageNet', '28', 'challenge', 'A', 'customized', 'three', 'layered', 'CNN', 'model', 'is', 'also', 'designed', 'trained', 'from', 'scratch', 'and', 'then', 'compared', 'with', 'the', 'pre', 'trained', 'deep', 'models', 'mentioned', 'above', 'This', 'paper', 'uses', 'five', 'gradient', 'based', 'optimizers', 'Stochastic', 'gradient', 'descent', 'SGD', 'adaptive', 'gradient', 'AdaGrad', 'adaptive', 'delta', 'AdaDelta', 'root', 'mean', 'square', 'propagation', 'RMSProp', 'and', 'adaptive', 'moment', 'estimation', 'Adam', 'with', 'their', 'hyperparameters', 'like', 'learning', 'rate', 'batch', 'size', 'and', 'momentum', 'This', 'work', 'aims', 'to', 'evaluate', 'the', 'latest', 'deep', 'mod', 'els', 'optimizers', 'and', 'hyperparameters', 'on', 'Indian', 'signs', 'Thus', 'two', 'subsets', 'Numerals', 'and', 'Alphabets', 'of', 'a', 'publicly', 'available', 'dataset', 'are', 'selected', 'for', 'the', 'comprehensive', 'analysis', 'First', 'Numerals', 'subset', 'with', '9', 'classes', 'is', 'used', 'to', 'tune', 'the', 'hyperparameters', 'which', 'are', 'then', 'applied', 'to', 'the', 'Alphabets', 'subset', '24', 'classes', 'to', 'evaluate', 'the', 'performance', 'of', 'deep', 'models', 'on', 'a', 'subset', 'using', 'the', 'hyperparam', 'eters', 'tuned', 'on', 'a', 'different', 'subset', 'of', 'the', 'same', 'dataset', 'The', 'pro', 'cess', 'of', 'evaluating', 'the', 'models', 'optimizers', 'and', 'hyperparameters', 'follows', 'the', 'steps', 'given', 'below', 'Step', '1', 'This', 'step', 'uses', 'the', 'relatively', 'smaller', 'sized', 'architecture', 'InceptionV3', 'to', 'tune', 'the', 'batch', 'size', 'on', 'the', 'Numerals', 'subset', 'of', 'the', 'dataset', 'by', 'fixing', 'other', 'hyperparameters', 'and', 'optimizers', 'Step', '2', 'InceptionV3', 'is', 'again', 'used', 'to', 'tune', 'the', 'learning', 'rate', 'and', 'momentum', 'SGD', 'for', 'each', 'optimizer', 'by', 'fixing', 'the', 'batch', 'size', 'with', 'the', 'value', 'obtained', 'in', 'Step', '1', 'and', 'using', 'the', 'Numerals', 'subset', 'Step', '3', 'This', 'step', 'evaluates', 'the', 'optimizers', 'with', 'the', 'hyperpa', 'rameter', 'settings', 'selected', 'from', 'Steps', '1', 'and', '2', 'The', 'optimizer', 'with', 'the', 'lowest', 'loss', 'and', 'highest', 'recognition', 'accuracy', 'on', 'the', 'Numerals', 'subset', 'is', 'selected', 'to', 'evaluate', 'the', 'deep', 'models', 'further', 'Step', '4', 'Finally', 'this', 'last', 'step', 'evaluate', 'the', 'deep', 'models', 'with', 'the', 'selected', 'hyperparameters', 'and', 'optimizer', 'from', 'Steps', '1', '2', 'and', '3', 'on', 'both', 'the', 'Numerals', 'and', 'Alphabets', 'of', 'the', 'dataset', 'Thus', 'in', 'the', 'end', 'the', 'CNN', 'model', 'that', 'gives', 'the', 'highest', 'recog', 'nition', 'performance', 'on', 'both', 'the', 'subsets', 'of', 'the', 'ISL', 'dataset', 'is', 'considered', 'to', 'be', 'the', 'most', 'suitable', 'for', 'the', 'application', 'of', 'static', 'ISL', 'recognition', '3', 'CNN', 'models', 'The', 'work', 'in', 'this', 'paper', 'utilizes', 'fine', 'tuning', 'of', 'pre', 'trained', 'deep', 'models', 'where', 'a', 'sequence', 'of', 'flatten', 'dense', 'and', 'dropout', 'layers', 'Fig', '1', 'replace', 'the', 'last', 'layer', 'of', 'these', 'models', 'and', 'freeze', 'the', 're', 'maining', 'layers', 'to', 'train', 'on', 'the', 'ISL', 'dataset', 'This', 'section', 'thoroughly', 'discusses', 'the', 'architectures', 'of', 'pre', 'trained', 'deep', 'models', 'and', 'the', 'proposed', 'three', 'layered', 'CNN', 'model', 'used', 'for', 'feature', 'extraction', 'and', 'classification', 'of', 'Indian', 'signs', '2', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'Table', '1', 'Architectural', 'and', 'performance', 'details', 'of', 'pre', 'trained', 'deep', 'models', 'Models', 'Parameters', 'M', 'Layers', 'Size', 'MB', 'Top', '1', 'Loss', 'Top', '2', 'Loss', 'InceptionV3', '15', 'ResNet152V2', '33', 'InceptionResNetV2', '34', 'ResNeXt101', '35', '23', '8', '60', '4', '55', '8', '48', '152', '164', '101', '92', '232', '215', '638', '21', '2', '19', '38', '19', '9', '19', '1', '5', '6', '4', '49', '4', '9', '4', '4', 'modules', 'in', 'softmax', 'layers', 'prevent', 'the', 'vanishing', 'gradient', 'prob', 'lem', 'in', 'the', 'middle', 'of', 'the', 'model', 'Thus', 'InceptionV1', 'aims', 'to', 'make', 'a', 'balance', 'between', 'efficiency', 'and', 'computational', 'complexity', 'to', 'improve', 'an', 'inception', 'model', 'InceptionV2', '15', 'also', 'incorporates', 'the', 'following', 'changes', 'when', 'compared', 'to', 'the', 'previous', 'versions', '1', 'factorizing', 'large', 'convolutions', 'into', 'smaller', 'ones', '2', 'factorizing', 'convolutions', 'into', 'asymmetric', 'ones', '3', 'expanding', 'the', 'filter', 'banks', 'to', 'make', 'the', 'model', 'wider', 'that', 'reduces', 'its', 'representation', 'bottle', 'neck', '4', 'reducing', 'the', 'grid', 'size', 'by', 'parallel', 'pooling', 'convolving', 'and', 'then', 'concatenation', 'InceptionV3', '15', 'is', 'similar', 'to', 'InceptionV2', 'with', 'the', 'addition', 'of', 'the', 'following', '1', 'factorizing', '7', '7', 'convolu', 'tions', '2', 'using', 'RMSProp', 'as', 'an', 'optimizer', '3', 'batch', 'normalization', 'of', 'the', 'side', 'layer', 'of', 'the', 'network', 'consisting', 'of', 'auxiliary', 'classifiers', '4', 'introducing', 'label', 'smoothing', 'regularization', 'to', 'make', 'the', 'model', 'less', 'confident', 'about', 'a', 'class', 'thereby', 'preventing', 'the', 'over', 'fitting', 'problem', 'This', 'paper', 'selects', 'InceptionV3', 'due', 'to', 'its', 'popularity', 'as', 'it', 'is', 'the', 'first', 'runner', 'up', 'with', 'the', 'lowest', 'error', 'rate', 'in', 'image', 'classification', 'competition', 'on', 'ImageNet', 'dataset', 'in', '2015', '3', '3', 'ResNet152V2', 'He', 'et', 'al', '36', 'introduced', 'deep', 'residual', 'neural', 'networks', 'Resnets', 'in', '2015', 'and', 'proposed', 'stacked', 'residual', 'blocks', 'instead', 'of', 'a', 'plain', 'network', 'to', 'solve', 'the', 'vanishing', 'gradient', 'problem', 'Instead', 'of', 'following', 'the', 'main', 'path', 'in', 'a', 'plain', 'network', 'that', 'involves', 'linear', 'operators', 'and', 'non', 'linear', 'activations', 'the', 'residual', 'blocks', 'have', 'a', 'short', 'cut', 'path', 'that', 'directly', 'adds', 'the', 'input', 'activation', 'to', 'the', 'last', 'layer', 's', 'output', 'without', 'going', 'from', 'the', 'main', 'path', 'The', 'first', 'version', 'of', 'resnet', 'ResNetV1', 'adds', 'the', 'last', 'layer', 's', 'output', 'in', 'the', 'original', 'residual', 'network', 'before', 'the', 'non', 'linear', 'activation', 'rectified', 'linear', 'unit', 'ReLU', 'and', 'after', 'the', 'linear', 'operation', 'In', 'the', 'second', 'version', 'ResNetV2', '33', 'authors', 'made', 'a', 'direct', 'path', 'in', 'the', 'resnet', 'architecture', 'for', 'propagating', 'the', 'information', 'from', 'input', 'to', 'output', 'in', '2016', 'Unlike', 'ResNetV1', 'ResNetV2', 'is', 'a', 'full', 'pre', 'activation', 'architecture', 'using', 'both', 'the', 'batch', 'normalization', 'BN', 'and', 'ReLU', 'layers', 'as', 'pre', 'activation', 'by', 'adopting', 'these', 'layers', 'before', 'the', 'weight', 'layers', 'ResNetV2', 'has', 'resulted', 'in', 'significant', 'improvements', 'in', 'performance', 'on', 'various', 'datasets', 'as', 'shown', 'in', 'paper', '33', 'and', 'thus', 'this', 'work', 'selected', 'one', 'of', 'its', 'variants', 'ResNet152V2', 'consisting', 'of', '152', 'layers', 'for', 'performance', 'evaluation', 'on', 'the', 'recognition', 'of', 'Indian', 'signs', '3', '4', 'InceptionResNetV2', 'InceptionResNetV2', '34', 'is', 'similar', 'to', 'InceptionV4', '34', 'except', 'the', 'added', 'advantage', 'of', 'residual', 'connections', 'Deep', 'networks', 'with', 'many', 'layers', 'like', 'inceptions', '30', 'usually', 'suffer', 'from', 'vanishing', 'gradient', 'problem', 'Thus', 'replacing', 'filter', 'concatenations', 'in', 'an', 'in', 'ception', 'model', 'with', 'the', 'residual', 'connections', 'proves', 'instrumental', 'in', 'increasing', 'the', 'speed', 'of', 'the', 'model', 's', 'convergence', 'and', 'efficiency', 'thereby', 'solving', 'the', 'vanishing', 'gradient', 'problem', '36', 'Szegedy', 'et', 'al', '34', 'analyzed', 'both', 'the', 'cases', 'of', 'an', 'inception', 'network', 'residual', 'InceptionResNetV2', 'and', 'non', 'residual', 'InceptionV4', 'and', 'reported', 'that', 'InceptionResNetV2', 'is', 'marginally', 'better', 'than', 'Incep', 'tionV4', 'in', 'terms', 'of', 'convergence', 'speed', 'classification', 'accuracy', 'and', 'loss', 'It', 'is', 'the', 'reason', 'for', 'selecting', 'InceptionReNetV2', 'for', 'evalua', 'tion', 'in', 'this', 'work', 'Table', '1', 'gives', 'the', 'details', 'about', 'the', 'network', 's', 'architecture', 'and', 'performance', 'on', 'the', 'ImageNet', 'dataset', 'Fig', '1', 'Layers', 'in', 'pre', 'trained', 'Top', 'and', 'the', 'proposed', 'three', 'layered', 'CNN', 'deep', 'models', '3', '1', 'Proposed', 'CNN', 'model', 'A', 'custom', 'made', 'three', 'layered', 'CNN', 'model', 'is', 'proposed', 'that', 'consists', 'of', 'a', 'max', 'pooling', 'and', 'a', 'dropout', 'layer', 'for', 'regularization', 'following', 'the', 'first', 'two', 'CNN', 'layers', 'and', 'the', 'dropout', 'flattened', 'and', 'dense', 'layers', 'following', 'the', 'last', 'CNN', 'layer', 'shown', 'in', 'Fig', '1', 'This', 'proposed', 'model', 'trains', 'on', 'the', 'ISL', 'dataset', 'from', 'scratch', 'comparing', 'its', 'recognition', 'performance', 'with', 'pre', 'trained', 'deep', 'models', 'that', 'utilize', 'the', 'fine', 'tuning', 'technique', 'for', 'training', '3', '2', 'InceptionV3', 'Before', 'the', 'advent', 'of', 'inception', 'models', 'increasing', 'the', 'number', 'of', 'layers', 'and', 'the', 'neurons', 'connected', 'to', 'those', 'layers', 'to', 'make', 'the', 'model', 'prominent', 'was', 'the', 'only', 'solution', 'for', 'improving', 'the', 'neural', 'networks', 'The', 'big', 'models', 'suffer', 'from', 'the', 'following', 'problems', 'high', 'computational', 'complexity', 'over', 'fitting', 'due', 'to', 'limited', 'train', 'ing', 'dataset', 'and', 'fast', 'disappearance', 'of', 'gradient', 'change', 'The', 'first', 'version', 'of', 'an', 'inception', 'model', 'InceptionV1', '20', 'tried', 'to', 'solve', 'these', 'problems', 'by', 'increasing', 'the', 'width', 'rather', 'than', 'the', 'depth', 'of', 'a', 'model', 'incorporating', 'multiple', 'sized', 'convolutional', 'filters', 'to', 'get', 'both', 'the', 'local', 'and', 'global', 'information', 'from', 'an', 'image', 'Also', 'in', 'troducing', 'two', 'auxiliary', 'classifiers', 'at', 'the', 'output', 'of', 'two', 'inception', '3', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', '3', '5', 'ResNeXt101', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', '5', '1', 'Stochastic', 'gradient', 'descent', 'SGD', 'ResNeXt', 'one', 'of', 'the', 'variants', 'of', 'resnet', 'was', 'introduced', 'in', 'pa', 'per', '35', 'in', 'which', 'the', 'building', 'block', 'that', 'aggregates', 'a', 'set', 'of', 'trans', 'formations', 'repeats', 'with', 'the', 'same', 'topology', 'Here', 'X', 'represents', 'Next', 'dimension', 'called', 'Cardinality', 'C', 'which', 'is', 'the', 'number', 'of', 'repetitions', 'of', 'a', 'set', 'of', 'aggregated', 'transformations', 'i', 'e', 'expand', 'ing', 'the', 'Network', 'in', 'Neuron', 'along', 'this', 'new', 'dimension', 'Eq', '1', 'represents', 'these', 'aggregated', 'transformations', 'as', 'SGD', '38', '39', 'is', 'an', 'optimizer', 'that', 'accelerates', 'the', 'process', 'of', 'convergence', 'to', 'the', 'desired', 'objective', 'in', 'a', 'fast', 'way', 'Instead', 'of', 'using', 'all', 'the', 'training', 'examples', 'for', 'computing', 'the', 'gradient', 'by', 'plain', 'gradient', 'descent', 'method', '40', 'SGD', 'uses', 'a', 'mini', 'batch', 'of', 'samples', 'from', 'the', 'training', 'set', 'for', 'calculating', 'the', 'gradient', 'This', 'process', 'reduces', 'the', 'computational', 'complexity', 'irrespective', 'of', 'the', 'size', 'of', 'the', 'training', 'data', 'The', 'calculation', 'of', 'gradient', 'at', 'each', 'iteration', 'in', 'SGD', 'is', 'shown', 'in', 'Eq', '2', 'as', 'F', 'x', 'C', 'i', '1', 'Ti', 'x', '1', 'g', '1', 'n', 'n', 'i', '1', 'θ', 'L', 'x', 'i', 'y', 'i', 'θt', '2', 'where', 'Ti', 'x', 'is', 'an', 'arbitrary', 'function', 'that', 'projects', 'x', 'into', 'a', 'low', 'dimension', 'and', 'then', 'transforms', 'it', 'ResNeXt', 'performs', 'better', 'than', 'the', 'other', 'models', 'like', 'Incep', 'tionV3', 'V4', 'and', 'InceptionResNetV2', 'for', 'ImageNet', '2k', 'validation', 'set', 'as', 'experimented', 'in', 'paper', '35', 'That', 'is', 'why', 'this', 'paper', 'uses', 'ResNeXt101', 'for', 'SLR', '4', 'Hyperparameters', 'Hyperparameters', 'of', 'a', 'network', 'control', 'the', 'entire', 'training', 'pro', 'cess', 'and', 'are', 'of', 'two', 'types', 'model', 'and', 'optimization', 'Model', 'hyper', 'parameters', 'define', 'the', 'structure', 'of', 'a', 'network', 'and', 'optimization', 'hyperparameters', 'decide', 'the', 'training', 'process', 's', 'path', 'to', 'reach', 'the', 'desired', 'output', 'This', 'paper', 'analyzes', 'various', 'optimization', 'hyper', 'parameters', 'with', 'different', 'pre', 'trained', 'deep', 'models', 'The', 'opti', 'mization', 'hyperparameters', 'batch', 'size', 'and', 'learning', 'rate', 'are', 'discussed', 'below', 'Batch', 'size', 'Batch', 'size', 'is', 'the', 'number', 'of', 'input', 'training', 'samples', 'given', 'at', 'a', 'time', 'to', 'the', 'network', 'It', 'decides', 'the', 'utilization', 'of', 'resources', 'and', 'the', 'speed', 'of', 'a', 'network', 'There', 'are', 'three', 'types', 'of', 'training', 'batch', 'Stochastic', 'and', 'mini', 'batch', 'In', 'batch', 'training', 'the', 'whole', 'training', 'set', 'goes', 'into', 'training', 'at', 'once', 'i', 'e', 'batch', 'size', 'equals', 'the', 'total', 'number', 'of', 'training', 'samples', 'However', 'it', 'is', 'less', 'time', 'consuming', 'but', 'it', 'takes', 'too', 'much', 'memory', 'and', 'can', 'get', 'stuck', 'in', 'a', 'local', 'minimum', 'At', 'a', 'time', 'Stochastic', 'training', 'sends', 'one', 'training', 'sample', 'into', 'training', 'i', 'e', 'batch', 'size', 'equals', '1', 'and', 'is', 'very', 'time', 'consuming', 'but', 'guarantees', 'to', 'reach', 'the', 'global', 'minimum', 'Mini', 'batch', 'training', 'where', 'the', 'batch', 'size', 'is', 'greater', 'than', '1', 'con', 'verges', 'fast', 'with', 'less', 'memory', 'requirement', 'if', 'the', 'chosen', 'batch', 'size', 'is', 'not', 'too', 'large', 'The', 'proposed', 'work', 'uses', 'mini', 'batch', 'training', 'to', 'solve', 'the', 'problems', 'of', 'batch', 'and', 'Stochastic', 'training', 'methods', 'The', 'range', 'of', 'batch', 'size', 'selected', 'for', 'tuning', 'is', 'from', '23', '8', 'to', '27', '128', 'because', 'this', 'is', 'the', 'most', 'used', 'range', 'in', 'the', 'literature', 'Learning', 'Rate', 'Learning', 'rate', 'is', 'a', 'hyperparameter', 'that', 'decides', 'how', 'fast', 'and', 'accurately', 'the', 'model', 'converges', 'to', 'the', 'desired', 'point', 'The', 'learning', 'rate', 'can', 'be', 'a', 'constant', 'value', 'for', 'the', 'training', 'process', 'or', 'it', 'can', 'be', 'automatically', 'decayed', 'using', 'various', 'decay', 'schemes', 'This', 'work', 'follows', 'a', 'constant', 'learning', 'rate', 'throughout', 'the', 'training', 'process', 'for', 'each', 'model', 'with', 'the', 'most', 'used', 'range', 'from', '1e', '1', 'to', '1e', '5', 'based', 'on', 'the', 'literature', 'surveyed', 'by', 'Shivaprasad', 'et', 'al', '37', 'This', 'paper', 'also', 'tunes', 'two', 'more', 'hyperparameters', 'namely', 'momentum', 'and', 'Nesterov', 'acceleration', 'gradient', 'NAG', 'which', 'are', 'discussed', 'in', 'Section', '5', '1', 'as', 'they', 'belong', 'to', 'the', 'SGD', 'optimizer', 'helping', 'its', 'gradient', 'reach', 'the', 'objective', 'quickly', 'and', 'accurately', '5', 'Optimization', 'algorithms', 'Then', 'the', 'weights', 'of', 'the', 'model', 'gets', 'updated', 'using', 'the', 'follow', 'ing', 'update', 'rule', 'Eq', '3', 'θt', '1', 'θt', 'η', 'g', '3', 'where', 'θ', 'is', 'a', 'parameter', 'that', 'can', 'be', 'changed', 'to', 'get', 'the', 'minimum', 'loss', 'η', 'is', 'the', 'learning', 'rate', 'that', 'decides', 'the', 'extent', 'of', 'change', 'of', 'parameters', 'w', 'r', 't', 'the', 'gradients', 'However', 'SGD', 'has', 'the', 'following', 'problems', '1', 'becomes', 'very', 'slow', 'when', 'the', 'gradient', 'is', 'con', 'sistently', 'small', '2', 'has', 'gradient', 'dependent', 'update', 'rule', 'at', 'each', 'iteration', 'and', '3', 'follows', 'the', 'wrong', 'gradient', 'frequently', 'due', 'to', 'noisy', 'gradients', 'The', 'tuning', 'of', 'the', 'optimization', 'hyper', 'parameters', 'momentum', 'and', 'NAG', 'solve', 'the', 'problems', 'mentioned', 'above', 'Momentum', 'M', 'and', 'Nesterov', 'acceleration', 'gradient', 'NAG', 'Momentum', 'method', '41', 'developed', 'by', 'Polyak', '42', 'accelerated', 'the', 'gradient', 'descent', 'by', 'taking', 'into', 'account', 'the', 'previous', 'gradi', 'ents', 'at', 'each', 'iteration', 'thereby', 'updating', 'the', 'update', 'rule', 'as', 'given', 'in', 'Eqs', '4', 'and', '5', 'below', 'vt', '1', 'α', 'vt', 'η', 'g', '4', 'θt', '1', 'θt', 'vt', '1', '5', 'where', 'v', 'is', 'the', 'velocity', 'term', 'that', 'determines', 'how', 'fast', 'and', 'in', 'what', 'direction', 'the', 'parameter', 'should', 'be', 'changed', 'The', 'α', 'is', 'a', 'decay', 'ing', 'hyperparameter', 'that', 'determines', 'how', 'fast', 'the', 'accumulated', 'gradients', 'will', 'decay', 'The', 'momentum', 'smoothens', 'the', 'unnecessary', 'oscillations', 'of', 'gradients', 'while', 'reaching', 'the', 'desired', 'output', 'However', 'if', 'the', 'momentum', 'value', 'is', 'high', 'and', 'unknowingly', 'skips', 'the', 'desired', 'objective', 'point', 'it', 'will', 'give', 'bad', 'results', 'NAG', '43', '45', 'further', 'solves', 'the', 'problem', 'of', 'high', 'momentum', 'The', 'difference', 'between', 'the', 'momentum', 'and', 'the', 'NAG', 'method', 'lies', 'only', 'in', 'the', 'gradient', 'part', 's', 'computation', 'while', 'the', 'update', 'rule', 'remains', 'the', 'same', 'As', 'given', 'in', 'Eq', '5', 'the', 'gradient', 'calculation', 'in', 'momentum', 'method', 'considers', 'only', 'current', 'parameters', 'θ', 'but', 'in', 'NAG', 'velocity', 'vt', 'is', 'applied', 'to', 'θ', 'to', 'compute', 'the', 'interim', 'parameters', 'θ', 'as', 'shown', 'in', 'Eq', '6', 'below', 'θ', 'θt', 'α', 'vt', '6', 'After', 'the', 'gradient', 'calculation', 'the', 'θ', 'will', 'replace', 'θ', 'in', 'the', 'update', 'rule', 'given', 'in', 'Eq', '5', 'Thus', 'NAG', 'acts', 'as', 'a', 'correction', 'factor', 'for', 'the', 'momentum', 'method', 'The', 'momentum', 'values', 'used', 'in', 'the', 'SGD', 'optimizer', 'are', '0', '0', 'without', 'momentum', '0', '5', 'slight', 'momentum', 'and', '0', '9', 'high', 'momentum', 'with', 'and', 'without', 'NAG', 'because', 'its', 'value', 'ranges', 'from', '0', 'to', '1', 'InceptionV3', 'model', 'tunes', 'the', 'momentum', 'and', 'NAG', 'for', 'SGD', 'optimizer', 'on', 'ISL', 'dataset', 's', 'numerals', '5', '2', 'Adaptive', 'Gradient', 'AdaGrad', 'The', 'gradient', 'based', 'optimizers', 'used', 'in', 'the', 'paper', 'are', 'discussed', 'in', 'detail', 'in', 'the', 'following', 'subsections', 'The', 'SGD', 'optimizer', 'works', 'using', 'a', 'procedural', 'scheme', 'that', 'applies', 'the', 'learning', 'rate', 'unaware', 'of', 'the', 'dataset', 's', 'characteristics', 'AdaGrad', 'algorithm', '46', 'solves', 'this', 'problem', 'using', 'the', 'previous', '4', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'iterations', 'to', 'gather', 'the', 'knowledge', 'of', 'data', 's', 'geometry', 'and', 'in', 'corporate', 'it', 'in', 'an', 'informative', 'way', 'for', 'gradient', 'based', 'learning', 'A', 'small', 'learning', 'rate', 'is', 'given', 'in', 'this', 'algorithm', 'if', 'the', 'features', 'occur', 'frequently', 'and', 'a', 'large', 'learning', 'rate', 'if', 'the', 'frequency', 'of', 'features', 'occurring', 'is', 'shallow', 'SGD', 'carry', 'out', 'an', 'update', 'for', 'all', 'the', 'parameters', 'θ', 'because', 'for', 'every', 'parameter', 'θi', 'there', 'is', 'a', 'fixed', 'learning', 'rate', 'η', 'In', 'AdaGrad', 'there', 'are', 'different', 'learning', 'rates', 'for', 'each', 'parameter', 'θi', 'at', 'every', 'time', 'step', 'or', 'iteration', '47', 'as', 'observed', 'from', 'Eq', '7', 'as', 'gt', 'i', 'θt', 'J', 'θt', 'i', 'where', 'gt', 'i', 'gradient', 'of', 'the', 'objective', 'function', 'w', 'r', 't', 'the', 'parame', 'ter', 'θi', 'at', 'time', 'step', 't', 'The', 'SGD', 'update', 'rule', 'for', 'every', 'θi', 'at', 'each', 'time', 'step', 'is', 'given', 'in', 'Eq', '8', 'similar', 'to', 'Eq', '5', 'as', 'θt', '1', 'i', 'θt', 'i', 'η', 'gt', 'i', '7', '8', 'However', 'in', 'Eq', '8', 'the', 'learning', 'rate', 'has', 'to', 'be', 'updated', 'at', 'every', 'iteration', 'for', 'every', 'parameter', 'θi', 'based', 'on', 'the', 'previous', 'gradients', 'computed', 'for', 'θi', 'for', 'AdaGrad', 'optimizer', 'Thus', 'Eq', '8', 'can', 'be', 'written', 'as', 'in', 'Eq', '9', 'θt', '1', 'i', 'θt', 'i', 'η', 'Gt', 'ii', 'ϵ', 'gt', 'i', 'where', 'Gt', 'ii', 'is', 'the', 'diagonal', 'matrix', 'where', 'each', 'diagonal', 'element', 'i', 'i', 'is', 'the', 'sum', 'of', 'squares', 'of', 'gradients', 'w', 'r', 't', 'θi', 'up', 'to', 'time', 'step', 't', 'ϵ', 'is', 'the', 'smoothing', 'term', 'to', 'prevent', 'division', 'by', 'zero', 'and', 'is', 'usually', 'of', 'the', 'order', 'of', '1e', '8', 'The', 'learning', 'rate', 'becomes', 'endlessly', 'small', 'towards', 'the', 'end', 'of', 'the', 'training', 'process', 'due', 'to', 'the', 'aggregation', 'of', 'squared', 'gradients', 'in', 'the', 'denominator', 'of', 'Eq', '9', 'making', 'it', 'difficult', 'for', 'the', 'model', 'to', 'learn', 'new', 'knowledge', 'Another', 'optimizer', 'called', 'AdaDelta', 'solves', 'this', 'problem', 'and', 'is', 'explained', 'in', 'the', 'following', 'sub', 'section', '5', '3', 'AdaDelta', 'Monotonically', 'decreasing', 'learning', 'rate', 'and', 'a', 'need', 'to', 'man', 'ually', 'select', 'the', 'global', 'learning', 'rate', 'are', 'the', 'two', 'disadvantages', 'of', 'AdaGrad', 'optimizer', 'taken', 'care', 'of', 'by', 'AdaDelta', 'To', 'solve', 'the', 'first', 'problem', 'AdaDelta', '48', 'implements', 'an', 'aggregation', 'of', 'ex', 'ponentially', 'decaying', 'average', 'of', 'squared', 'gradients', 'The', 'series', 'of', 'Equations', '47', 'from', '10', 'to', '14', 'given', 'below', 'shows', 'the', 'imple', 'mentation', 'of', 'the', 'above', 'mentioned', 'aggregation', 'The', 'SGD', 'update', 'rule', 'in', 'the', 'form', 'of', 'δθt', 'is', 'given', 'in', 'Eqs', '10', 'and', '11', 'as', 'δθt', 'η', 'gt', 'i', '10', 'θt', '1', 'θt', 'δθt', '11', 'The', 'value', 'of', 'δθt', 'Eq', '12', 'in', 'case', 'of', 'AdaDelta', 'is', 'written', 'as', 'exponentially', 'decaying', 'average', 'E', 'δθ', '2', 't', 'of', 'parameter', 'updates', 'δθ', 'such', 'as', 'δθt', 'E', 'δθ', '2', 't', 'ϵ', 'RMS', 'g', 't', 'gt', 'Eq', '15', 'can', 'also', 'be', 'written', 'as', 'δθt', 'RMS', 'δθ', 't', '1', 'RMS', 'g', 't', 'gt', '15', '16', 'The', 'Eq', '16', 'is', 'now', 'free', 'from', 'learning', 'rate', 'η', 'solving', 'the', 'AdaGrad', 's', 'second', 'problem', '5', '4', 'Root', 'mean', 'square', 'propagation', 'RMSProp', 'RMSProp', '49', 'is', 'almost', 'similar', 'to', 'the', 'solution', 'given', 'by', 'AdaDelta', 'to', 'the', 'first', 'problem', 'of', 'AdaGrad', 'as', 'shown', 'in', 'Eq', '14', 'Both', 'the', 'algorithms', 'AdaDelta', 'and', 'RMSProp', 'were', 'developed', 'by', 'two', 'different', 'researchers', 'simultaneously', 'but', 'independently', 'Geoff', 'Hinton', 'discussed', 'RMSProp', 'for', 'the', 'first', 'time', 'in', '2012', 'and', 'stated', 'that', '0', '9', 'value', 'for', 'γ', 'Eq', '13', 'and', '0', '001', 'value', 'for', 'learning', 'rate', 'η', 'Eq', '14', 'are', 'the', 'best', 'suited', 'ones', 'Adam', '50', 'is', 'a', 'combination', 'of', 'two', 'optimization', 'algorithms', 'RMSProp', 'and', 'SGD', 'with', 'momentum', 'It', 'also', 'takes', 'advantage', 'of', 'AdaGrad', 'and', 'RMSProp', 'for', 'dealing', 'well', 'with', 'sparse', 'gradients', 'and', 'online', 'settings', 'Adam', 'stores', 'the', 'second', 'raw', 'moment', 'estimate', 'say', 'vt', 'similar', 'to', 'RMSProp', 'and', 'AdaDelta', 'and', 'the', 'first', 'moment', 'estimate', 'say', 'mt', 'similar', 'to', 'momentum', 'and', 'thus', 'is', 'named', 'as', 'adaptive', 'moment', 'estimation', 'The', 'first', 'and', 'second', 'moment', 'es', 'timates', '47', 'are', 'exponentially', 'decaying', 'average', 'of', 'past', 'and', 'past', 'squared', 'gradients', 'respectively', 'mt', 'β1', 'mt', '1', '1', 'β1', 'gt', '17', 'vt', 'β2', 'vt', '1', '1', 'β1', 'g', '2', 't', '18', 'According', 'to', 'Adam', 's', 'algorithm', 'the', 'moment', 'estimates', 'are', 'biased', 'towards', 'zero', 'especially', 'in', 'the', 'initial', 'phase', 'of', 'training', 'when', 'mt', 'and', 'vt', 'initializes', 'to', '0', 'in', 'Eqs', '17', 'and', '18', 'and', 'the', 'learning', 'process', 'becomes', 'slower', 'when', 'the', 'decay', 'rates', 'β1', 'and', 'β2', 'are', 'close', 'to', 'zero', 'To', 'solve', 'this', 'issue', 'bias', 'corrected', 'estimates', 'ˆmt', 'and', 'ˆvt', 'are', 'used', 'to', 'update', 'the', 'weights', 'as', 'given', 'in', 'Eqs', '19', 'and', '20', 'below', 'ˆmt', 'mt', '1', 'β', 't', '1', '19', 'ˆvt', 'vt', '1', 'β', 't', '2', '20', '9', '5', '5', 'Adaptive', 'Moment', 'Estimation', 'Adam', 'δθt', 'η', 'E', 'g', '2', 't', 'ϵ', 'gt', '12', 'These', 'bias', 'corrected', 'terms', 'are', 'now', 'used', 'to', 'calculate', 'the', 'Adam', 'update', 'rule', 'Eq', '21', 'similar', 'to', 'RMSProp', 'and', 'AdaDelta', 'where', 'E', 'g', '2', 't', 'is', 'the', 'running', 'average', 'of', 'the', 'past', 'squared', 'gradi', 'ents', 'and', 'the', 'current', 'gradient', 'at', 'each', 'time', 'step', 't', 'It', 'is', 'defined', 'in', 'Eq', '13', 'as', 'E', 'g', '2', 't', 'γ', 'E', 'g', '2', 't', '1', '1', 'γ', 'g', '2', '13', 'Here', 'γ', 'is', 'a', 'decay', 'constant', 'similar', 'to', 'momentum', 'In', 'Eq', '12', 'E', 'g', '2', 't', 'ϵ', 'is', 'the', 'root', 'mean', 'squared', 'error', 'criterion', 'of', 'the', 'gra', 'dient', 'Thus', 'Eq', '12', 'can', 'be', 'rewritten', 'as', 'Eq', '14', 'as', 'shown', 'below', 't', 'δθt', 'η', 'RMS', 'g', 't', 'gt', '14', 'To', 'solve', 'the', 'second', 'problem', 'of', 'manually', 'setting', 'the', 'global', 'learning', 'rate', 'the', 'learning', 'rate', 'η', 'in', 'Eq', '14', 'is', 'replaced', 'by', 'an', '5', 'θt', '1', 'θt', 'η', 'ˆvt', 'ϵ', 'ˆmt', '21', 'Kingma', 'and', 'Ba', '50', 'suggests', 'the', 'default', 'values', 'for', 'β1', 'β2', 'and', 'ϵ', 'to', 'be', '0', '9', '0', '999', 'and', '10', '8', 'respectively', '6', 'Dataset', 'descriptions', 'and', 'pre', 'processing', 'This', 'paper', 'works', 'on', 'a', 'public', 'static', 'ISL', 'dataset', 'developed', 'by', 'Ansari', 'and', 'Harit', '51', 'consisting', 'of', '140', 'Indian', 'signs', 'for', 'alphabets', 'numerals', 'technical', 'words', 'and', 'words', 'related', 'to', 'objects', 'situa', 'tions', 'actions', 'and', 'people', 'The', 'dataset', 'involves', '18', 'users', 'repeating', 'a', 'particular', 'Indian', 'sign', 'two', 'times', 'but', 'out', 'of', '18', 'data', 'of', 'only', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'focuses', 'on', 'a', 'single', 'cue', 'depth', 'for', 'segmentation', 'of', 'hands', 'thus', 'considering', 'only', 'depth', 'data', 'from', 'the', 'dataset', 'A', 'depth', 'value', 'of', '2047', 'is', 'assigned', 'to', 'a', 'pixel', 'in', 'the', 'dataset', 'if', 'it', 'is', 'out', 'of', 'the', 'Kinect', 's', 'sensing', 'limit', 'The', 'segmentation', 'of', 'hands', 'from', 'the', 'depth', 'images', 'uses', 'the', 'same', 'methodology', 'as', 'described', 'in', 'paper', '10', 'on', 'American', 'SLR', 'involving', 'depth', 'thresholding', 'for', 'hand', 'region', 'segmentation', 'followed', 'by', 'forearm', 'removal', 'The', 'steps', 'for', 'seg', 'menting', 'the', 'hand', 'palm', 'and', 'fingers', 'from', 'a', 'depth', 'image', 'are', 'shown', 'in', 'Fig', '4', 'The', 'segmented', 'hands', 'binary', 'images', 'are', 'then', 'converted', 'into', 'color', 'images', 'and', 'given', 'input', 'to', 'the', 'pre', 'trained', 'deep', 'models', 'This', 'manuscript', 'aims', 'to', 'evaluate', 'optimizers', 'pre', 'trained', 'deep', 'models', 'and', 'optimization', 'hyperparameters', 'on', 'static', 'Indian', 'signs', 'thus', 'the', 'evaluation', 'uses', 'only', 'two', 'subsets', 'of', 'the', 'ISL', 'dataset', 'Numerals', '1', '9', 'and', 'Alphabets', 'A', 'Y', 'excluding', 'J', 'instead', 'of', 'the', 'whole', 'dataset', 'Each', 'class', 'of', 'Numerals', '9', 'and', 'Alphabets', '24', 'consists', 'of', 'approximately', '30', 'sample', 'depth', 'images', 'making', 'a', 'total', 'of', '269', 'images', 'for', 'Numerals', 'and', '716', 'images', 'for', 'Alphabets', 'Both', 'the', 'subsets', 'consist', 'of', 'only', 'single', 'handed', 'Indian', 'signs', 'and', 'Fig', '2', 'shows', 'some', 'sample', 'images', 'of', 'classes', 'of', 'both', 'the', 'subsets', 'The', 'Alphabets', 'are', 'pretty', 'complicated', 'than', 'the', 'Numerals', 'as', 'the', 'former', 'consists', 'of', 'many', 'similar', 'shaped', 'signs', 'shown', 'in', 'Fig', '2', 'and', 'have', 'more', 'classes', 'than', 'the', 'latter', 'These', 'differences', 'between', 'both', 'subsets', 'help', 'in', 'a', 'more', 'robust', 'evaluation', 'of', 'the', 'classification', 'models', 'A', 'deep', 'model', 'requires', 'many', 'training', 'samples', 'to', 'train', 'the', 'top', 'layers', 'of', 'an', 'already', 'trained', 'model', 'or', 'to', 'train', 'it', 'from', 'scratch', 'Thus', 'the', 'ISL', 'dataset', 's', 'size', 'is', 'increased', 'to', '63', '188', 'and', '240', '716', 'images', 'for', 'Numerals', 'and', 'Alphabets', 'respectively', 'The', 'details', 'of', 'the', 'operations', 'like', 'rotation', 'blurring', 'horizontal', 'flipping', 'and', 'adding', 'random', 'noise', 'to', 'the', 'ISL', 'dataset', 's', 'original', 'images', 'for', 'data', 'aug', 'mentation', 'are', 'shown', 'in', 'Fig', '3', '7', 'Evaluation', 'metrics', 'The', 'following', 'subsections', 'describe', 'the', 'performance', 'measures', 'used', 'for', 'comprehensive', 'analysis', '7', '1', 'Accuracy', 'Precision', 'Recall', 'and', 'F', '1', 'Score', 'For', 'a', 'supervised', 'classification', 'problem', 'SLR', 'in', 'this', 'paper', 'on', 'a', 'balanced', 'dataset', 'metrics', 'such', 'as', 'accuracy', 'false', 'negatives', 'FN', 'and', 'false', 'positives', 'FP', 'become', 'very', 'important', 'for', 'a', 'robust', 'performance', 'comparison', 'between', 'two', 'or', 'more', 'models', 'These', 'metrics', 'are', 'mathematically', 'defined', 'in', 'Eqs', '23', 'and', '25', 'as', 'Accuracy', 'TP', 'TN', 'TP', 'TN', 'FP', 'FN', 'Precision', 'TP', 'TP', 'FP', 'Recall', 'TP', 'TP', 'FN', 'F', '1', 'Score', '2', 'Recall', 'Precision', 'Recall', 'Precision', '22', '23', '24', '25', 'where', 'TP', 'True', 'positive', 'and', 'TN', 'True', 'negative', '7', '2', 'Categorical', 'cross', 'entropy', 'loss', 'Cross', 'entropy', 'loss', 'is', 'a', 'loss', 'for', 'binary', 'classification', 'problems', 'and', 'is', 'defined', 'in', 'Eq', '26', 'as', 'Cross', 'entropy', 'CE', 'loss', 'C', 'i', 'ti', 'log', 'f', 'si', '26', 'where', 's', 'is', 'the', 'CNN', 'score', 'for', 'each', 'class', 'i', 'in', 'C', 'f', 'si', 'represents', 'activations', 'sigmoid', 'or', 'softmax', 'and', 't', 'is', 'the', 'ground', 'truth', 'The', '6', 'Fig', '2', 'Numerals', 'and', 'Alphabets', 'in', 'ISL', 'Dataset', '1', '9', 'A', 'Y', 'except', 'J', 'and', 'Z', 'Fig', '3', 'Dataset', 'Processing', 'is', 'shown', 'in', 'a', 'b', 'and', 'c', 'Dataset', 'augmentation', 'is', 'shown', 'in', 'd', 'Blur', 'Probability', '0', '1', 'e', 'Rotation', 'Prob', '0', '5', 'Max', 'right', 'and', 'left', 'degree', '25', 'f', 'Random', 'Noise', 'Prob', '0', '5', 'and', 'g', 'Vertical', 'Flip', 'Prob', '0', '3', 'Fig', '4', 'Hand', 'palm', 'and', 'fingers', 'segmentation', 'process', 'From', 'Top', 'left', 'to', 'right', 'Depth', 'image', 'segmented', 'hand', 'region', 'using', 'depth', 'thresholding', 'Gaussian', 'blurring', 'to', 'find', 'the', 'point', 'with', 'maximum', 'density', 'of', 'pixels', 'forming', 'the', 'axis', 'of', 'hand', 'region', 'rotated', 'hand', 'in', 'a', 'standard', 'direction', 'circle', 'fitting', 'to', 'find', 'the', 'wrist', 'points', 'From', 'Bottom', 'left', 'to', 'right', 'Dividing', 'the', 'image', 'into', 'four', 'quadrants', 'increasing', 'the', 'radius', 'of', 'the', 'circle', 'till', 'it', 'intersects', 'the', 'hand', 'region', 'in', '3rd', 'and', '4th', 'quadrants', 'wrist', 'points', 'joining', 'the', 'wrist', 'points', 'and', 'removing', 'the', 'forearm', '15', 'users', 'are', 'available', 'online', 'Ansari', 'and', 'Harit', 'captured', 'both', 'the', 'RGB', 'and', 'depth', 'data', 'for', 'the', 'ISL', 'dataset', 'using', 'Microsoft', 's', 'KinectV2', 'camera', 'in', 'a', 'uniform', 'background', 'allowing', 'only', 'a', 'single', 'user', 'at', 'a', 'time', 'in', 'the', 'frame', 'Ansari', 'and', 'Harit', 'also', 'did', 'not', 'limit', 'the', 'users', 'of', 'wearing', 'any', 'wearable', 'during', 'the', 'signing', 'and', 'assumed', 'that', 'the', 'hand', 'is', 'the', 'closest', 'object', 'to', 'the', 'camera', 'This', 'work', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'Fig', '5', 'Performance', 'comparison', 'of', 'batch', 'sizes', 'on', 'numerals', 'using', 'InceptionV3', 'model', 'a', 'Validation', 'loss', 'evolution', 'and', 'b', 'training', 'time', 'classification', 'of', 'more', 'than', 'two', 'classes', 'uses', 'categorical', 'CE', 'loss', 'that', 'is', 'a', 'combination', 'of', 'softmax', 'activation', 'and', 'CE', 'loss', 'Softmax', 'activation', 'function', 'is', 'given', 'in', 'Eq', '27', 'as', '6', '1', 'compute', 'capability', 'and', 'memory', 'limit', 'of', '268', 'MB', 'and', '10', 'GB', 'on', 'CPU', 'and', 'GPU', 'respectively', 'The', 'subsections', 'from', '8', '1', 'to', '8', '5', 'dis', 'cuss', 'the', 'result', 'of', 'the', 'experiments', 'and', 'Section', '8', '6', 'compares', 'the', 'results', 'of', 'the', 'present', 'work', 'with', 'the', 'state', 'of', 'the', 'art', 'approaches', 'f', 'si', 'esi', 'C', 'j', 'esj', '27', '8', '1', 'Impact', 'of', 'batch', 'size', 'where', 'sj', 'is', 'the', 'net', 'of', 'scores', 'of', 'each', 'class', 'i', 'in', 'C', 'This', 'equation', 'shows', 'that', 'softmax', 'activation', 'of', 'a', 'class', 'si', 'depends', 'on', 'all', 'CNN', 'scores', 'in', 's', 'Categorical', 'CE', 'loss', 'can', 'be', 'obtained', 'by', 'combining', 'Eqs', '26', 'and', '27', 'in', 'Eq', '28', 'as', 'Categorical', 'cross', 'entropy', 'CCE', 'loss', 'log', 'esp', 'C', 'j', 'esj', '28', 'where', 'sp', 'is', 'the', 'CNN', 'score', 'for', 'positive', 'class', 'because', 'labels', 'are', 'one', 'hot', 'so', 'the', 'target', 'vector', 't', 'tp', 'represents', 'only', 'one', 'non', 'zero', 'element', 'of', 'the', 'target', 'vector', '7', '3', 'Coefficient', 'of', 'variation', 'CV', 'CV', 'is', 'a', 'statistical', 'method', 'for', 'calculating', 'and', 'comparing', 'the', 'data', 'samples', 'spread', 'or', 'variance', 'in', 'different', 'datasets', 'around', 'the', 'mean', 'even', 'when', 'the', 'means', 'are', 'very', 'distinct', 'from', 'each', 'other', 'This', 'paper', 'uses', 'CV', 'to', 'compare', 'the', 'performance', 'stability', 'of', 'different', 'combinations', 'of', 'deep', 'models', 'optimizers', 'and', 'hy', 'perparameters', 'by', 'calculating', 'the', 'spread', 'of', 'their', 'training', 'and', 'validation', 'loss', 'evolution', 'throughout', 'the', 'epochs', 'Mathematically', 'it', 'is', 'written', 'as', 'shown', 'below', 'in', 'Eq', '29', '52', '1', 'N', 'N', 'i', '1', 'xi', 'µ', '2', 'µ', 'CV', '29', 'where', 'numerator', 'is', 'the', 'standard', 'deviation', 'with', 'N', 'number', 'of', 'data', 'samples', 'xi', 'data', 'sample', 'at', 'ith', 'location', 'in', 'a', 'dataset', 'and', 'µ', 'mean', '8', 'Experimental', 'details', 'and', 'results', 'The', 'experiments', 'divide', 'each', 'augmented', 'group', 'numerals', 'and', 'alphabets', 'into', 'train', 'and', 'validation', 'set', 'in', 'the', 'ratio', 'of', '75', '25', 'The', 'user', 's', 'sample', 'image', 'of', 'an', 'Indian', 'sign', 'is', 'either', 'placed', 'in', 'a', 'validation', 'or', 'train', 'set', 'but', 'not', 'in', 'both', 'The', 'input', 'image', 's', 'size', 'is', '224', '224', 'and', 'the', 'number', 'of', 'epochs', 'is', '100', 'for', 'the', 'training', 'process', 'The', 'experiments', 'for', 'comprehensive', 'analysis', 'follow', 'the', 'steps', 'as', 'explained', 'in', 'Section', '2', 'with', 'first', 'tuning', 'the', 'batch', 'size', 'followed', 'by', 'optimizing', 'the', 'models', 'and', 'tuning', 'the', 'hy', 'perparameters', 'on', 'numerals', 'and', 'last', 'evaluating', 'the', 'recognition', 'performance', 'of', 'optimized', 'deep', 'models', 'on', 'both', 'numerals', 'and', 'alphabets', 'of', 'the', 'ISL', 'dataset', 'This', 'work', 'does', 'not', 'include', 'those', 'results', 'in', 'which', 'a', 'model', 'stops', 'learning', 'any', 'new', 'knowledge', 'with', 'very', 'high', 'error', 'values', 'The', 'hardware', 'used', 'for', 'the', 'implementation', 'of', 'the', 'comprehensive', 'analysis', 'is', 'Nvidia', 'GeForce', 'GTX', '1080Ti', 'with', 'This', 'subsection', 'analyzes', 'the', 'impact', 'of', 'batch', 'size', 'on', 'the', 'recog', 'nition', 'performance', 'of', 'InceptionV3', 'on', 'the', 'Numerals', 'subset', 'of', 'the', 'ISL', 'dataset', 'by', 'fixing', 'the', 'other', 'hyperparameters', 'such', 'as', 'learning', 'rate', '1e', '5', 'is', 'used', 'with', 'Adam', 'optimizer', 'According', 'to', 'exper', 'imental', 'results', 'batch', 'size', '8', 'achieved', 'the', 'highest', 'recognition', 'accuracy', 'of', '83', '8', 'on', 'Numerals', 'subset', 'This', 'result', 'indicates', 'that', 'the', 'selection', 'of', 'smaller', 'batch', 'size', 'is', 'a', 'valuable', 'heuristic', 'towards', 'good', 'optimization', 'However', 'convergence', 'speed', 'and', 'the', 'frequent', 'variation', 'of', 'validation', 'loss', 'values', 'throughout', 'the', 'training', 'process', 'increases', 'with', 'increasing', 'batch', 'size', 'leading', 'to', 'an', 'increase', 'in', 'the', 'final', 'loss', 'value', 'as', 'shown', 'in', 'Fig', '5', 'Batch', 'size', '8', 'performed', 'better', 'than', 'others', 'due', 'to', 'noisy', 'gradients', 'in', 'small', 'batch', 'size', 'which', 'prevents', 'the', 'model', 'from', 'being', 'trapped', 'in', 'sharp', 'mini', 'mizers', 'and', 'encourage', 'it', 'to', 'move', 'forward', 'towards', 'more', 'flatter', 'minimizers', '53', 'That', 'is', 'how', 'the', 'small', 'batch', 'size', 'helps', 'the', 'model', 'to', 'reach', 'global', 'minima', 'smoothly', 'The', 'subsequent', 'experiments', 'of', 'optimizing', 'deep', 'models', 'and', 'tuning', 'other', 'hyperparameters', 'use', 'batch', 'size', '8', 'for', 'the', 'training', 'process', '8', '2', 'Tuning', 'of', 'SGD', 'optimizer', 's', 'hyperparameters', 'This', 'work', 'analyzes', 'SGD', 'optimizer', 's', 'performance', 'utilizing', 'a', 'range', 'of', 'learning', 'rates', '1e', '1', '1e', '1', '1e', '5', 'with', 'and', 'without', 'momentum', 'values', '0', '5', '0', '6', 'and', 'NAG', 'using', 'InceptionV3', 'on', 'the', 'ISL', 'dataset', 's', 'Numerals', 'subset', 'Although', 'through', 'experi', 'ments', 'SGD', 'with', 'momentum', 'and', 'NAG', 'show', 'promising', 'results', 'for', 'learning', 'rates', '1e', '4', 'and', '1e', '5', 'the', 'highest', 'recognition', 'accuracy', 'of', '82', '5', 'is', 'achieved', 'with', 'learning', 'rate', '1e', '3', 'and', 'when', 'SGD', 'uses', 'momentum', '0', '5', 'without', 'NAG', 'SGD', 'with', 'M', '0', '9', 'and', 'NAG', 'using', 'learning', 'rate', '1e', '4', 'also', 'attained', 'almost', 'similar', 'recognition', 'accuracy', 'of', '81', '8', 'Fig', '6', 'shows', 'that', 'the', 'learning', 'rate', 'lower', 'than', '1e', '3', 'degrades', 'the', 'model', 's', 'performance', 'when', 'SGD', 'uses', 'only', 'the', 'momentum', 'and', 'the', 'learning', 'rate', 'higher', 'than', '1e', '3', 'stops', 'the', 'model', 's', 'learning', 'with', 'both', 'momentum', 'and', 'NAG', 'For', 'lower', 'learning', 'rates', 'momentum', 'and', 'NAG', 'help', 'by', 'speeding', 'the', 'training', 'process', 'by', 'helping', 'it', 'to', 'pass', 'through', 'the', 'right', 'path', 'thereby', 'leading', 'fastly', 'to', 'the', 'convergence', 'point', 'For', 'higher', 'learning', 'rates', 'momentum', 'and', 'NAG', 'do', 'not', 'help', 'much', 'as', 'a', 'high', 'learning', 'rate', 'itself', 'speeds', 'up', 'the', 'process', 'of', 'convergence', 'but', 'usually', 'on', 'the', 'wrong', 'path', 'These', 'insights', 'are', 'also', 'reflected', 'in', 'the', 'experimental', 'results', 'Table', '2', 'shows', 'the', 'metrics', 'like', 'loss', 'recall', 'precision', 'f1', 'score', 'CV', 'and', 'percentage', 'of', 'errors', 'in', 'the', 'validation', 'set', 'for', 'all', 'the', 'learning', 'rates', 'using', 'SGD', 'with', 'and', 'without', 'momentum', 'and', 'NAG', 'These', 'results', 'SGD', 'uses', 'the', 'selected', 'hyperparameter', 's', 'setting', 'to', 'compare', 'its', 'performance', 'with', 'other', 'optimizers', 'in', 'the', 'subsequent', 'subsections', '7', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'Fig', '6', 'Tuning', 'of', 'learning', 'rate', 'momentum', 'and', 'NAG', 'for', 'SGD', 'optimizer', 'a', 'd', 'Validation', 'loss', 'evolution', 'for', 'learning', 'rates', '1e', '2', '1e', '5', 'Table', '2', 'Evaluation', 'metrics', 'for', 'tuning', 'of', 'SGD', 'Optimizer', 's', 'hyperparameters', 'LR', 'M', 'N', 'Train', 'loss', 'CV', 'for', 'train', 'CVT', '1e', '2', '0', '0', '1e', '3', '0', '5', '1e', '4', '0', '9', '1e', '5', '0', '9', '0', '12', '0', '05', '0', '06', '0', '20', '0', '73', '0', '94', '0', '33', '0', '60', 'Val', 'loss', '0', '81', '0', '57', '0', '59', '1', '05', 'CV', 'for', 'Val', 'CVV', 'Train', 'acc', 'Val', 'acc', 'Precision', 'Recall', 'f1', 'score', 'Val', 'errors', '0', '24', '0', '33', '0', '32', '0', '21', '95', '9', '98', '1', '98', '1', '93', '3', '77', '2', '82', '5', '81', '8', '65', '6', '0', '79', '0', '83', '0', '82', '0', '68', '0', '77', '0', '82', '0', '82', '0', '66', '0', '77', '0', '83', '0', '82', '0', '66', '22', '7', '17', '7', '18', '2', '34', '3', 'Note', 'LR', 'is', 'learning', 'rate', 'M', 'is', 'momentum', 'N', 'is', 'NAG', '8', '3', 'Tuning', 'of', 'learning', 'rate', 'for', 'adaptive', 'optimizers', 'The', 'comparative', 'evaluation', 'and', 'tuning', 'of', 'adaptive', 'optimizers', 'uses', 'InceptionV3', 'model', 'batch', 'size', '8', 'learning', 'rates', '1e', '1', '1e', '1', '1e', '5', 'as', 'used', 'in', 'Section', '8', '2', 'and', 'the', 'Numerals', 'subset', 'of', 'the', 'dataset', 'Fig', '7', 'a', 'b', 'shows', 'the', 'performance', 'results', 'of', 'AdaDelta', 'on', 'ISL', 'dataset', 's', 'Numerals', 'with', 'various', 'learning', 'rates', 'The', 'learning', 'rate', '1e', '1', 'suffers', 'from', 'increasing', 'validation', 'loss', 'evolution', 'with', 'frequent', 'ups', 'and', 'downs', 'i', 'e', 'high', 'CVV', 'because', 'high', 'learning', 'rates', 'try', 'to', 'converge', 'faster', 'and', 'get', 'stuck', 'in', 'the', 'local', 'minima', 'before', 'reaching', 'the', 'desired', 'global', 'minima', 'The', 'lower', 'learning', 'rates', '1e', '4', 'and', '1e', '5', 'converges', 'very', 'slow', 'as', 'observed', 'from', 'Fig', '7', 'a', 'The', 'experimental', 'results', 'show', 'that', 'the', 'learning', 'rate', '1e', '2', 'performs', 'better', 'than', 'the', 'other', 'learning', 'rate', 'values', 'In', 'AdaGrad', 'if', 'the', 'initial', 'gradients', 'are', 'large', 'the', 'learning', 'rate', 'becomes', 'low', 'Eq', '9', 'which', 'makes', 'it', 'difficult', 'for', 'the', 'model', 'to', 'learn', 'new', 'knowledge', 'as', 'given', 'in', 'Section', '5', '2', 'According', 'to', 'experiments', 'the', 'model', 'stops', 'learning', 'with', 'learning', 'rates', '1e', '1', 'and', '1e', '2', 'and', 'the', 'learning', 'rate', '1e', '3', 'achieves', 'relatively', 'better', 'recognition', 'performance', 'compared', 'to', 'other', 'learning', 'rates', 'However', 'the', 'convergence', 'speed', 'becomes', 'too', 'slow', 'for', 'all', 'the', 're', 'maining', 'learning', 'rates', 'indicating', 'no', 'learning', 'of', 'new', 'knowledge', 'and', 'thus', 'it', 'seems', 'almost', 'saturated', 'as', 'observed', 'from', 'Fig', '7', 'b', 'Experimental', 'results', 'for', 'Adam', 'show', 'that', 'the', 'model', 'stops', 'learning', 'with', 'learning', 'rates', '1e', '1', '1e', '2', 'and', '1e', '3', 'Out', 'of', 'learning', 'rates', '1e', '4', 'and', '1e', '5', '1e', '4', 'takes', 'more', 'time', 'to', 'train', 'and', 'has', 'more', 'frequent', 'validation', 'loss', 'variations', 'i', 'e', 'high', 'CVV', 'than', '1e', '5', 'as', 'shown', 'in', 'Fig', '7', 'c', 'Thus', 'learning', 'rate', '1e', '5', 'gives', 'better', 'results', 'than', 'the', 'other', 'learning', 'rates', 'for', 'Adam', 'optimizer', 'For', 'RMSProp', 'the', 'model', 'stops', 'learning', 'with', 'learning', 'rates', '1e', '1', '1e', '2', 'and', '1e', '3', 'and', '1e', '5', 'results', 'in', 'better', 'performance', 'than', '1e', '4', 'similar', 'to', 'Adam', 'on', 'Numerals', 'subset', 'The', 'RMSProp', 's', 'validation', 'loss', 'evolution', 'for', 'different', 'learning', 'rates', 'is', 'shown', 'in', 'Fig', '7', 'd', 'Thus', 'based', 'on', 'experimental', 'results', 'AdaDelta', 'uses', 'learning', 'rate', '1e', '2', 'AdaGrad', '1e', '3', 'Adam', '1e', '5', 'and', 'RMSProp', '1e', '5', 'for', 'further', 'evaluation', 'of', 'optimizers', 'in', 'the', 'next', 'subsection', 'Mostly', 'lower', 'learning', 'rates', 'perform', 'better', 'than', 'the', 'higher', 'learning', 'rates', 'In', 'almost', 'all', 'the', 'cases', 'in', 'the', 'paper', 'model', 'has', 'either', 'stopped', 'working', 'on', 'higher', 'learning', 'over', '1e', '3', 'or', 'have', 'given', 'low', 'recognition', 'performance', 'and', 'the', 'reverse', 'is', 'true', 'for', 'the', 'remaining', 'learning', 'rates', 'However', 'the', 'reason', 'why', 'some', 'learning', 'rates', 'among', 'the', 'remaining', 'ones', 'work', 'well', 'on', 'the', 'current', 'application', 'and', 'why', 'some', 'do', 'not', 'is', 'based', 'on', 'trial', 'and', 'error', '8', '4', 'Performance', 'evaluation', 'of', 'tuned', 'optimizers', 'This', 'subsection', 'compares', 'the', 'tuned', 'optimizers', 'and', 'although', 'the', 'experimental', 'results', 'show', 'that', 'Adam', 'takes', 'more', 'time', 'to', 'train', 'than', 'other', 'optimizers', 'it', 'also', 'achieves', 'the', 'highest', 'recognition', 'accuracy', 'of', '83', '79', 'on', 'ISL', 's', 'Numerals', 'subset', 'The', 'performance', 'of', 'SGD', 'is', 'very', 'close', 'to', 'Adam', 's', 'and', 'also', 'has', 'the', 'fastest', 'training', 'process', 'AdaDelta', 'AdaGrad', 'and', 'RMSProp', 'follow', 'Adam', 'and', 'SGD', 'in', 'recognition', 'performance', 'with', 'RMSProp', 'attaining', 'the', 'least', 'performance', 'with', 'the', 'second', 'highest', 'training', 'time', 'after', 'Adam', '8', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'Fig', '7', 'Tuning', 'of', 'learning', 'rate', 'for', 'adaptive', 'optimizers', 'a', 'd', 'Validation', 'loss', 'evolution', 'Table', '3', 'Evaluation', 'metrics', 'for', 'tuned', 'optimizers', 'comparison', 'Optimizer', 'Train', 'loss', 'CV', 'for', 'train', 'CVT', 'SGD', 'AdaGrad', 'AdaDelta', 'RMSProp', 'Adam', '0', '05', '0', '11', '0', '07', '0', '20', '0', '04', '0', '94', '3', '47', '0', '87', '0', '44', '1', '07', 'Val', 'loss', '0', '57', '0', '76', '0', '81', '1', '76', '0', '60', 'CV', 'for', 'val', 'CVV', 'Train', 'acc', 'Val', 'acc', 'Precision', 'Recall', 'f1', 'score', 'Val', 'errors', 'Train', 'time', 's', '0', '33', '1', '75', '0', '24', '0', '08', '0', '31', '98', '1', '96', '5', '97', '9', '95', '8', '98', '5', '82', '5', '74', '9', '81', '8', '74', '0', '83', '8', '0', '83', '0', '76', '0', '82', '0', '76', '0', '84', '0', '82', '0', '75', '0', '82', '0', '74', '0', '83', '0', '83', '0', '75', '0', '82', '0', '74', '0', '83', '17', '7', '24', '8', '18', '3', '25', '8', '16', '4', '246', '288', '380', '456', '470', 'Table', '4', 'Evaluation', 'metrics', 'for', 'CNN', 'models', 'Deep', 'models', 'Train', 'loss', 'CV', 'train', 'CVT', 'Val', 'loss', 'CV', 'val', 'CVV', 'Train', 'acc', 'Val', 'acc', 'Precision', 'Recall', 'f1', 'score', 'Val', 'errors', 'Train', 'time', 's', 'Numerals', 'InceptionV3', 'ResNet152V2', 'InceptionResNetV2', 'ResNeXt101', 'CNN', 'Alphabets', 'InceptionV3', 'ResNet152V2', 'InceptionResNetV2', 'ResNeXt101', 'CNN', '0', '04', '0', '01', '0', '02', '0', '02', '0', '01', '0', '14', '0', '02', '0', '05', '0', '07', '0', '07', '1', '60', '1', '53', '2', '67', '0', '31', '0', '50', '1', '13', '1', '01', '1', '94', '0', '19', '0', '33', '0', '60', '0', '21', '0', '19', '0', '37', '0', '01', '1', '21', '0', '58', '0', '57', '0', '79', '0', '12', '0', '50', '0', '35', '0', '33', '0', '35', '1', '93', '0', '32', '0', '22', '0', '17', '0', '22', '1', '17', '98', '5', '99', '9', '99', '5', '99', '4', '99', '8', '95', '5', '99', '5', '98', '3', '97', '9', '97', '9', '83', '8', '96', '2', '94', '4', '91', '5', '99', '8', '71', '1', '90', '8', '85', '6', '83', '00', '97', '0', '0', '84', '0', '96', '0', '95', '0', '92', '1', '00', '0', '72', '0', '91', '0', '86', '0', '83', '0', '97', '0', '83', '0', '96', '0', '94', '0', '92', '1', '00', '0', '71', '0', '91', '0', '86', '0', '83', '0', '97', '0', '83', '0', '96', '0', '95', '0', '92', '1', '00', '0', '71', '0', '91', '0', '86', '0', '83', '0', '97', '16', '4', '4', '1', '5', '6', '8', '7', '0', '2', '28', '8', '9', '2', '14', '3', '17', '2', '3', '0', '470', '665', '501', '1215', '226', '801', '1536', '1253', '2956', '568', 'Table', '3', 'shows', 'the', 'metrics', 'that', 'evaluate', 'the', 'tuned', 'optimizers', 'The', 'reason', 'of', 'these', 'results', 'is', 'well', 'presented', 'in', 'Section', '5', 'The', 'fol', 'lowing', 'subsection', 'uses', 'Adam', 'optimizer', 'for', 'further', 'deep', 'models', 'comparison', '8', '5', 'Performance', 'evaluation', 'of', 'CNN', 'models', 'The', 'comparative', 'evaluation', 'shows', 'that', 'among', 'pre', 'trained', 'deep', 'models', 'ResNet152V2', 'performs', 'better', 'than', 'other', 'mod', 'els', 'with', 'a', 'recognition', 'accuracy', 'of', '96', '18', 'and', '90', '84', 'on', 'the', 'ISL', 'dataset', 's', 'Numerals', 'and', 'Alphabets', 'subsets', 'respectively', 'The', 'performance', 'of', 'InceptionResNetV2', 'is', 'closer', 'to', 'ResNet152V2', 'on', 'both', 'the', 'Numerals', 'and', 'Alphabets', 'but', 'has', 'the', 'frequently', 'changing', 'validation', 'loss', 'values', 'over', '100', 'epochs', 'leading', 'to', 'increased', 'CVV', 'as', 'shown', 'in', 'Table', '4', 'Although', 'InceptionV3', 'takes', 'less', 'time', 'to', 'train', 'it', 'shows', 'the', 'least', 'performance', 'on', 'both', 'the', 'ISL', 'dataset', 'subsets', 'ResNeXt101', 'performs', 'better', 'than', 'InceptionV3', 'but', 'not', 'better', 'than', 'the', 'other', 'pre', 'trained', 'deep', 'models', 'These', 'results', 'show', 'that', 'pure', 'resnet', 'work', 'well', 'in', 'the', 'SLR', 'application', 'due', 'to', 'concept', 'of', 'skip', 'connections', 'that', 'tackles', 'the', 'vanishing', 'gradient', 'problem', 'and', 'make', 'the', 'model', 'more', 'robust', 'to', 'many', 'layers', 'The', 'designing', 'and', 'training', 'of', 'a', 'model', 'from', 'scratch', 'has', 'to', 'go', 'through', 'several', 'trials', 'to', 'decide', 'the', 'number', 'of', 'CNN', 'layers', 'regularization', 'techniques', 'and', 'structural', 'parameters', 'e', 'g', 'hidden', 'units', 'and', 'pool', 'size', 'Thus', 'if', 'there', 'are', 'limitations', 'on', 'computational', 'resources', 'and', 'decision', 'making', 'time', 'the', 'models', 'already', 'trained', 'on', 'the', '9', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'Fig', '8', 'Training', 'and', 'validation', 'loss', 'evolution', 'for', 'pre', 'trained', 'and', 'the', 'proposed', 'CNN', 'models', 'Left', 'For', 'numerals', 'and', 'Right', 'For', 'alphabets', 'of', 'ISL', 'dataset', 'Table', '5', 'Comparison', 'with', 'state', 'of', 'the', 'art', 'approaches', 'Models', 'References', '51', '54', 'InceptionV3', 'ResNet152V2', 'InceptionResNetV2', 'ResNeXt101', 'Proposed', 'CNN', 'Accuracy', 'numerals', '72', '07', '68', '8', '83', '79', '96', '18', '94', '42', '91', '46', '99', '76', 'Accuracy', 'alphabets', '57', '03', '55', '11a', '78', '67a', '71', '09', '71', '12a', '90', '84', '91', '22a', '85', '65', '85', '8a', '83', '04', '83', '16a', '97', '96', '74', 'a', 'a18', 'Alphabets', 'A', 'S', 'excluding', 'J', 'ImageNet', 'dataset', 'yield', 'good', 'results', 'for', 'static', 'Indian', 'SLR', 'without', 'training', 'the', 'whole', 'model', 'However', 'the', 'ImageNet', 'is', 'a', 'generic', 'object', 'recognition', 'dataset', 'different', 'from', 'a', 'sign', 'language', 'dataset', 'and', 'thus', 'the', 'CNN', 's', 'lower', 'layers', 'help', 'the', 'model', 'learn', 'the', 'features', 'of', 'the', 'new', 'data', 'rather', 'than', 'the', 'higher', 'layers', 'The', 'proposed', 'three', 'layered', 'CNN', 'model', 'outperformed', 'the', 'pre', 'trained', 'models', 'with', 'a', 'recognition', 'accuracy', 'of', '99', '76', 'on', 'Numerals', 'and', '97', '00', 'on', 'Alphabets', 'subset', 'of', 'the', 'ISL', 'dataset', 'This', 'result', 'shows', 'that', 'training', 'even', 'a', 'small', 'CNN', 'model', 'from', 'scratch', 'on', 'the', 'new', 'dataset', 'can', 'prove', 'better', 'than', 'the', 'transfer', 'learning', 'technique', 'when', 'the', 'pre', 'trained', 'models', 'have', 'been', 'trained', 'on', 'a', 'different', 'dataset', 'than', 'the', 'dataset', 'at', 'hand', 'Training', 'the', 'small', 'CNN', 'model', 'from', 'scratch', 'is', 'also', 'faster', 'than', 'fine', 'tuning', 'the', 'pre', 'trained', 'models', 'Thus', 'it', 'seems', 'that', 'pre', 'trained', 'models', 'are', 'not', 'able', 'to', 'adapt', 'the', 'sign', 'language', 'datasets', 'properly', 'which', 'can', 'be', 'seen', 'from', 'the', 'frequent', 'variations', 'in', 'the', 'test', 'loss', 'evolution', 'of', 'the', 'pre', 'trained', 'models', 'compared', 'to', 'the', 'proposed', 'CNN', 'model', 'in', 'Fig', '8', 'Fig', '8', 'shows', 'the', 'training', 'and', 'validation', 'loss', 'evolution', 'and', 'Table', '4', 'gives', 'the', 'metrics', 'such', 'as', 'training', 'time', 'validation', 'errors', 'f1', 'score', 'CVV', 'loss', 'recall', 'and', 'precision', 'to', 'evaluate', 'the', 'deep', 'models', 'The', 'confusion', 'matrices', 'of', 'the', 'deep', 'models', 'are', 'given', 'in', 'Fig', '9', 'for', 'Numerals', 'and', 'in', 'Fig', '10', 'for', 'Alphabets', 'subset', '8', '6', 'Performance', 'comparison', 'of', 'proposed', 'work', 'with', 'state', 'of', 'the', 'art', 'Raghuveera', 'et', 'al', '54', 'and', 'the', 'developers', '51', 'of', 'the', 'ISL', 'dataset', 'extracted', 'the', 'hand', 'crafted', 'features', 'from', 'the', 'input', 'images', 'and', 'classified', 'them', 'using', 'machine', 'learning', 'algorithms', 'The', 'pro', 'posed', 'three', 'layered', 'CNN', 'model', 'outperforms', 'the', 'work', 'of', 'Ansari', 'and', 'Harit', '51', 'by', '38', '4', 'and', '70', '1', 'on', 'Numerals', 'and', 'Alphabets', 'subset', 'respectively', 'Raghuveera', 'et', 'al', '54', 'worked', 'on', 'both', 'the', 'subsets', 'of', 'the', 'ISL', 'dataset', 'and', 'showed', 'the', 'recognition', 'accuracy', 'on', 'all', 'numerals', 'but', 'only', 'on', '18', 'alphabets', 'Thus', 'the', 'average', 'recognition', 'accuracy', 'of', 'both', '18', 'and', '24', 'alphabets', 'is', 'shown', 'in', 'Table', '5', 'for', 'a', 'fair', 'comparison', 'with', 'literature', 'The', 'proposed', 'CNN', 'model', 'outperforms', 'the', 'work', 'of', 'Raghuveera', 'et', 'al', '54', 'by', '45', 'on', 'Numerals', 'and', '23', 'on', '18', 'alphabets', 'of', 'the', 'ISL', 'dataset', 'Among', 'the', 'already', 'trained', 'deep', 'models', 'ResNet152V2', 'outperforms', 'the', 'Fig', '9', 'Confusion', 'matrix', 'for', 'deep', 'models', 'on', 'ISL', 'Dataset', 's', 'numerals', 'work', 'of', 'Ansari', 'and', 'Harit', '51', 'and', 'Raghuveera', 'et', 'al', '54', 'by', '33', '4', 'and', '39', '8', 'on', 'Numerals', 'and', 'by', '45', '6', 'and', '5', '7', 'on', 'Alphabets', 'of', 'the', 'ISL', 'dataset', 'respectively', 'as', 'shown', 'in', 'Table', '5', 'These', 'results', 'show', 'that', 'the', 'features', 'extracted', 'using', 'the', 'proposed', 'CNN', 'model', 'and', 'the', 'other', 'pre', 'trained', 'deep', 'models', 'are', 'highly', 'efficient', 'and', 'informative', 'than', 'the', 'hand', 'crafted', 'features', 'Selection', 'of', 'the', 'right', 'optimizer', 'and', 'tuning', 'of', 'hyperparameters', 'also', 'helps', 'in', 'highly', 'improving', 'the', 'deep', 'models', 'recognition', 'performance', '9', 'Conclusion', 'This', 'manuscript', 'presents', 'the', 'first', 'comprehensive', 'evaluation', 'of', 'a', 'proposed', 'three', 'layered', 'CNN', 'architecture', 'four', 'popular', 'pre', 'trained', 'deep', 'models', 'gradient', 'based', 'optimizers', 'and', 'optimization', 'hyperparameters', 'for', 'static', 'ISL', 'recognition', 'to', 'the', 'best', 'of', 'our', 'knowledge', 'The', 'comparative', 'analysis', 'is', 'motivated', 'by', 'the', 'prolif', 'eration', 'and', 'thus', 'lack', 'of', 'systematic', 'comparative', 'evaluation', 'of', 'pre', 'trained', 'deep', 'architectures', 'trained', 'on', 'ImageNet', 'dataset', 'with', 'their', 'hyperparameters', 'This', 'paper', 's', 'deep', 'models', 'are', 'inceptions', 'resnets', 'and', 'variants', 'and', 'a', 'small', 'three', 'layered', 'CNN', 'model', 'is', '10', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', 'Fig', '10', 'Confusion', 'matrix', 'for', 'deep', 'models', 'on', 'ISL', 'Dataset', 's', 'alphabets', 'trained', 'from', 'scratch', 'The', 'performance', 'evaluation', 'reports', 'metrics', 'such', 'as', 'accuracy', 'loss', 'precision', 'recall', 'f', '1', 'score', 'and', 'coefficient', 'of', 'variation', 'for', 'each', 'model', 'run', 'The', 'proposed', 'CNN', 'model', 'trained', 'from', 'scratch', 'and', 'ResNet152V2', 'achieves', 'the', 'highest', 'recognition', 'performance', 'on', 'the', 'ISL', 'dataset', 's', 'Numerals', 'and', 'Alphabets', 'through', 'experimental', 'results', 'All', 'the', 'deep', 'models', 'highly', 'outperform', 'the', 'state', 'of', 'the', 'art', 'machine', 'learning', 'techniques', 'and', 'hand', 'crafted', 'features', 'This', 'comparative', 'analysis', 'can', 'be', 'used', 'as', 'a', 'reference', 'for', 'researchers', 'to', 'select', 'the', 'suitable', 'deep', 'model', 'optimizer', 'and', 'hyperparameters', 'for', 'the', 'static', 'ISL', 'recognition', 'CRediT', 'authorship', 'contribution', 'statement', 'Prachi', 'Sharma', 'Conceptualization', 'Methodology', 'Software', 'Data', 'curation', 'Writing', 'original', 'draft', 'Visualization', 'Investiga', 'tion', 'Validation', 'Radhey', 'Shyam', 'Anand', 'Supervision', 'Writing', 'review', 'editing', '4', 'Dahmani', 'D', 'Larabi', 'S', 'User', 'independent', 'system', 'for', 'sign', 'language', 'finger', 'spelling', 'recognition', 'J', 'Vis', 'Commun', 'Image', 'Represent', '2014', '25', '5', '1240', '50', 'http', 'dx', 'doi', 'org', '10', '1016', 'j', 'jvcir', '2013', '12', '019', '5', 'Fagiani', 'M', 'Principi', 'E', 'Squartini', 'S', 'Piazza', 'F', 'Signer', 'independent', 'isolated', 'Italian', 'sign', 'recognition', 'based', 'on', 'hidden', 'Markov', 'models', 'Pattern', 'Anal', 'Appl', '2015', '18', '2', '385', '402', 'http', 'dx', 'doi', 'org', '10', '1007', 's10044', '014', '0400', 'z', '6', 'Roy', 'PP', 'Kumar', 'P', 'Kim', 'B', 'G', 'An', 'efficient', 'sign', 'language', 'recognition', 'SLR', 'system', 'using', 'camshift', 'tracker', 'and', 'hidden', 'Markov', 'model', 'HMM', 'SN', 'Comput', 'Sci', '2021', '2', '2', '1', '15', '7', 'Fukushima', 'K', 'Neocognitron', 'A', 'self', 'organizing', 'neural', 'network', 'model', 'for', 'a', 'mechanism', 'of', 'pattern', 'recognition', 'unaffected', 'by', 'shift', 'in', 'position', 'Biol', 'Cybernet', '1980', '36', '4', '193', '202', 'http', 'dx', 'doi', 'org', '10', '1007', 'BF00344251', '8', 'Rastgoo', 'R', 'Kiani', 'K', 'Escalera', 'S', 'Real', 'time', 'isolated', 'hand', 'sign', 'language', 'J', 'Ambient', 'Intell', 'Humaniz', 'recognition', 'using', 'deep', 'networks', 'and', 'SVD', 'Comput', '2021', '1', '21', '9', 'Ben', 'Slimane', 'F', 'Bouguessa', 'M', 'Context', 'Matters', 'Self', 'Attention', 'for', 'Sign', 'Language', 'Recognition', '2021', 'arXiv', 'e', 'prints', 'arXiv', '2101', '10', 'Sharma', 'P', 'Anand', 'RS', 'Depth', 'data', 'and', 'fusion', 'of', 'feature', 'descriptors', 'for', 'IET', 'Image', 'Process', '2020', '14', '5', '909', '20', 'http', 'static', 'gesture', 'recognition', 'dx', 'doi', 'org', '10', '1049', 'iet', 'ipr', '2019', '0230', 'Jiang', 'S', 'Sun', 'B', 'Wang', 'L', 'Bai', 'Y', 'Li', 'K', 'Fu', 'Y', 'Skeleton', 'aware', 'multi', 'modal', 'sign', 'language', 'recognition', '2021', 'arXiv', 'preprint', 'arXiv', '2103', '08833', 'Declaration', 'of', 'competing', 'interest', '11', 'The', 'authors', 'declare', 'that', 'they', 'have', 'no', 'known', 'competing', 'finan', 'cial', 'interests', 'or', 'personal', 'relationships', 'that', 'could', 'have', 'appeared', 'to', 'influence', 'the', 'work', 'reported', 'in', 'this', 'paper', 'Acknowledgments', 'The', 'authors', 'are', 'thankful', 'to', 'the', 'Ministry', 'of', 'Education', 'MoE', 'earlier', 'Ministry', 'of', 'Human', 'Resource', 'Development', 'MHRD', 'under', 'the', 'Government', 'of', 'India', 'for', 'financial', 'support', 'in', 'pursuing', 'the', 'proposed', 'work', 'References', '1', 'Card', 'SK', 'Moran', 'TP', 'Newwell', 'A', 'The', 'psychology', 'of', 'human', 'computer', 'interaction', 'Hillsdale', 'NJ', 'Lawrence', 'Erlbaum', 'Associates', '1983', '2', 'Li', 'Y', 'Chen', 'X', 'Zhang', 'X', 'Wang', 'K', 'Wang', 'ZJ', 'A', 'sign', 'component', 'based', 'framework', 'for', 'Chinese', 'sign', 'language', 'recognition', 'using', 'accelerometer', 'and', 'sEMG', 'data', 'IEEE', 'Trans', 'Biomed', 'Eng', '2012', '59', '10', '2695', '704', 'http', 'dx', 'doi', 'org', '10', '1109', 'TBME', '2012', '2190734', '3', 'Yang', 'H', 'D', 'Lee', 'S', 'W', 'Robust', 'sign', 'language', 'recognition', 'by', 'combining', 'manual', 'and', 'non', 'manual', 'features', 'based', 'on', 'conditional', 'random', 'field', 'and', 'support', 'vector', 'machine', 'Pattern', 'Recognit', 'Lett', '2013', '34', '16', '2051', '6', 'http', 'dx', 'doi', 'org', '10', '1016', 'j', 'patrec', '2013', '06', '022', '12', 'Kumar', 'P', 'Saini', 'R', 'Roy', 'PP', 'Dogra', 'DP', 'A', 'position', 'and', 'rotation', 'invariant', 'framework', 'for', 'sign', 'language', 'recognition', 'SLR', 'using', 'Kinect', 'Multimedia', 'Tools', 'Appl', '2018', '77', '7', '8823', '46', 'Jebali', 'M', 'Dakhli', 'A', 'recognition', 'using', 'multimodal', 'sensor', 'fusion', 'Evol', 'Syst', '2021', '1', '14', 'Jemni', 'M', 'Vision', 'based', 'continuous', 'sign', 'language', '13', '14', 'Abiyev', 'RH', 'Arslan', 'M', 'Idoko', 'JB', 'Sign', 'language', 'translation', 'using', 'deep', 'convolutional', 'neural', 'networks', 'KSII', 'Trans', 'Internet', 'Inf', 'Syst', '2020', '14', '2', 'http', 'dx', 'doi', 'org', '10', '3837', 'tiis', '2020', '02', '009', '15', 'Szegedy', 'C', 'Vanhoucke', 'V', 'Ioffe', 'S', 'Shlens', 'J', 'Wojna', 'Z', 'Rethinking', 'the', 'inception', 'architecture', 'for', 'computer', 'vision', 'In', 'Proceedings', 'of', 'the', 'IEEE', 'conference', 'on', 'computer', 'vision', 'and', 'pattern', 'recognition', '2016', 'p', '2818', '26', 'http', 'dx', 'doi', 'org', '10', '1109', 'CVPR', '2016', '308', '16', 'Wu', 'D', 'Pigou', 'L', 'Kindermans', 'P', 'J', 'Le', 'ND', 'H', 'Shao', 'L', 'Dambre', 'J', 'et', 'al', 'Deep', 'dynamic', 'neural', 'networks', 'for', 'multimodal', 'gesture', 'segmentation', 'and', 'recognition', 'IEEE', 'Trans', 'Pattern', 'Anal', 'Mach', 'Intell', '2016', '38', '8', '1583', '97', 'http', 'dx', 'doi', 'org', '10', '1109', 'TPAMI', '2016', '2537340', '17', 'Duan', 'J', 'Wan', 'J', 'Zhou', 'S', 'Guo', 'X', 'Li', 'SZ', 'A', 'unified', 'framework', 'for', 'multi', 'modal', 'isolated', 'gesture', 'recognition', 'ACM', 'Trans', 'Multimed', 'Comput', 'Commun', 'Appl', 'TOMM', '2018', '14', '1s', '1', '16', 'http', 'dx', 'doi', 'org', '10', '1145', '3131343', '18', 'Liao', 'Y', 'Xiong', 'P', 'Min', 'W', 'Min', 'W', 'Lu', 'J', 'Dynamic', 'sign', 'language', 'recognition', 'based', 'on', 'video', 'sequence', 'with', 'BLSTM', '3D', 'residual', 'networks', 'IEEE', 'Access', '2019', '7', '38044', '54', 'http', 'dx', 'doi', 'org', '10', '1109', 'ACCESS', '2019', '2904749', '19', 'Koller', 'O', 'Zargaran', 'O', 'Ney', 'H', 'Bowden', 'R', 'Deep', 'sign', 'Hybrid', 'CNN', 'HMM', 'for', 'continuous', 'sign', 'language', 'recognition', 'In', 'Proceedings', 'of', 'the', 'British', 'machine', 'vision', 'conference', '2016', '2016', '11', 'P', 'Sharma', 'and', 'R', 'S', 'Anand', 'Graphics', 'and', 'Visual', 'Computing', '5', '2021', '200032', '20', 'Szegedy', 'C', 'Liu', 'W', 'Jia', 'Y', 'Sermanet', 'P', 'Reed', 'S', 'Anguelov', 'D', 'et', 'al', 'Going', 'deeper', 'with', 'convolutions', 'In', 'Proceedings', 'of', 'the', 'IEEE', 'conference', 'on', 'computer', 'vision', 'and', 'pattern', 'recognition', '2015', 'p', '1', '9', 'http', 'dx', 'doi', 'org', '10', '1109', 'CVPR', '2015', '7298594', '21', 'Kumar', 'P', 'Gauba', 'H', 'Roy', 'PP', 'Dogra', 'DP', 'Coupled', 'HMM', 'based', 'multi', 'sensor', 'data', 'fusion', 'for', 'sign', 'language', 'recognition', 'Pattern', 'Recognit', 'Lett', '2017', '86', '1', '8', '22', 'Rastgoo', 'R', 'Kiani', 'K', 'Escalera', 'S', 'Multi', 'modal', 'deep', 'hand', 'sign', 'language', 'recognition', 'in', 'still', 'images', 'using', 'restricted', 'Boltzmann', 'machine', 'Entropy', '2018', '20', '11', '809', '23', 'Liang', 'Z', 'j', 'Liao', 'S', 'b', 'Hu', 'B', 'z', '3D', 'convolutional', 'neural', 'networks', 'for', 'dynamic', 'sign', 'language', 'recognition', 'Comput', 'J', '2018', '61', '11', '1724', '36', 'http', 'dx', 'doi', 'org', '10', '1093', 'comjnl', 'bxy049', '24', 'Ravi', 'S', 'Suman', 'M', 'Kishore', 'P', 'Kumar', 'K', 'Kumar', 'A', 'et', 'al', 'Multi', 'modal', 'spatio', 'temporal', 'co', 'trained', 'CNNs', 'with', 'single', 'modal', 'testing', 'on', 'RGB', 'D', 'based', 'sign', 'language', 'gesture', 'recognition', 'J', 'Computer', 'Languages', '2019', '52', '88', '102', 'http', 'dx', 'doi', 'org', '10', '1016', 'j', 'cola', '2019', '04', '002', '25', 'Pratt', 'LY', 'Discriminability', 'based', 'transfer', 'between', 'neural', 'networks', 'In', 'Advances', 'information', 'processing', 'systems', '1993', 'p', '204', '211', 'http', 'papers', 'nips', 'cc', 'paper', '641', 'discriminability', 'based', 'transfer', 'between', 'neural', 'networks', 'pdf', 'in', 'neural', '26', 'Töngi', 'R', 'Application', 'of', 'transfer', 'learning', 'to', 'sign', 'language', 'recognition', 'using', 'an', 'inflated', '3D', 'deep', 'convolutional', 'neural', 'network', '2021', 'arXiv', 'preprint', 'arXiv', '2103', '05111', '27', 'Halvardsson', 'G', 'Peterson', 'J', 'Soto', 'Valero', 'C', 'Baudry', 'B', 'Interpretation', 'of', 'Swedish', 'sign', 'language', 'using', 'convolutional', 'neural', 'networks', 'and', 'transfer', 'learning', 'SN', 'Comput', 'Sci', '2021', '2', '3', '1', '15', '28', 'Deng', 'J', 'Dong', 'W', 'Socher', 'R', 'Li', 'L', 'J', 'Li', 'K', 'Fei', 'Fei', 'L', 'Imagenet', 'A', 'large', 'scale', 'hierarchical', 'image', 'database', 'In', '2009', 'IEEE', 'conference', 'on', 'computer', 'vision', 'and', 'pattern', 'recognition', 'Ieee', '2009', 'p', '248', '55', 'http', 'dx', 'doi', 'org', '10', '1109', 'CVPR', '2009', '5206848', '29', 'Krizhevsky', 'A', 'Sutskever', 'Imagenet', 'classification', 'with', 'deep', 'convolutional', 'neural', 'networks', 'In', 'Advances', 'in', 'neural', 'information', 'processing', 'systems', '2012', 'p', '1097', '105', 'http', 'dx', 'doi', 'org', '10', '1145', '3065386', '30', 'Ozcan', 'T', 'Basturk', 'A', 'Transfer', 'learning', 'based', 'convolutional', 'neural', 'networks', 'with', 'heuristic', 'optimization', 'for', 'hand', 'gesture', 'recognition', 'Neural', 'Comput', 'Appl', '2019', '31', '12', '8955', '70', 'http', 'dx', 'doi', 'org', '10', '1007', 's00521', '019', '04427', 'y', 'I', 'Hinton', 'GE', '31', 'Wadhawan', 'A', 'Kumar', 'P', 'Deep', 'learning', 'based', 'sign', 'language', 'recognition', 'system', 'for', 'static', 'signs', 'Neural', 'Comput', 'Appl', '2020', '1', '12', 'http', 'dx', 'doi', 'org', '10', '1007', 's00521', '019', '04691', 'y', '35', 'Xie', 'S', 'Girshick', 'R', 'Dollár', 'P', 'Tu', 'Z', 'He', 'K', 'Aggregated', 'residual', 'transformations', 'for', 'deep', 'neural', 'networks', 'In', 'Proceedings', 'of', 'the', 'IEEE', 'conference', 'on', 'computer', 'vision', 'and', 'pattern', 'recognition', '2017', 'p', '1492', '500', 'http', 'dx', 'doi', 'org', '10', '1109', 'CVPR', '2017', '634', '36', 'He', 'K', 'Zhang', 'X', 'Ren', 'S', 'Sun', 'J', 'Deep', 'residual', 'learning', 'for', 'image', 'recognition', 'In', 'Proceedings', 'of', 'the', 'IEEE', 'conference', 'on', 'computer', 'vision', 'and', 'pattern', 'recognition', '2016', 'p', '770', '8', 'http', 'dx', 'doi', 'org', '10', '1109', 'CVPR', '2016', '90', '37', 'Sivaprasad', 'PT', 'Mai', 'F', 'Vogels', 'T', 'Jaggi', 'M', 'Fleuret', 'F', 'Optimizer', 'benchmarking', 'needs', 'to', 'account', 'for', 'hyperparameter', 'tuning', 'In', 'International', 'conference', 'on', 'machine', 'learning', 'PMLR', '2020', 'p', '9036', '45', '38', 'Robbins', 'H', 'Monro', 'S', 'A', 'stochastic', 'approximation', 'method', 'Ann', 'Math', 'Stat', '1951', '400', '7', 'http', 'dx', 'doi', 'org', '10', '1214', 'aoms', '1177729586', '39', 'Kiefer', 'J', 'Wolfowitz', 'J', 'et', 'al', 'Stochastic', 'estimation', 'of', 'the', 'maximum', 'of', 'a', 'regression', 'function', 'Ann', 'Math', 'Stat', '1952', '23', '3', '462', '6', 'http', 'dx', 'doi', 'org', '10', '1214', 'aoms', '1177729392', '40', 'Cauchy', 'A', 'Méthode', 'générale', 'pour', 'la', 'résolution', 'des', 'systemes', 'd', 'équations', 'simultanées', 'C', 'R', 'Sci', 'Paris', '1847', '25', '1847', '536', '8', '41', 'Qian', 'N', 'On', 'the', 'momentum', 'term', 'in', 'gradient', 'descent', 'learning', 'algo', 'rithms', 'Neural', 'Netw', '1999', '12', '1', '145', '51', 'http', 'dx', 'doi', 'org', '10', '1016', 'S0893', '6080', '98', '00116', '6', '42', 'Polyak', 'BT', 'Some', 'methods', 'of', 'speeding', 'up', 'the', 'convergence', 'of', 'iteration', 'methods', 'USSR', 'Comput', 'Math', 'Math', 'Phys', '1964', '4', '5', '1', '17', 'http', 'dx', 'doi', 'org', '10', '1016', '0041', '5553', '64', '90137', '5', '43', 'Nesterov', 'Y', 'A', 'method', 'for', 'unconstrained', 'convex', 'minimization', 'problem', 'with', 'the', 'rate', 'of', 'convergence', 'O', '1', 'k2', 'In', 'Doklady', 'an', 'Ussr', 'vol', '269', '1983', 'p', '543', '547', '44', 'Sutskever', 'I', 'Martens', 'J', 'Dahl', 'G', 'Hinton', 'G', 'On', 'the', 'importance', 'of', 'initialization', 'and', 'momentum', 'in', 'deep', 'learning', 'In', 'International', 'conference', 'on', 'machine', 'learning', '2013', 'p', '1139', '1147', '45', 'Goodfellow', 'I', 'Bengio', 'Y', 'Courville', 'A', 'Deep', 'learning', 'MIT', 'Press', '2016', '46', 'Duchi', 'J', 'Hazan', 'E', 'Singer', 'Y', 'Adaptive', 'subgradient', 'methods', 'for', 'online', 'learning', 'and', 'stochastic', 'optimization', 'J', 'Mach', 'Learn', 'Res', '2011', '12', 'Jul', '2121', '59', '47', 'Ruder', 'S', 'An', 'overview', 'of', 'gradient', 'descent', 'optimization', 'algorithms', '2016', 'arXiv', 'preprint', 'arXiv', '1609', '04747', '48', 'Zeiler', 'MD', 'Adadelta', 'An', 'adaptive', 'learning', 'rate', 'method', '2012', 'arXiv', 'preprint', 'arXiv', '1212', '5701', '49', 'Hinton', 'G', 'Srivastava', 'N', 'Swersky', 'K', 'Neural', 'networks', 'for', 'machine', 'learning', 'lecture', '6a', 'overview', 'of', 'mini', 'batch', 'gradient', 'descent', 'Cited', 'on', '2012', '14', '8', '50', 'Kingma', 'DP', 'Ba', 'J', 'Adam', 'A', 'method', 'for', 'stochastic', 'optimization', '2014', 'arXiv', 'preprint', 'arXiv', '1412', '6980', '32', 'Pinto', 'RF', 'Borges', 'CD', 'Almeida', 'A', 'Paula', 'IC', 'Static', 'hand', 'gesture', 'recognition', 'based', 'on', 'convolutional', 'neural', 'networks', 'J', 'Electr', 'Comput', 'Eng', '2019', '2019', 'http', 'dx', 'doi', 'org', '10', '1155', '2019', '4167890', '51', 'Ansari', 'ZA', 'Harit', 'G', 'Nearest', 'neighbour', 'classification', 'of', 'Indian', 'sign', 'language', 'gestures', 'using', 'kinect', 'camera', 'Sadhana', '2016', '41', '2', '161', '82', 'http', 'dx', 'doi', 'org', '10', '1007', 's12046', '015', '0405', '3', '33', 'He', 'K', 'Zhang', 'X', 'Ren', 'S', 'Sun', 'J', 'Identity', 'mappings', 'in', 'deep', 'residual', 'networks', 'In', 'European', 'conference', 'on', 'computer', 'vision', 'Springer', '2016', 'p', '630', '45', 'http', 'dx', 'doi', 'org', '10', '1007', '978', '3', '319', '46493', '0_38', '34', 'Szegedy', 'C', 'Ioffe', 'S', 'Vanhoucke', 'V', 'Alemi', 'AA', 'Inception', 'v4', 'inception', 'resnet', 'and', 'the', 'impact', 'of', 'residual', 'connections', 'on', 'learning', 'In', 'Thirty', 'first', 'AAAI', 'conference', 'on', 'artificial', 'intelligence', '2017', '52', 'Everitt', 'B', 'The', 'Cambridge', 'dictionary', 'of', 'statistics', 'Cambridge', 'UK', 'New', 'York', 'Cambridge', 'University', 'Press', '1998', 'ISBN', '9780521593465', '53', 'Keskar', 'NS', 'Mudigere', 'D', 'Nocedal', 'J', 'Smelyanskiy', 'M', 'Tang', 'PTP', 'On', 'large', 'batch', 'training', 'for', 'deep', 'learning', 'Generalization', 'gap', 'and', 'sharp', 'minima', '2016', 'arXiv', 'preprint', 'arXiv', '1609', '04836', '54', 'Raghuveera', 'T', 'Deepthi', 'R', 'Mangalashri', 'R', 'Akshaya', 'R', 'A', 'depth', 'based', 'Indian', 'Sign', 'Language', 'recognition', 'using', 'Microsoft', 'Kinect', 'Sadhana', '2020', '45', '1', '34', 'http', 'dx', 'doi', 'org', '10', '1007', 's12046', '019', '1250', '6', '12']\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b3262-fe66-475c-8904-9f3eb8356b26",
   "metadata": {},
   "source": [
    "## extracting images from PDF's using fitz and pillow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2449ba-7da8-4254-9690-a9d1dcacdaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import PIL.Image \n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b98b19b-dda5-497f-8f0c-de6482258745",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pdf = fitz.open(\"/home/mahadevks1048/Desktop/Mahadev/1-s2.0-S2666629421000152-main.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74b1a9b-ccfd-477a-b4ee-c7f11f9734b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 1\n",
    "for i in range(len(image_pdf)):\n",
    "    page = image_pdf[i]\n",
    "    images = page.get_images()\n",
    "    for image in images:\n",
    "        base_image = image_pdf.extract_image(image[0])\n",
    "        image_data = base_image[\"image\"]\n",
    "        img = PIL.Image.open(io.BytesIO(image_data))\n",
    "        extension = base_image[\"ext\"]\n",
    "        img.save(open(f\"image{cnt}.{extension}\",\"wb\"))\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c37fd-3b4f-43a7-8ab6-a4b667fe2d5a",
   "metadata": {},
   "source": [
    "## extracting text from table's in the  pdf's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a19858c0-c98d-46eb-81c2-ced378cd96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d77b1a-e0ef-47fc-b1a1-6b3da5273889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Apr 18, 2024 5:40:53 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font Symbol\n",
      "Apr 18, 2024 5:40:53 PM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
      "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset more than the state-of-the-art ML techniques. Liao et al.  \\\n",
      "0   [18] used a bi-directional long short term mem...                  \n",
      "1   CNN residual network for recognition of signs ...                  \n",
      "2   sign language datasets with recognition accura...                  \n",
      "3   86.9%, more than the accuracy achieved with ex...                  \n",
      "4   like hidden markov models (HMMs), neural netwo...                  \n",
      "..                                                ...                  \n",
      "58  three-layered CNN model, trained from scratch,...                  \n",
      "59  that performed better than the other models us...                  \n",
      "60  for ISL recognition. Thus, this comparative an...                  \n",
      "61  into selecting the suitable deep model with th...                  \n",
      "62  and its hyperparameters to enhance the models’...                  \n",
      "\n",
      "   vances in DL and transfer learning for SLR. Section 2 introduces  \n",
      "0   the proposed methodology for the performance e...                \n",
      "1   CNN deep models with various optimizers and hy...                \n",
      "2   The CNN architectures, optimization hyperparam...                \n",
      "3   rithms used in the paper are explained in Sect...                \n",
      "4   respectively. Section 6 discusses the evaluati...                \n",
      "..                                                ...                \n",
      "58  models, where a sequence of flatten, dense, an...                \n",
      "59  (Fig. 1) replace the last layer of these model...                \n",
      "60  maining layers to train on the ISL dataset. Th...                \n",
      "61  discusses the architectures of pre-trained dee...                \n",
      "62  proposed three-layered CNN model used for feat...                \n",
      "\n",
      "[63 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahadevks1048/.local/lib/python3.10/site-packages/tabula/io.py:1045: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "tables = tabula.read_pdf(\"/home/mahadevks1048/Desktop/Mahadev/1-s2.0-S2666629421000152-main.pdf\",pages = \"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c156215-7ee0-473a-a489-c77184471932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Models Parameters (M)  Layers  Size (MB)  Top-1 Loss  \\\n",
      "0        InceptionV3 [15]           23.8      48         92       21.20   \n",
      "1        ResNet152V2 [33]           60.4     152        232       19.38   \n",
      "2  InceptionResNetV2 [34]           55.8     164        215       19.90   \n",
      "3         ResNeXt101 [35]             −−     101        638       19.10   \n",
      "\n",
      "   Top-2 Loss  \n",
      "0        5.60  \n",
      "1        4.49  \n",
      "2        4.90  \n",
      "3        4.40  \n"
     ]
    }
   ],
   "source": [
    "print(tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ae6b51-e275-4ed2-9045-89600070b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Optimizer Train       CV for   Val   CV for.1  Train.1    Val.1  Precision  \\\n",
      "0       NaN  loss  train (CVT)  loss  val (CVV)  acc (%)  acc (%)        NaN   \n",
      "1       SGD  0.05         0.94  0.57       0.33     98.1     82.5       0.83   \n",
      "2   AdaGrad  0.11         3.47  0.76       1.75     96.5     74.9       0.76   \n",
      "3  AdaDelta  0.07         0.87  0.81       0.24     97.9     81.8       0.82   \n",
      "4   RMSProp  0.20         0.44  1.76       0.08     95.8     74.0       0.76   \n",
      "5      Adam  0.04         1.07  0.60       0.31     98.5     83.8       0.84   \n",
      "\n",
      "   Recall  f1-score       Val.2   Train.2  \n",
      "0     NaN       NaN  errors (%)  time (s)  \n",
      "1    0.82      0.83        17.7       246  \n",
      "2    0.75      0.75        24.8       288  \n",
      "3    0.82      0.82        18.3       380  \n",
      "4    0.74      0.74        25.8       456  \n",
      "5    0.83      0.83        16.4       470  \n"
     ]
    }
   ],
   "source": [
    "print(tables[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c57f3101-246a-40b8-b3c3-79de908759d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[1]\n",
    "df2 = tables[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67e52ef2-09d3-4b19-900d-af78aa6f112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Models Parameters (M)  Layers  Size (MB)  Top-1 Loss  \\\n",
      "0        InceptionV3 [15]           23.8      48         92       21.20   \n",
      "1        ResNet152V2 [33]           60.4     152        232       19.38   \n",
      "2  InceptionResNetV2 [34]           55.8     164        215       19.90   \n",
      "3         ResNeXt101 [35]             −−     101        638       19.10   \n",
      "\n",
      "   Top-2 Loss  \n",
      "0        5.60  \n",
      "1        4.49  \n",
      "2        4.90  \n",
      "3        4.40  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "391b447d-7bd7-4e11-abd2-aaa9c00b60ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Optimizer Train       CV for   Val   CV for.1  Train.1    Val.1  Precision  \\\n",
      "0       NaN  loss  train (CVT)  loss  val (CVV)  acc (%)  acc (%)        NaN   \n",
      "1       SGD  0.05         0.94  0.57       0.33     98.1     82.5       0.83   \n",
      "2   AdaGrad  0.11         3.47  0.76       1.75     96.5     74.9       0.76   \n",
      "3  AdaDelta  0.07         0.87  0.81       0.24     97.9     81.8       0.82   \n",
      "4   RMSProp  0.20         0.44  1.76       0.08     95.8     74.0       0.76   \n",
      "5      Adam  0.04         1.07  0.60       0.31     98.5     83.8       0.84   \n",
      "\n",
      "   Recall  f1-score       Val.2   Train.2  \n",
      "0     NaN       NaN  errors (%)  time (s)  \n",
      "1    0.82      0.83        17.7       246  \n",
      "2    0.75      0.75        24.8       288  \n",
      "3    0.82      0.82        18.3       380  \n",
      "4    0.74      0.74        25.8       456  \n",
      "5    0.83      0.83        16.4       470  \n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77790bfb-e6cc-452b-b11e-38792fd058e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Optimizer Train CV for   Val CV for.1 Train.1 Val.1  Precision  Recall  \\\n",
      "1       SGD  0.05   0.94  0.57     0.33    98.1  82.5       0.83    0.82   \n",
      "3  AdaDelta  0.07   0.87  0.81     0.24    97.9  81.8       0.82    0.82   \n",
      "5      Adam  0.04   1.07  0.60     0.31    98.5  83.8       0.84    0.83   \n",
      "\n",
      "   f1-score Val.2 Train.2  \n",
      "1      0.83  17.7     246  \n",
      "3      0.82  18.3     380  \n",
      "5      0.83  16.4     470  \n"
     ]
    }
   ],
   "source": [
    "print(df2[df2.Recall>0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d388c4c-f563-413d-afa5-bd049e15fbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
